---
layout: post
title: "[인공지능] 10주차 - Linear Function Approximation"
excerpt: "Function Approximation, Linear Function Approximation"

tags:
  - [인공지능, Python]

toc: true

date: 2025-10-27
last_modified_at: 2025-10-27
---
## Linear Function Approximation
### 1. Function Approximation
- 지금까지는 Tabular Methods  
  - Dynamic Programming (e.g., Value Iteration)  
    - 상태를 Key로, 상태 가치 함수의 추정치를 Value로 하는 맵/사전/테이블/배열 등에 저장  

  - Monte Carlo Methods (e.g., On-Policy MC)  
    - 상태와 행동의 쌍을 Key로, 행동 가치 함수의 추정치를 Value로 하는 맵/사전/테이블/배열 등에 저장

  - Temporal-Difference Learning (e.g., SARSA)  
    - 상태와 행동의 쌍을 Key로, 행동 가치 함수의 추정치를 Value로 하는 맵/사전/테이블/배열 등에 저장  

- 이와 같은 Tabular Methods는 Cardinality(=집합의 원소 개수)가 크지 않은 이산 상태 공간(Discrete State Space)에 대해서는 잘 작동함

- 그러나 Discrete State Space의 Cardinality가 매우 크거나, Continuous State Space인 경우에는 Tabular Methods를 적용하기 어려움

- 또한 Tabular Methods는 각 상태를 독립적으로 고려하므로, 가치 함수 또한 독립적으로 학슴됨. 
그러나 어떤 상태는 다른 상태와 관련이 있을 수도 있으며, 이러한 정보를 활요한다면 가치 함수를 빠르게 학습할 수 있음  

<br>

- Function Approximation  
![function_approximation][def]  
  - 주어진 상태(+ 행동)을 입력으로 받아, 가치 함수의 값을 출력으로 내는 함수를 학습
    - e.g., `V`<sub>`π`</sub>`(s; w)` = `w`<sub>`0`</sub> + `w`<sub>`1`</sub>`s`  
    - e.g., `Q`<sub>`π`</sub>`(s, a; w)` = `w`<sub>`0`</sub> + `w`<sub>`1`</sub>`s` + `w`<sub>`2`</sub>`a`  

  - 매개변수 `w` : 주어진 상태(+ 행동)에 대한 참인 가치 함수의 값을 출력하기 위하여 학습되어야 하는 변수  

- 다시 Tabular Methods로 돌아가보면,  
![tabular_methods_as_function_approximation][def2]  
  - 맵/사전/테이블/배열 등에 저장된 가치 함수의 추정치와 목표로 하는 값 간의 차이를 최소화  

- Tabular Method와 마찬가지로, 가치 함수의 추정치와 목표로 하는 값 간의 차이를 최소화하는 것이 목적
  - 가치 함수의 추정치와 목표로 하는 값 간의 차이를 정량적으로 측정하는 지표(또는 매개변수 `w`에 대한 함수)인 목적 함수(Objective Function) `J(w)`를 정의

- Tabular Method와 달리, 맵/사전/테이블/배열 등에 저장된 가치 함수의 값 자체를 업데이트하는 대신, 매개변수 `w`를 업데이트(또는 학습) 시킴  
  - 목적 함수(`J(w)`)를 최적화(= 가치 함수의 추정치와 목표로 하는 값 간의 차이를 최소화)하는 최적의 매개변수 `w`<sub>`*`</sub> = `argmin`<sub>`w`</sub>`J(w)`를 학습  

  <br>

- Objective Functions  
![objective_functions][def3]  
  - Squared Error  
  ![squared_error][def4]  

  - Huber Loss  
  ![huber_loss][def5]  
    - Error가 `δ` 보다 작을 때는 Squared Error와 동일
    - Error가 `δ` 보다 클 때는 Squared Error보다 작은 Error로 보정하여, 지나치게 Error가 커지지 않도록 함  

<br>

- Optimization of Objective Functions ?  
![optimization_of_objective_functions][def6]  

<br>

- Gradient Descent  
![gradient_descent][def7]  
  - 기계 학습 분야를 포함하여 대량의 데이터에 대한 최적화 문제에서 활용되는 방법  
  - 반복적인 매개변수 업데이트를 통해 최적의 매개변수를 학습  
  - Steps  
  ![gradient_descent_steps][def8]  

- 어떻게 Gradient Descent가 작동하는가?
  - 테일러 급수(Taylor Series)  
  ![taylor_series][def9]  

  - 1차 테일러 급수로 표현한 목적 함수  
  ![taylor_series_objective_function][def10]  
  ![taylor_series_objective_function_expanded][def11]  

<br>

- Convexity & Convergence  
![convexity_convergence][def12]  
  - 최적 매개변수 `w`<sub>`*`</sub> = 목적 함수 `J(w)`의 값이 가장 작은 지점  
  - 목적 함수가 볼록 함수(Convex Function)라면, 손실 기울기가 `0`인 지점이 최적의 매개변수  
  - 즉, 손실 기울기가 `0`이 되면 더 이상 매개변수의 값이 변하지 않음 (= 수렴)  
  ![convex_function_convergence][def13]  
    - 즉, Gradient Descent를 적용하기 위해서는 목적 함수가 볼록 함수이면서, 미분 가능해야 함  

<br>

- Update Rule
  - Squared Error
    - State-Value Function Approximation  
    ![svf_approximation_update_rule][def14]  

    - Action-Value Function Approximation  
    ![avf_approximation_update_rule][def15]

  - Huber Loss  
    - State-Value Function Approximation  
    ![svf_approximation_update_rule_huber][def16]  

    - Action-Value Function Approximation  
    ![avf_approximation_update_rule_huber][def17]  

<br>

- True Gradient Descent  
![true_gradient_descent][def18]  
  - `G`<sub>`t`</sub> : 환경과 상호작용하면서 실제 수익의 분포로부터 추출된 편향되지 않은(Unbiased, 실제로 존재하는) 값
    - 최적의 매개변수는 실제 수익을 정확히 함수적으로 근사 가능
    - 에피소드가 끝나야 Target을 알 수 있으므로 학습 속도가 느림

- Semi-Gradient Descent  
![semi_gradient_descent][def19]  
  - `R`<sub>`t+1`</sub> + `γ` `V`<sub>`π`</sub><sup>`(k)`</sup>`(S`<sub>`t+1`</sub>`; w)` : 추정치의 추정치(= Bootstrapping)로, 편향된(Biased, 실제로 존재하지 않을 수도 있는) 값
    - 매개변수를 통해 가치함수를 근사하므로, 한 번 매개변수가 업데이트 되면 Target도 바뀜  
    - 최적의 매개변수는 실제로 얻는 수익을 정확하게 근사하지 못할 수 있음
    - 에피소드가 종료될 때까지 기다리지 않아도 학습 속도가 빠름  

<br>

- 주요 고려사항
  - 손실 기울기를 업데이트 반영하는 정도를 조정하는 **학습률**의 적절한 설정
  - 목적 함수는 미분 가능해야 하고, 볼록 함수여야 함
  - 입력 벡터의 범위에 민감 -> 서로 다른 차원의 입력 벡터 또는 특성 벡터의 범위를 통일시켜야 함(표준화, 정규화) 

<br>

- Pseudocode: On-Policy Monte Carlo Control  
![on_policy_mc_control_function_approximation_pseudocode][def20]  

- Pseudocode: Sarsa  
![sarsa_function_approximation_pseudocode][def21]  

- Pseudocode: n-step Sarsa  
![n_step_sarsa_function_approximation_pseudocode][def22]  

<br>

### 2. Linear Function Approximation  
- 다항 함수(Polynomial Function)  
![polynomial_function][def23]  
  - 계수(`w`<sub>`1`</sub>) : 각 계수에 대응하는 입력값이 출력값에 미치는 영향
  - 절편(`w`<sub>`0`</sub>) : 입력값이 없을 때(`0`)의 기본적인 출력값의 크기  

<br>

- 다항 함수 = 선형 함수(Linear Function)  
  - 입력값과 가중치의 가중 입력합으로 출력을 표현  
  ![linear_function][def24]  

  - m차원 입력에 대한 선형 함수의 일반적인 형태  
  ![general_linear_function][def25]  

  - 열 벡터 표현식  
  ![linear_function_vector_form][def26]  

- Linear Function Approximation  
  - m차원 상태의 가중 입력합으로 가치 함수를 표현  
  ![linear_function_approximation][def27]  

- Feature Vector
  - 보통은 상태 벡터를 그대로 사용하는 대신, 별도의 전처리 등을 거쳐 의미있는 벡터(= 특성 벡터, Feature Vector)로 변환하여 사용  
  ![feature_vector][def28]  

- Feature Vector: Polynomials  
  - 서로 다른 상태 차원 간의 Interaction Effect를 고려하여 특성값을 추출  
  - e.g., 2차원 상태 벡터 -> 3차원 특성 벡터  
  ![polynomial_feature_vector][def29]  
  - e.g., 2차원 상태 벡터 -> 8차원 특성 벡터  
  ![polynomial_feature_vector_2][def30]  

- Feature Vector: Coarse Coding  
![coarse_coding_feature_vector][def31]  
  - 임의의 범위들을 생성한 후, 주어진 상태가 각 범위 내에 포함되는 지를 `0` 또는 `1`의 값으로 표현하는 이진 특성 벡터를 추출  
  - 다양한 크기 및 형태를 가진 범위를 설정하거나 동시에 여러 설정들을 고려하는 것도 가능  
  - e.g.,  
  ![state_space][def32]  

- Feature Vector: Tile Coding
  - Coarse Coding을 확장하여 상태 공간을 이산적으로 분할한 여러 타일 내의 포함 여부를 특성값으로 활용
  - 타일의 형태, 위치 등을 다양하게 설정할 수 있음  
  - e.g.,  
  ![tile_coding_feature_vector][def33]  

<br>

- Gradient Descent  
![linear_function_approximation_gradient_descent][def34]  

<br>

- Action-Value: One-Hot Encoding  
![avf_one_hot_encoding][def35]  
  - 이산적인 행동 공간을 이진 벡터로 변환
  - e.g., 행동 `a` ∈ `{0, 1, 2, 3}`  
    - `a` = `0` : `a` = `[1, 0, 0, 0]`
    - `a` = `1` : `a` = `[0, 1, 0, 0]`  
    - `a` = `2` : `a` = `[0, 0, 1, 0]`  
    - `a` = `3` : `a` = `[0, 0, 0, 1]`  

- Action-Value: Separated Approximation  
![avf_separated_fa][def36]  
  - 각 행동마다 별도의 매개변수를 활용  
  - e.g., 행동 `a` ∈ `{0, 1, 2, 3}`  
  ![avf_separated_fa_equation][def37]  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown=   "1">

이 포스팅은 강원대학교 최우혁 교수님의 인공지능 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 

[def]: https://i.imgur.com/sX1Hfqx.png
[def2]: https://i.imgur.com/6G2M3fl.png
[def3]: https://i.imgur.com/Zqj07mP.png
[def4]: https://i.imgur.com/Kc6i2s3.png
[def5]: https://i.imgur.com/CaFUmGr.png
[def6]: https://i.imgur.com/r9Kq8nH.png
[def7]: https://i.imgur.com/nrlw93c.png
[def8]: https://i.imgur.com/NpYTfP8.png
[def9]: https://i.imgur.com/U4PsaSa.png
[def10]: https://i.imgur.com/Okx9CBR.png
[def11]: https://i.imgur.com/6gN6ZDv.png
[def12]: https://i.imgur.com/Ul4PYwA.png
[def13]: https://i.imgur.com/jZPLim1.png
[def14]: https://i.imgur.com/9mOpziY.png
[def15]: https://i.imgur.com/1XPfUq7.png
[def16]: https://i.imgur.com/6bKoirS.png
[def17]: https://i.imgur.com/jrP21bd.png
[def18]: https://i.imgur.com/K7NiFx3.png
[def19]: https://i.imgur.com/4lpSjDA.png
[def20]: https://i.imgur.com/kDcsJun.png
[def21]: https://i.imgur.com/BVAl5pC.png
[def22]: https://i.imgur.com/ibFp0wb.png
[def23]: https://i.imgur.com/qD0k4o3.png
[def24]: https://i.imgur.com/ltpgGKi.png
[def25]: https://i.imgur.com/yMohlgd.png
[def26]: https://i.imgur.com/H1YWeEN.png
[def27]: https://i.imgur.com/TypWTou.png
[def28]: https://i.imgur.com/bAO8xvt.png
[def29]: https://i.imgur.com/TBhu0Ri.png
[def30]: https://i.imgur.com/gNVuYHD.png
[def31]: https://i.imgur.com/vGHaTNM.png
[def32]: https://i.imgur.com/L34yRxo.png
[def33]: https://i.imgur.com/J04HuIk.png
[def34]: https://i.imgur.com/FeFy64e.png
[def35]: https://i.imgur.com/CLc3pXe.png
[def36]: https://i.imgur.com/s9qYZN6.png
[def37]: https://i.imgur.com/hE4pAl5.png