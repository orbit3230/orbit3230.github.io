---
layout: post
title: "[인공지능] 11주차 - Practice on Nonlinear Function Approximation"
excerpt: "Prerequisites, Building Neural Network using Keras, Model as Function, Traning Simple Agent, Building Convolutional Neural Network using Keras"

tags:
  - [인공지능, Python]

toc: true

date: 2025-11-10
last_modified_at: 2025-11-10
---
## Practice on Nonlinear Function Approximation
### 1. Prerequisites
`%pip install -q tensorflow gymnasium kymatio matplotlib`  

- Fixing Random Seed

```py
from tensorflow import keras

keras.utils.set_random_seed(42)
```

<br>

### 2. Building Neural Network using Keras
- Perceptron 생성

```py
from tensorflow import keras

model = keras.models.Sequential()
```

<br>

- Layer 추가

```py
from tensorflow import keras

# 입력 레이어를 추가
model.add(
    keras.layers.Input(
        shape=(3, ) # 입력의 차원으로, 항상 Tuple 형식으로 정의되어야 함; 여기선 3차원 입력을 설정
    )
)
```

- Fully Connected Layer 정의
  - `units` : 생성할 퍼셉트론의 개수
  - `activation` : 활성 함수
    - `identity`, `sigmoid`, `ReLU`, `tanh`, `softmax`, ...
  - `kernel_initializer` : 가중치 초기화
    - linear, tanh, sigmoid, softmax : `Glorot`
    - ReLU : `He`
    - SELU : `LeCun`

```py
import keras

model.add(
    keras.layers.Dense(
        # 레이어에 포함된 Perceptron의 개수
        units=1,
        # ReLU 함수를 Activation Function으로 활용
        activation=keras.activations.relu,
        # ReLU의 가중치 초기화 기법은 HeNormal 또는 HeUniform 사용
        # 가중치 초기화 시 역시 Random Seed를 넣는 것을 잊지 말자.
        kernel_initializer=keras.initializers.HeNormal(seed=42)
    )
)
```

<br>

- 모델 요약

```py
# 생성한 모델의 요약을 보여준다.
model.summary()

Model: "sequential"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ dense (Dense)                   │ (None, 1)              │             4 │
└─────────────────────────────────┘
 Total params: 4 (16.00 B)
 Trainable params: 4 (16.00 B)
 Non-trainable params: 0 (0.00 B)
```

<br>

- 여러 Perceptron들이 병렬적으로 존재하는 Layer 생성  

```py
from tensorflow import keras

model = keras.models.Sequential()

model.add(
    keras.layers.Input(
        shape=(3, )
    )
)

model.add(
    keras.layers.Dense(
        units=10,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42)
    )
)

model.summary()

Model: "sequential_1"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ dense_1 (Dense)                 │ (None, 10)             │            40 │
└─────────────────────────────────┘
 Total params: 40 (160.00 B)
 Trainable params: 40 (160.00 B)
 Non-trainable params: 0 (0.00 B)
```

<br>

- 여러 Layer 쌓기

```py
from tensorflow import keras

model = keras.models.Sequential()

model.add(
    keras.layers.Input(
        shape=(3, ),
    )
)

model.add(
    keras.layers.Dense(
        units=4,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
        name='input'
    )
)
model.add(
    keras.layers.Dense(
        units=6,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
        name='hidden'
    )
)
model.add(
    keras.layers.Dense(
        units=3,
        activation=keras.activations.linear,
        kernel_initializer=keras.initializers.GlorotNormal(seed=42), # Linear 함수의 가중치 초기화 기법은 GlorotNormal 또는 GlorotUniform 사용
        name='output'
    )
)

model.summary()

Model: "sequential_2"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ input (Dense)                   │ (None, 4)              │            16 │
├─────────────────────────────────┤
│ hidden (Dense)                  │ (None, 6)              │            30 │
├─────────────────────────────────┤
│ output (Dense)                  │ (None, 3)              │            21 │
└─────────────────────────────────┘
 Total params: 67 (268.00 B)
 Trainable params: 67 (268.00 B)
 Non-trainable params: 0 (0.00 B)
```

- 레이어는 리스트를 인자로 받아 한 번에 추가할 수도 있다.

```py
from tensorflow import keras

model = keras.models.Sequential([
    keras.layers.Input(
        shape=(3, ),
    ),
    keras.layers.Dense(
        units=4,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
        name='input'
    ),
    keras.layers.Dense(
        units=6,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
        name='hidden'
    ),
    keras.layers.Dense(
        units=3,
        activation=keras.activations.linear,
        kernel_initializer=keras.initializers.GlorotNormal(seed=42),
        name='output'
    )
])
```

<br>

### 3. Model as Function
- Keras에서 제공하는 Model과 Layer 클래스의 특징은 객체 그 자체가 일종의 함수라는 것이다.  

```py
import numpy as np
from tensorflow import keras

# 임의의 입력을 만들자
input = np.array([1, 2, 3])

# 6개의 퍼셉트론으로 구성된 레이어를 선언하자.
layer = keras.layers.Dense(
    units=6,
    activation=keras.activations.relu,
    kernel_initializer=keras.initializers.HeNormal(),
)

# 입력의 형태를 (3, ) 대신에 (1, 3)로 바꾸자.
# Keras의 Layer 및 Model은 단일 데이터를 입력으로 받는 게 아니라
# 여러 데이터의 묶음을 입력으로 받는다.
# (3, ) 이라면 3차원 단일 데이터지만
# (1, 3) 이라면 3차원 데이터가 1개 있다는 의미가 된다.

input = keras.ops.expand_dims(input, axis=0)

print(f'Expanded input: {input}; shape: {input.shape}')

# 이제 Layer 객체에 입력으로 넣자.
layer(input)
```

```
Expanded input: [[1 2 3]]; shape: (1, 3)
<tf.Tensor: shape=(1, 6), dtype=float32, numpy=
array([[0.       , 0.       , 0.       , 0.       , 1.9256754, 2.3117342]],
      dtype=float32)>
```

```py
import numpy as np
from tensorflow import keras

# (10, 3) 데이터를 만들자
input = np.ones(shape=(10, 3))

# 6개의 퍼셉트론으로 구성된 레이어를 선언하자.
layer = keras.layers.Dense(
    units=6,-
    activation=keras.activations.relu,
    kernel_initializer=keras.initializers.HeNormal(seed=42),
)

# 이제 Layer 객체에 입력으로 넣자.
layer(input)
```

```
<tf.Tensor: shape=(10, 6), dtype=float32, numpy=
array([[0.7509248, 0.       , 0.       , 1.5883077, 0.       , 0.4449048],
       [0.7509248, 0.       , 0.       , 1.5883077, 0.       , 0.4449048],
       [0.7509248, 0.       , 0.       , 1.5883077, 0.       , 0.4449048],
       [0.7509248, 0.       , 0.       , 1.5883077, 0.       , 0.4449048],
       [0.7509248, 0.       , 0.       , 1.5883077, 0.       , 0.4449048],
       [0.7509248, 0.       , 0.       , 1.5883077, 0.       , 0.4449048],
       [0.7509248, 0.       , 0.       , 1.5883077, 0.       , 0.4449048],
       [0.7509248, 0.       , 0.       , 1.5883077, 0.       , 0.4449048],
       [0.7509248, 0.       , 0.       , 1.5883077, 0.       , 0.4449048],
       [0.7509248, 0.       , 0.       , 1.5883077, 0.       , 0.4449048]],
      dtype=float32)>
```

<br>

### 3. Traning Simple Agent  
- `keras.models.Model` 클래스의 `compile-fit`는, 입력 데이터에 대해 출력 데이터가 이미 충분히 많이 확보가 된 상태에서 사용 가능하다.  
그러나 우리는 데이터를 미리 준비할 수 없는 강화학습 환경이므로, 직접 신경망을 훈련시키는 파이프라인을 구현해야 한다.  

- FrozenLake 환경 불러오기  

```py
import gymnasium as gym
import matplotlib.pyplot as plt

env = gym.make(
    id='FrozenLake-v1',
    render_mode='rgb_array',
    is_slippery=False, # 타일에서 미끄러지는 여부를 결정
)
env.reset()

plt.imshow(env.render())
plt.axis('off')
plt.show()
```

- 상태로 `[0, 15]` 사이 숫자를 사용하는 대신, One-hot encoding을 사용하여 상태를 이진 벡터로 표현하자.  

```py
from tensorflow import keras

# 숫자 1을 One-Hot Encoding으로 변환해보겠다
keras.ops.one_hot(1, env.observation_space.n)
```

```
<tf.Tensor: shape=(16,), dtype=float32, numpy=
array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
      dtype=float32)>
```

- 신경망 또한 16차원으로 받아야 한다.  

```py
from tensorflow import keras


model = keras.models.Sequential([
    # 16차원 입력을 받는다
    keras.layers.Input(
        shape=(env.observation_space.n, ),
    ),
    # 먼저 16차원 입력을 64개의 퍼셉트론이 있는 레이어로 연결한다.
    keras.layers.Dense(
        units=64,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
    ),
    # 다음, 64개의 퍼셉트론이 있는 레이어를 연결한다.
    keras.layers.Dense(
        units=64,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
    ),
    # 마지막으로 4개의 퍼셉트론이 있는 레이어를 연결한다.
    # 각 퍼셉트론이 상, 하, 좌, 우 행동에 대한 행동 가치 함수를 출력하는 것이다.
    keras.layers.Dense(
        units=env.action_space.n,
        activation=keras.activations.linear,
        kernel_initializer=keras.initializers.GlorotNormal(seed=42),
    )
])
model.summary()

Model: "sequential_4"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ dense_4 (Dense)                 │ (None, 64)             │         1,088 │
├─────────────────────────────────┤
│ dense_5 (Dense)                 │ (None, 64)             │         4,160 │
├─────────────────────────────────┤
│ dense_6 (Dense)                 │ (None, 4)              │           260 │
└─────────────────────────────────┘
 Total params: 5,508 (21.52 KB)
 Trainable params: 5,508 (21.52 KB)
 Non-trainable params: 0 (0.00 B)
```

<br>

- Objective Function과 훈련 알고리즘 선언  
  - 대표적인 목적 함수
    - `keras.losses.MeanSquaredError`
    - `keras.losses.Huber`
  - 대표적인 훈련 알고리즘  
    - `keras.optimizers.SGD`
    - `keras.optimizers.Adagrad`
    - `keras.optimizers.RMSprop`
    - `keras.optimizers.Adam`
    - `keras.optimizers.Adamax`
    - `keras.optimizers.Nadam`  

```py
from tensorflow import keras


objective = keras.losses.Huber(
    delta=1.0 # Huber Loss의 Delta 값이다. 보통은 1.0 정도로 잡는다.
)

optimizer = keras.optimizers.Adam(
    learning_rate=0.00025, # 학습룰
    clipnorm=1.0 # Gradient Clipping을 의미한다
)
```

<br>

- Epsilon Scheduling  

```py
def calc_epsilon(
    episode: int, # 현재 에피소드 횟수
    eps_min: float, # 최소 Epsilon
    eps_max: float, # 최대 Epsilon
    episodes_eps_max: int, # 최대 Epsilon을 적용할 초반 에피소드 갯수
    episodes_eps_decrease: int # Epsilon 값을 점차 줄여나갈 에피소드 갯수
):
    if episode < episodes_eps_max:
        epsilon = eps_max
    else:
        episode_diff = episode - episodes_eps_max
        episode_range = episodes_eps_decrease - episodes_eps_max
        eps_diff = eps_max - eps_min
        epsilon = eps_max - eps_diff * episode_diff / episode_range
        epsilon = max(epsilon, eps_min)
    return epsilon
```

```py
import numpy as np
import matplotlib.pyplot as plt


episodes = np.arange(1000)
epsilons = [
    calc_epsilon(
        episode=episode,
        eps_min=0.1,
        eps_max=1.0,
        episodes_eps_max=300,
        episodes_eps_decrease=700,
    )
    for episode in episodes
]
```

<br>

- On-Policy Monte Carlo Control with Function Approximation

```py
import numpy as np
from tensorflow import keras
import tensorflow as tf
from tqdm.auto import tqdm

EPS_MIN, EPS_MAX = 0.1, 1.0
EPISODES_EPS_MAX, EPISODES_EPS_DECREASE, EPISODES_MAX = 100, 500, 1000
GAMMA = 0.99

# 재현성 확보를 위해 랜덤 시드를 고정
random = np.random.default_rng(42)

# 예쁘게 중간 과정을 보여주기 위해 tqdm 라이브러리 활용
pbar = tqdm(range(EPISODES_MAX), desc='Episode')

# 최근 5개의 에피소드에 대한 평균 보상을 저장
reward_per_episode = []

for episode in pbar:
    epsilon = calc_epsilon(
        episode=episode,
        eps_min=EPS_MIN,
        eps_max=EPS_MAX,
        episodes_eps_max=EPISODES_EPS_MAX,
        episodes_eps_decrease=EPISODES_EPS_DECREASE
    )

    # 현재 에피소드의 상태-행동-보상을 저장
    history = []

    obs, _ = env.reset()
    done = False

    while not done:
        # One-Hot Encoding으로 16차원 이진 벡터로 변환
        state = keras.ops.one_hot(obs, env.observation_space.n)
        # (16, ) -> (1, 16)
        state = keras.ops.expand_dims(state, axis=0)

        # Epsilon 확률로 무작위 행동 선택
        if random.random() < epsilon:
            action = random.choice(np.arange(env.action_space.n))
        else:
            # 4개 행동에 대한 행동 가치 함수 출력
            Q = model(state)

            # 행동 가치 함수가 가장 큰 행동 선택
            # 만약 행동 가치 함수의 값이 같은 행동이 있다면
            # 그 중 하나를 무작위로 선택
            action = random.choice(np.flatnonzero(Q == np.max(Q)))

        next_obs, _, terminated, truncated, _ = env.step(action)

        done = terminated or truncated

        # 보상은 다음과 같이 설정
        # 같은 장소에 머무르는 경우: -0.1
        if obs == next_obs:
            reward = -0.1
        # 목표 지점에 도착한 경우: 1.0
        elif next_obs == env.observation_space.n - 1:
            reward = 1.0
        # 행동 횟수 제한 초과 (100번) 또는 얼음 구멍에 빠진 경우: -1.0
        elif done:
            reward = -1.0
        # 그 외: 0.0
        else:
            reward = 0.0

        obs = next_obs

        history.append((state, action, reward))

    avg_loss = 0

    G = keras.ops.expand_dims(0.0, axis=0)

    for state, action, reward in reversed(history):
        # 에피소드 종료 후 수익 계산
        G = reward + GAMMA * G

        # 여기서부터 중요하다.
        # 테이프에 입출력을 수행하고, 목적 함수의 값을 계산하면
        # 활용된 모든 매개변수들이 기록되며
        # 자동적으로 손실 기울기를 계산할 수 있게 된다.
        with tf.GradientTape() as tape:
            # 행동 가치 함수를 출력한다.
            Q = model(state)

            # 이 중, 선택된 행동에 대한 행동 가치 함수의 값만을 가져온다.
            Q_a = Q[:, action]
            # 수익의 값과 행동 가치 함수의 값 간의 차이를 Huber Loss를 통해 계산한다.
            loss = objective(G, Q_a)

        # Huber Loss 대해서 Loss Gradient를 계산한다.
        gradients = tape.gradient(
            loss, # Huber Loss 값
            model.trainable_variables # Huber Loss를 모델의 훈련해야할 매개변수로 미분
        )

        # 계산된 Loss Gradient를 가지고 Optimizer로 하여금 매개변수 업데이트를 수행하도록 한다.
        optimizer.apply_gradients(zip(gradients, model.trainable_variables))

        avg_loss += loss

    avg_loss /= len(history)
    avg_reward = np.mean([reward for _, _, reward in history])

    pbar.set_postfix(
        eps=f'{epsilon:.5f}',
        loss=f'{avg_loss:.5f}',
        reward=f'{avg_reward:.5f}'
    )

    # 평균 보상 기록이 5개 초과 시 맨 처음 (= 제일 과거)의 기록 삭제
    if len(reward_per_episode) > 5:
        del reward_per_episode[:1]

    reward_per_episode.append(avg_reward)

    # 4 x 4 FrozenLake는 6번의 행동으로 클리어가 가능하며, 클리어 시 보상 1.0을 주므로
    # 최근 5개 에피소드에서 약 0.15 이상의 평균 보상을 얻으면
    # 최적의 정책을 찾았다고 할 수 있음
    if np.mean(reward_per_episode) >= 0.15:
        print('Solved!')
        break
```

<br>

- 에이전트 구현  

```py
from tensorflow import keras
import kymnasium as kym
from typing import Any, Dict
import pickle

class MonteCarloAgent(kym.Agent):
    def __init__(
            self,
            model: keras.models.Model,
            seed: int = None
    ):
        self.model = model
        self.seed = seed
        self.random = np.random.default_rng(self.seed)

    def save(self, path: str):
        config = {
            'seed': self.seed,
        }
        # Random Seed를 저장해놓겠다.
        with open(f'{path}.config', 'wb') as f:
            pickle.dump(config, f)

        # Model은 다음처럼 저장할 수 있다.
        keras.models.save_model(
            model=self.model,
            filepath=f'{path}.keras'
        )

    @classmethod
    def load(cls, path: str):
        # Random Seed를 불러오겠다.
        with open(f'{path}.config', 'rb') as f:
            config = pickle.load(f)

        # Model은 다음처럼 불러올 수 있다.
        model = keras.models.load_model(
            filepath=f'{path}.keras'
        )
        return MonteCarloAgent(model=model, seed=config['seed'])

    def act(self, observation: Any, info: Dict):
        state = keras.ops.one_hot(obs, env.observation_space.n)
        state = keras.ops.expand_dims(state, axis=0)
        Q = self.model(state)
        action = self.random.choice(np.flatnonzero(Q == np.max(Q)))
        return action
```

<br>

- 에이전트 테스트  

```py
import matplotlib.pyplot as plt

agent = MonteCarloAgent.load('./mc-agent')
images = []
done = False

obs, info = env.reset()
images.append(env.render())

while not done:
    action = agent.act(obs, info)
    obs, _, terminated, truncated, info = env.step(action)
    images.append(env.render())
    done = terminated or truncated

print(f'Game Clear w/ {len(images) - 1} Actions')

fig, axes = plt.subplots(len(images), 1, figsize=(5, len(images) * 5))

for i, image in enumerate(images):
    axes[i].imshow(image)
    axes[i].axis('off')
```

<br>

### 4. Building Convolutional Neural Network using Keras
- `keras.layers.Conv1D`를 사용하면 쉽게 한 방향으로 Convolution Operation을 수행하는 1D Convolutional Layer를 만들 수 있다.  

```py
from tensorflow import keras

model = keras.models.Sequential([
    keras.Input(
        shape=(4, 1)
    ),
    keras.layers.Conv1D(
        kernel_size=2, # Receptive Field의 크기
        strides=1, # Receptive Field를 움직일 Stride의 크기
        filters=1, # Filter의 개수
    )
])

model.summary()

Model: "sequential_5"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ conv1d (Conv1D)                 │ (None, 3, 1)           │             3 │
└─────────────────────────────────┘
 Total params: 3 (12.00 B)
 Trainable params: 3 (12.00 B)
 Non-trainable params: 0 (0.00 B)
```

- 입력 데이터의 차원을 좀 더 늘려보자.

```py
from tensorflow import keras

model = keras.models.Sequential([
    keras.Input(
        shape=(4, 3)
    ),
    keras.layers.Conv1D(
        kernel_size=2,
        strides=1,
        filters=1,
    )
])

model.summary()

Model: "sequential_6"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ conv1d_1 (Conv1D)               │ (None, 3, 1)           │             7 │
└─────────────────────────────────┘
 Total params: 7 (28.00 B)
 Trainable params: 7 (28.00 B)
 Non-trainable params: 0 (0.00 B)
```

- 필터의 개수를 늘려보자.

```py
from tensorflow import keras

model = keras.models.Sequential([
    keras.Input(
        shape=(4, 3)
    ),
    keras.layers.Conv1D(
        kernel_size=2,
        strides=1,
        filters=4,
    )
])

model.summary()

Model: "sequential_7"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ conv1d_2 (Conv1D)               │ (None, 3, 4)           │            28 │
└─────────────────────────────────┘
 Total params: 28 (112.00 B)
 Trainable params: 28 (112.00 B)
 Non-trainable params: 0 (0.00 B)
```

- 차원을 늘리고 싶다면 `keras.layers.Conv2D` or `keras.layers.Conv3D`를 사용할 수 있다.  

```py
from tensorflow import keras

model = keras.models.Sequential([
    keras.Input(
        shape=(4, 3, 5)
    ),
    keras.layers.Conv2D(
        kernel_size=(2, 2),
        strides=1,
        filters=4,
    )
])

model.summary()

Model: "sequential_8"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ conv2d (Conv2D)                 │ (None, 3, 2, 4)        │            84 │
└─────────────────────────────────┘
 Total params: 84 (336.00 B)
 Trainable params: 84 (336.00 B)
 Non-trainable params: 0 (0.00 B)
```

<br>

- Zero Padding으로 입력 크기와 같은 크기의 출력을 낼 수 있다.  

```py
from tensorflow import keras


model = keras.models.Sequential([
    keras.Input(
        shape=(4, 1)
    ),
    keras.layers.Conv1D(
        kernel_size=3,
        strides=1,
        filters=1,
        padding="valid" # Zero-Padding 적용하지 않음
    )
])

model.summary()

Model: "sequential_9"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ conv1d_3 (Conv1D)               │ (None, 2, 1)           │             4 │
└─────────────────────────────────┘
 Total params: 4 (16.00 B)
 Trainable params: 4 (16.00 B)
 Non-trainable params: 0 (0.00 B)
```

```py
from tensorflow import keras

model = keras.models.Sequential([
    keras.Input(
        shape=(4, 1)
    ),
    keras.layers.Conv1D(
        kernel_size=3,
        strides=1,
        filters=1,
        padding="same" # Zero-Padding 적용함
    )
])

model.summary()

Model: "sequential_10"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ conv1d_4 (Conv1D)               │ (None, 4, 1)           │             4 │
└─────────────────────────────────┘
 Total params: 4 (16.00 B)
 Trainable params: 4 (16.00 B)
 Non-trainable params: 0 (0.00 B)
```

<br>

- Pooling Layer - 1D Pooling Layer

```py
from tensorflow import keras


model = keras.models.Sequential([
    keras.Input(
        shape=(4, 1)
    ),
    keras.layers.MaxPool1D(
        pool_size=2,
        strides=1
    )
])

model.summary()

Model: "sequential_11"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ max_pooling1d (MaxPooling1D)    │ (None, 3, 1)           │             0 │
└─────────────────────────────────┘
 Total params: 0 (0.00 B)
 Trainable params: 0 (0.00 B)
 Non-trainable params: 0 (0.00 B)
```

- Pooling Layer - 1D Pooling Layer (2 Strides)

```py
from tensorflow import keras

model = keras.models.Sequential([
    keras.Input(
        shape=(4, 3)
    ),
    keras.layers.MaxPool1D(
        pool_size=2,
        strides=2
    )
])

model.summary()

Model: "sequential_12"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ max_pooling1d_1 (MaxPooling1D)  │ (None, 2, 3)           │             0 │
└─────────────────────────────────┘
 Total params: 0 (0.00 B)
 Trainable params: 0 (0.00 B)
 Non-trainable params: 0 (0.00 B)
```

- Global Pooling

```py
from tensorflow import keras

model = keras.models.Sequential([
    keras.Input(
        shape=(12, 3)
    ),
    keras.layers.GlobalAveragePooling1D()
])

model.summary()

Model: "sequential_13"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ global_average_pooling1d        │ (None, 3)              │             0 │
│ (GlobalAveragePooling1D)        │                        │               │
└─────────────────────────────────┘
 Total params: 0 (0.00 B)
 Trainable params: 0 (0.00 B)
 Non-trainable params: 0 (0.00 B)
```

<br>

### 5. Training Agent using Image Observation
- `render()` 함수를 쓰면 이미지를 받아올 수 있다.  

```py
import matplotlib.pyplot as plt

obs, _ = env.reset()
img = env.render()
```

<br>

- Preprocessing
  - 크기를 더 작게 조절하고, 흑백값 & 픽셀값을 [0, 1] 사이로 정규화

```py
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

resizing_layer = keras.layers.Resizing(
    height=32,
    width=32,
)
resized_img = resizing_layer(img)

gray_img = tf.image.rgb_to_grayscale(resized_img)
```

- 그러나 흑백으로 바꾸는 연산은 레이어에서 하는 연산이 아니므로, `keras.layers.Layer` 클래스를 상속하여 새로운 레이어 생성  

```py
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt

# 아래의 Decoration을 쓰지 않으면
# 이 레이어를 활용한 신경망 모델을 불러올 수 없다.
@keras.utils.register_keras_serializable()
class GrayScaleLayer(keras.layers.Layer):
    def __inint__(self, **kwargs):
        super().__init__(**kwargs)

    # 레이어 연산을 하는 부분은 call()에서 정의한다.
    def call(self, inputs):
        return tf.image.rgb_to_grayscale(inputs)


gray_layer = GrayScaleLayer()
gray_img = gray_layer(resized_img)

plt.imshow(gray_img, cmap='gray')
plt.axis('off')
plt.show()

print(f'Shape: {gray_img.shape}')
```

- 마지막으로 픽셀값을 [0, 1] 사이로 정규화  

```py
from tensorflow import keras

rescaling_layer = keras.layers.Rescaling(
    scale=1.0 / 255.0,
)

rescaling_layer(gray_img)
```

<br>

- Convolution 연산을 수행하는 신경망 생성

```py
from tensorflow import keras


model = keras.models.Sequential([
    # 원본 입력 크기
    keras.layers.Input(
        shape=(256, 256, 3),
    ),
    # (32, 32, 3)으로 축소
    keras.layers.Resizing(
        height=32,
        width=32,
    ),
    # Gray Scale로 변환
    GrayScaleLayer(),
    # 픽셀값 [0, 255]에서 [0, 1]로 변환
    keras.layers.Rescaling(
        scale=1.0 / 255.0,
    ),
    # 큰 Receptive Field를 가진 적은 수의 필터로 시작
    keras.layers.Conv2D(
        filters=32,
        kernel_size=8,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
        padding='same'
    ),
    # Max Pooling으로 데이터의 크기를 줄임
    keras.layers.MaxPool2D(
        pool_size=2,
    ),
    # 앞선 Convolution Layer보다 작은 Receptive Field를 가지고 다수의 필터를 활용하는
    # Convolution Layer 두 개를 연결
    keras.layers.Conv2D(
        filters=64,
        kernel_size=4,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
        padding='same'
    ),
    keras.layers.Conv2D(
        filters=64,
        kernel_size=4,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
        padding='same'
    ),
    # Max Pooling으로 데이터의 크기를 줄임
    keras.layers.MaxPool2D(
        pool_size=2,
    ),
    # 앞선 Convolution Layer보다 작은 Receptive Field를 가지고 다수의 필터를 활용하는
    # Convolution Layer 두 개를 연결
    keras.layers.Conv2D(
        filters=128,
        kernel_size=3,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
        padding='same'
    ),
    keras.layers.Conv2D(
        filters=128,
        kernel_size=3,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
        padding='same'
    ),
    # Max Pooling으로 데이터의 크기를 줄임
    keras.layers.MaxPool2D(
        pool_size=2,
    ),
    # Global Pooling으로 데이터를 펼침
    keras.layers.GlobalAveragePooling2D(),
    # Dense Layer들을 연결해서 행동에 대한 가치 함수를 출력
    keras.layers.Dense(
        units=64,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
    ),
    keras.layers.Dense(
        units=32,
        activation=keras.activations.relu,
        kernel_initializer=keras.initializers.HeNormal(seed=42),
    ),
    keras.layers.Dense(
        units=env.action_space.n,
        activation=keras.activations.linear,
        kernel_initializer=keras.initializers.GlorotNormal(seed=42),
   )
])
model.summary()

Model: "sequential_14"
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│ resizing_1 (Resizing)           │ (None, 32, 32, 3)      │             0 │
├─────────────────────────────────┤
│ gray_scale_layer_1              │ (None, 32, 32, 1)      │             0 │
│ (GrayScaleLayer)                │                        │               │
├─────────────────────────────────┤
│ rescaling_1 (Rescaling)         │ (None, 32, 32, 1)      │             0 │
├─────────────────────────────────┤
│ conv2d_1 (Conv2D)               │ (None, 32, 32, 32)     │         2,080 │
├─────────────────────────────────┤
│ max_pooling2d (MaxPooling2D)    │ (None, 16, 16, 32)     │             0 │
├─────────────────────────────────┤
│ conv2d_2 (Conv2D)               │ (None, 16, 16, 64)     │        32,832 │
├─────────────────────────────────┤
│ conv2d_3 (Conv2D)               │ (None, 16, 16, 64)     │        65,600 │
├─────────────────────────────────┤
│ max_pooling2d_1 (MaxPooling2D)  │ (None, 8, 8, 64)       │             0 │
├─────────────────────────────────┤
│ conv2d_4 (Conv2D)               │ (None, 8, 8, 128)      │        73,856 │
├─────────────────────────────────┤
│ conv2d_5 (Conv2D)               │ (None, 8, 8, 128)      │       147,584 │
├─────────────────────────────────┤
│ max_pooling2d_2 (MaxPooling2D)  │ (None, 4, 4, 128)      │             0 │
├─────────────────────────────────┤
│ global_average_pooling2d        │ (None, 128)            │             0 │
│ (GlobalAveragePooling2D)        │                        │               │
├─────────────────────────────────┤
│ dense_7 (Dense)                 │ (None, 64)             │         8,256 │
├─────────────────────────────────┤
│ dense_8 (Dense)                 │ (None, 32)             │         2,080 │
├─────────────────────────────────┤
│ dense_9 (Dense)                 │ (None, 4)              │           132 │
└─────────────────────────────────┘
 Total params: 332,420 (1.27 MB)
 Trainable params: 332,420 (1.27 MB)
 Non-trainable params: 0 (0.00 B)
```

<br>

- Sarsa

```py
import numpy as np
from tensorflow import keras
import tensorflow as tf
from tqdm.auto import tqdm


EPS_MIN, EPS_MAX = 0.1, 1.0
EPISODES_EPS_MAX, EPISODES_EPS_DECREASE, EPISODES_MAX = 300, 1500, 3000
GAMMA = 0.99

random = np.random.default_rng(42)

pbar = tqdm(range(EPISODES_MAX), desc='Episode')

reward_per_episode = []

objective = keras.losses.Huber(
    delta=1.0
)

optimizer = keras.optimizers.Adam(
    learning_rate=0.00025,
    clipnorm=1.0
)

for episode in pbar:
    epsilon = calc_epsilon(
        episode=episode,
        eps_min=EPS_MIN,
        eps_max=EPS_MAX,
        episodes_eps_max=EPISODES_EPS_MAX,
        episodes_eps_decrease=EPISODES_EPS_DECREASE
    )

    obs, _ = env.reset()
    done = False

    state = env.render()
    state = keras.ops.expand_dims(state, axis=0)

    if random.random() < epsilon:
        action = random.choice(np.arange(env.action_space.n))
    else:
        Q = model(state)
        action = random.choice(np.flatnonzero(Q == np.max(Q)))

    avg_loss, avg_reward, steps = 0, 0, 0

    while not done:
        next_obs, _, terminated, truncated, _ = env.step(action)
        done = terminated or truncated

        if obs == next_obs:
            reward = -0.1
        elif next_obs == env.observation_space.n - 1:
            reward = 1.0
        elif done:
            reward = -1.0
        else:
            reward = 0.0

        next_state = env.render()
        next_state = keras.ops.expand_dims(next_state, axis=0)

        if random.random() < epsilon:
            next_action = random.choice(np.arange(env.action_space.n))
        else:
            Q = model(next_state)
            next_action = random.choice(np.flatnonzero(Q == np.max(Q)))

        # Monte Carlo Method는 에피소드가 끝나고 매개변수의 업데이트를 했지만
        # Sarsa는 에피소드 도중에 매개변수의 업데이트를 한다.
        with tf.GradientTape() as tape:
            Q_curr = model(state)[:, action]
            if done:
                Q_next = keras.ops.expand_dims(0.0, axis=0)
            else:
                Q_next = model(next_state)[:, next_action]
            target = reward + GAMMA * Q_next
            loss = objective(target, Q_curr)

        grads = tape.gradient(loss, model.trainable_weights)
        optimizer.apply_gradients(zip(grads, model.trainable_weights))

        avg_loss += loss
        avg_reward += reward
        steps += 1

        obs = next_obs
        state = next_state
        action = next_action

    avg_loss /= steps
    avg_reward /= steps

    pbar.set_postfix(
        eps=f'{epsilon:.5f}',
        loss=f'{avg_loss:.5f}',
        reward=f'{avg_reward:.5f}'
    )

    if len(reward_per_episode) > 5:
        del reward_per_episode[:1]

    reward_per_episode.append(avg_reward)

    if np.mean(reward_per_episode) >= 0.15:
        print('Solved!')
        break
```

<br>

- Agent 구현

```py
from tensorflow import keras
import kymnasium as kym
from typing import Any, Dict
import pickle


class SarsaAgent(kym.Agent):
    def __init__(
            self,
            model: keras.models.Model,
            seed: int = None
    ):
        self.model = model
        self.seed = seed
        self.random = np.random.default_rng(self.seed)

    def save(self, path: str):
        config = {
            'seed': self.seed,
        }
        with open(f'{path}.config', 'wb') as f:
            pickle.dump(config, f)

        keras.models.save_model(
            model=self.model,
            filepath=f'{path}.keras'
        )

    @classmethod
    def load(cls, path: str):
        with open(f'{path}.config', 'rb') as f:
            config = pickle.load(f)

        model = keras.models.load_model(
            filepath=f'{path}.keras'
        )
        return SarsaAgent(model=model, seed=config['seed'])

    def act(self, observation: Any, info: Dict):
        state = keras.ops.expand_dims(observation, axis=0)
        Q = self.model(state)
        action = self.random.choice(np.flatnonzero(Q == np.max(Q)))
        return action
```

- 에이전트 테스트

```py
import matplotlib.pyplot as plt
import tensorflow as tf


agent = SarsaAgent.load('./sarsa-agent')
images = []
done = False

_, info = env.reset()
state = env.render()
images.append(state)

while not done:
    action = agent.act(state, info)
    _, _, terminated, truncated, info = env.step(action)
    state = env.render()
    images.append(state)

    # 종료 여부를 확인
    done = terminated or truncated

print(f'Game Clear w/ {len(images) - 1} Actions')

fig, axes = plt.subplots(len(images), 1, figsize=(5, len(images) * 5))

for i, image in enumerate(images):
    axes[i].imshow(image)
    axes[i].axis('off')

plt.show()
```

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown=   "1">

이 포스팅은 강원대학교 최우혁 교수님의 인공지능 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 