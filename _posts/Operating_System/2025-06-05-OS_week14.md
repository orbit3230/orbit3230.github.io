---
layout: post
title: "[운영체제] 14주차 - Virtual Memory"
excerpt: "Virtual Memory, Demand Paging, Page Fault, Aspects of Demand Paging, Performance of Demand Paging, Copy-on-Write, What Happens if There is No Free Frame?, Page Replacement Algorithms, Trashing, Working Set Model"

tags:
  - [운영체제]

toc: true

date: 2025-06-05
last_modified_at: 2025-06-12
---
## Virtual Memory
- 코드가 실행을 위해 메모리에 올라와야 하나, 전체 프로그램이 사용되는 경우는 드물다.  
  - Error code, unusual routines, large data structures  
- 전체 프로그램 코드를 한 번에 필요로 하지는 않는다.
- 따라서 partially-loaded program을 실행하는 것을 고려해볼 필요가 있다.
  - 프로그램이 더 이상 physical memory의 제한에 의해 제약을 받지 않는다.
  - 각 프로그램이 실행되는 동안 메모리를 덜 잡아먹는다. -> 동시에 더 많은 프로그램을 실행할 수 있다.
    - Response time이나 turnaround time의 향상 없이도 CPU utilization과 throughput을 향상시킬 수 있다.  
  - 프로그램을 메모리로 load하거나 swap하는데 I/O가 더 적게 필요하다. -> 각 유저 프로그램이 더 빠르게 실행될 수 있다.  

<br>

### 1. Virtual Memory  
- **Virtual Memory** - User logical memory를 Physical memory와 분리하는 기술  
  - 오직 프로그램의 일부만 실행을 위해 메모리에 올라올 필요가 있다.
    - 프로그램 코드 전체가 동시에 필요하진 않다.  
    - 따라서, 전체 프로그램이 physical memory에 올라올 필요는 없다.  
  - 그러므로,  Logical address space가 Physical address space보다 훨씬 더 커도 된다.  
  - Address spaces로 하여금 여러 프로세스에 의해 공유될 수 있도록 한다.  
  - 더 효율적인 프로세스 생성을 가능하게끔 한다.
  - 더 많은 프로그램들이 동시에 실행될 수 있다.
  - 프로세스들을 load/swap하는 데 I/O가 더 적게 필요하다.  

  <br>

- **Virtual address space** - 어떻게 프로세스가 메모리에 저장되는지에 대한 logical view  
![Virtual Address Space][def]
  - 일반적으로 주소 `0`에서 시작하고, 연속적인 주소를 갖는다.  
  - 한편, physical memory는 page frames로 구조화된다.  
  - MMU는 반드시 logical->physical로 매핑해야 한다.  

![Virtual Address Space 2][def2]  
  - 일반적으로 logical address는 stack이 Max logical address에서 시작하고 아래로 grow하도록 설계된다.  
    - Address space의 사용량을 극대화한다.  
    - Stack과 heap 사이의 사용되지 않은 address space를 **hole**이라고 한다.  
    - Heap이나 stack이 grow하여 새로운 주어진 page에 도달하기 전까지는, 주어진 page에 대한 **추가적인 physical memory는 필요하지 않다**.

![Virtual Address Space 3][def3]  
  - Hole로 인해 **sparse**한 address space는 추가적인 growth나 dynamically linked libraries 등을 위해 남겨진다.  
  - System libraries는 virtual address space로의 매핑을 통해 공유된다.  
  - Read-write 가능한 pages를 virtual address space로 매핑함으로써 Shared memory를 구현할 수 있다.  
  - Pages는 `fork()` 호출을 통해 공유될 수 있고, 프로세스 생성을 더 효율적으로 만든다.  

<br>

### 2. Demand Paging  
- Virtual Memory는 **Demand Paging** 기법을 사용하여 구현된다.
- OS는 전체 프로세스를 load time에 메모리에 가져올 수 있다.
- 또는, 필요할 때만 메모리에 page를 가져올 수 있다.  
![Demand Paging][def4]  
  - 더 적은 I/O가 필요하고, 불필요한 I/O가 없다.
  - 더 적은 메모리가 필요하다.
  - 더 빠른 response
  - 더 많은 사용자
- Swapping을 포함한 paging system과 유사하다.  
- Invalid reference -> abord
  - Not-in-memory -> bring to memory
- **Lazy swapper** : 페이지가 필요하지 않다면, 절대 메모리로 swap하지 않는다.  
  - pages를 다루는 Swapper를 **pager**라고 한다.

- Demand paging 기법으로, 프로세스가 실행되는 동안 어떤 page는 메모리에, 어떤 page는 secondary storage에 위치할 수 있다.  
- 이 둘을 어떻게 구별할 수 있을까?
- Demand paging을 구현하기 위해서는 새로운 MMU 기능이 필요하다.  
- 이미 필요한 page가 **메모리에 있다**면,  
  - Non demand paging과 다를 게 없다.
- 그러나 필요한 page가 **메모리에 없다**면,  
  - 이를 탐지하고, storage에서 메모리로 page를 가져와야 한다.
    - 프로그램 동작에는 변화 없이
    - 프로그래머의 코드 변화 필요 없이
- 이를 위해서 **valid-invalid bit**를 포함한 Page table을 사용한다.    

- 각 Page table entry와 함께, valid-invalid 비트가 짝지어진다.  
  - `v` -> in-memory
  - `i` -> not-in-memory
- 초기에는 모든 entries에 대해 valid-invalid 비트가 `i`로 설정된다.  
- Example of a page table snapshot  
![Page Table Snapshot][def5]  

- 몇몇 pages가 메모리에 있지 않은 Page table Example  
![Page Table Example][def6]  

<br>

### 3. Page Fault  
- 프로세스가 메모리에 존재하지 않는 page에 접근할 때, page fault trap이 발생한다.  
  - Paging hardware는 Page table을 사용하여 주소를 변환하는 동안, invalid bits를 감지하여 OS에 trap을 발생시킨다.  

- Page fault를 다루는 단계  
  - (1) 만약 page에 대한 reference가 존재한다면, 해당 page에 대한 첫 번째 reference가 OS에 trap을 발생시킨다.
    - page fault
  - (2) OS는 다른 table을 살펴본다.
    - Invalid reference -> abort
    - 메모리에 없음 -> (go to step 3)
  - (3) Free frame을 찾는다. (만약 없다면?)
  - (4) 예약된 disk operation을 통해 page를 frame으로 swap한다.
  - (5) 이제 메모리에 온 page를 보이기 위해, table을 reset한다.  
    - validation bit를 `v`로 설정
  - (6) Page fault를 유발한 instruction을 다시 실행한다.  

![Page Fault Steps][def7]  

<br>

### 4. Aspects of Demand Paging
- **Pure demand paging** : 프로세스가 시작할 때는 어떤 page도 메모리에 올라오지 않는다.  
  - OS는 instruction pointer를 프로세스의 첫 번째 instruction으로 설정하고, 이는 non-memory-resident -> **page fault**를 발생시킨다.  
  - 그리고 모든 다른 프로세스 pages의 첫 번째 access는 page fault를 발생시킨다.  

- 실제로, 주어진 instruction은 여러 pages를 액세스할 수 있다. -> multiple page faults  
  - 두 개의 숫자를 메모리에서 얻어와 더하고, 다시 메모리에 저장하는 instruction을 생각해보자.  

- Demand paging은 hardward support를 필요로 한다.
  - Valid-invalid bits를 포함한 Page table
  - **swap space**를 포함한 Secondary storage
  - Instruction restart  

<br>

- Stages in Demand Paging - Worse Case  
  - (1) Operation에 Trap 발생
  - (2) 유저 레지스터와 프로세스 상태 저장 (e.g., PCB)  
  - (3) Interrupt가 page fault였음을 Determine
  - (4) Page reference가 legal 했는지 확인, 그리고 disk에서 page의 위치를 Determine
  - (5) Disk를 읽어 Free frame을 탐색
    - (a) Read request가 서비스되기 전까지 queue에 대기
    - (b) Device seek and/or latency time동안 대기
    - (c) Page를 free frame으로 보내기 시작
  - (6) 기다리는 동안, CPU를 다른 유저에게 할당
  - (7) Disk I/O subsystem으로부터 I/O 완료 interrupt를 수신
  - (8) 다른 유저에 대한 레지스터와 프로세스 상태를 저장
  - (9) Interrupt가 Disk에서 왔음을 Determine
  - (10) Page가 이제 메모리에 있음을 보이기 위해 Page table을 업데이트
  - (11) CPU가 할당되기를 기다림
  - (12) 유저 레지스터와 프로세스 상태, 새로운 page table을 복원하고, interrupted instruction을 다시 실행  

<br>

### 5. Performance of Demand Paging
- 세 가지 주요 activities
  - Service the interrupt : careful coding은 단 몇백개의 instruction이 필요함을 의미한다.  
  - Input the page from disk : lots of time
  - Restart the process : 또 다시 적은 양의 시간이 필요하다.  

- **Page Fault Rate** `0 <= p <= 1`  
  - 만약 `p = 0`이면, no page fault
  - 만약 `p = 1`이면, 모든 reference가 page fault

- Effective Access Time (EAT)  
`EAT = (1 - p) * memory access + p (page fault overhead + swap page out + swap page in)`  

<br>

- Example
  - Memory access time = `200` ns
  - Average page-fault service time = `8` ms
  - EAT = `(1 - p) * 200 + p * (8,000,000)`  
  = `200 + p * 7,999,800` ns

  - 만약 `1000`번 중 `1`번의 page fault가 발생한다면,  
  EAT = `8.2` ms  
    - 약 `40`개의 요소 만큼의 slowdown !!
  
  - 만약 performance degradation < `10`%를 원한다면,  
    - `220` > `200 + p * 7,999,800`  
    - `p < 0.0000025`  
      - 즉, `400,000`번 중 `1`번의 page fault가 발생해야 한다.  

<br>

- **Demand Paging Optimizations**  
  - 심지어는 같은 디바이스 내에서도, Swap space I/O는 file system I/O보다 더 빠르다.
    - Swap space가 더 큰 chunks에 할당되고, file system보다 관리가 간단하다.  
  - 프로세스 로드 시간에 전체 프로세스 이미지를 swap space로 copy
    - 그리고 나서 swap space에서 page in/out을 수행한다.
    - 구 BSD Unix에서 사용되었다.
  - Disk의 실행파일에서 직접 demand paging하고, frame을 비울 때는 swapping을 하지 않고 버린다.
    - Solaris와 BSD에서 사용된다.
    - 그러나 여전히 swap space에 write해야 할 필요는 있다.  
      - 파일과 연결되지 않은 Pages (like 스택, 힙) - **anonymous memory**
      - 메모리에서 수정되었으나, 아직 file system에 저장되지 않은 Pages  
  - Mobile systems  
    - 일반적으로 swapping을 지원하지 않는다.  
    - 대신, 파일 시스템에서 직접 demand paging하고,  read-only pages(e.g., code)는 그냥 버리고 필요 시 다시 읽어온다.  

    <br>

### 6. Copy-on-Write
- **Copy-on-Write**(COW)는 부모 프로세스와 자식 프로세스들이 모두 초기에 메모리의 같은 pages를 **공유**하도록 한다.  
  - Remind
    - `fork()` -> 부모 프로세스에 속하는 pages를 복제
    - `exec()` -> 자식 프로세스의 binary를 pages에 overwrite  
  - 만약 프로세스가 shared page를 수정하려고 하면, page가 복사되어 분리된다.  

- COW는 오직 pages를 수정했을 때에서야 분리되도록 하여 더 효율적인 프로세스 생성을 가능하게 한다.  
![COW][def8]  

<br>

- 일반적으로, free pages는 **zero-fill-on-demand** pages(내용이 모두 `0`으로 초기화된 페이지)의 **pool**로부터 할당된다.  
  - Pool은 반드시 빠른 demand page execution을 위해 항상 free frames를 가지고 있어야 한다.
    - Page fault를 처리함과 동시에 frame을 `0`으로 초기화하길 원하지 않기 때문이다.  
  - 왜 할당하기 전에 page를 zero-out 해야하는가?
    - For security reason.  
    이전에 다른 프로세스가 사용하던 메모리의 데이터를 읽지 못하도록 하기 위해서. 
    - 그러나 GPU 메모리는 zero-out하지 않아 그대로 남아있는 문제가 많다.  

<br>

### 7. What Happens if There is No Free Frame?  
- 프로세스 pages로 인해 다 소진되어 버렸다.

- kernel이나 I/O buffer 등에서도 pages를 필요로 한다.  

- 각각에 얼마나 할당해줘야 하는가?
  - 만약 우리가 multiprogramming의 degree를 늘린다면, 우리는 memory를 **over-allocating**하고 있는 것이다.  

- Page replacement가 필요하다. - 즉, 잘 쓰이지 않는 page를 찾아서 page it out.
  - Algorithm - 중단할 것인가? swap out할 것인가? replace할 것인가?  
  - Performance - page fault의 수를 최소화하는 알고리즘을 찾아야 한다.  

- 몇몇 page는 memory에 여러 번 가져와질 수 있다.  

![No Free Frame][def9]

<br>

- **Basic page replacement**  
![Basic Page Replacement][def10]
  - (1) 디스크에서 원하는 page의 위치를 찾는다.
  - (2) free frame을 찾는다.
    - 만약 free frame이 있다면, 사용한다.  
    - 만약 free frame이 없다면, **victim frame**을 선택하기 위해 replacement algorithm을 사용한다.  
  - (3) 원하는 page를 (새로운) free frame으로 가져와서, page와 frame table을 업데이트한다.  
  - (4) Trap에 걸려있던 명령어를 재시작함으로서, 프로세스를 계속 실행한다.  

  - 이제 잠재적으로 page fault에 대해 **2 page transfer**가 필요할 수 있다.  
    - 하나는 page-out을 위해, 하나는 page-in을 위해.  
    - EAT가 증가한다.    

<br>

- **Page replacement**  
  - Page-fault service routine이 Page replacement를 포함하도록 수정하여, memory의 over-allocation을 방지한다.  
  - Modify(**dirty**) bit를 사용하여, page transfer의 overhead를 최소화한다.  
  -> 즉, 페이지가 메모리에서 수정되었는지 여부를 나타낸다.  
  -> 만약 dirty bit가 `0`이면, 현재 디스크와 동일하므로 그냥 버리면 된다.  
  -> 만약 dirty bit가 `1`이면, 수정되었으므로 디스크에 저장 후 버려야 한다.  

  - Page replacement는 Logical memory와 Physical memory를 분리하는 Virtual Memory의 핵심이다.  
  -> 이를 통해 virtual memory는 더 작은 physical memory에서 제공될 수 있다.  

<br>

### 8. Page Replacement Algorithms  
- **Frame-allocation algorithm**은,  
  - 각 프로세스에 주어질 frame의 수를 결정한다.
  - 어떤 frame이 replace될 지를 결정한다.  

- **Page replacement algorithm**은,  
  - first access와 re-access 모두에서 가장 낮은 page-fault rate를 원한다.  

- Memory reference를 나타내는 특정 string에 대해 실행해보고, 해당 string에 대한 page fault의 수를 계산함으로써 알고리즘을 평가한다.  
  - string은 단순 page number sequence이다.
  - 같은 page에 대한 repeated access는 page fault를 발생시키지 않는다.  
  - 결과는 available frames의 수에 따라 달라진다.  

- 일반적으로, page faults와 # of frames의 관계는 다음과 같다.  
![Page Faults vs # of Frames][def11]  

<br>

#### [1] First-In-First-Out (FIFO) Algorithm
- Reference string : `7`,`0`,`1`,`2`,`0`,`3`,`0`,`4`,`2`,`3`,`0`,`3`,`0`,`3`,`2`,`1`,`2`,`0`,`1`,`7`,`0`,`1`

  - `3` frames (각 프로세스 당 한 번에 `3`개의 pages가 메모리에 올라올 수 있다.)  
  ![Page Replacement FIFO][def12]  
  -> `15` page faults  

  - 이해하기 쉽지만 성능이 항상 좋지는 않다.  

<br>

#### Belady's Anomaly  
- 우리는 프로세스에 더 많은 메모리를 부여하는 것이 성능을 향상시킬 것이라 생각한다.  
그러나, 이는 항상 true는 아니다.  

- 다음과 같은 string을 고려해보자 : `1`,`2`,`3`,`4`,`1`,`2`,`5`,`1`,`2`,`3`,`4`,`5`  
  - 더 많은 frames를 추가하는 것은 더 많은 page faults를 발생시킬 수 있다 !

- 이에 대한 그래프가 Belady's Anomaly를 보여준다.  
![Belady's Anomaly][def13]

<br>

#### [2] Optimal Algorithm
- 앞으로 가장 오랜 기간동안 사용되지 않을 page를 replace한다.  
![Optimal Algorithm][def14]  
  - `9` page faults  

- 이는 구현하기 어렵다. 우리는 미래를 읽을 수 없기 때문이다.  

- 가장 최적화된 알고리즘이기에, 얼마나 알고리즘이 최적화되었는지에 대한 기준이 된다.  

<br>

#### [3] Least Recently Used (LRU) Algorithm
- Optimal algorithm의 approximation이다. 미래 대신, 과거에 대한 정보를 사용한다.  

- 가장 오랫동안 사용되지 않은 page를 replace한다.  
![LRU Algorithm][def15]  
  - `12` page faults - FIFO보다는 낫지만, Optimal보다는 worse이다.  

- 일반적으로 훌륭한 알고리즘이고, 자주 사용된다.  

- LRU는 **stack algorithm**의 예시 중 하나이다. 따라서, Belady's Anomaly의 영향을 받지 않는다.  
  - **stack algorithm** : **locality**를 고려하는 알고리즘  

<br>

- LRU Algorithm Implementation  
  - (1) Time-counter implementation
    - **각각의 page entry**가 time-counter 변수를 갖는다.  
    매 시간 page는 entry를 통해 참조되며, 현재 시간 값이 time-counter에 copy된다.  
    - page가 replace될 때, time-counter를 비교하여 가장 작은 값을 찾는다. (오래된 page를 찾는다.)  
      - table search가 필요하다.  

  - (2) Stack implementation  
  ![LRU Stack Implementation][def16]  
    - page number의 stack을 double linked list 형태로 유지한다.  
    - Page가 참조되면,  
      - 해당 page를 top으로 이동시킨다.
      - 이렇게되면, `6`번의 pointer 변경이 필요하다.  
      (`prev` x `3` / `next` x `3`)  
    - 각 Update가 더 expensive하지만, search는 필요가 없다.  

<br>

### 9. Trashing
- 만약 프로세스가 "충분한" frames를 받지 못한다면, page-fault rate가 매우 높아질 수 밖에 없다.  
  - page를 얻기 위해 page fault
  - 기존 frame을 replace
  - 그러나 가까운 미래에 또 replace back

- 이는 다음으로 이어진다.  
  - 낮은 CPU utilization
  - 운영체제는 multiprogramming의 degree를 늘려야 할 필요가 있다고 생각한다.  
  - 다른 프로세스가 시스템에 추가된다.  

- **Trashing** : 프로세스가 제대로 실행되지 못하고, 계속해서 바쁘게 swapping pages in and out.  
![Trashing][def17]  

<br>

- Demand paging은 왜 효과적인가?
  - **Locality model**
    - 프로세스가 실제로 사용하는 프레임의 수 만큼만 on memory.
    - 프로세스가 실행되는 동안,, 프로세스는 한 locality에서 다른 locality로 이동.    
  - Memory footprint  
  ![memory footprint][def18]  

<br>

- 왜 Thrashing이 일어나는가?
  - `프로세스 locality size의 Summation` > `전체 memory size`  

- 만약 현재 locality size를 수용할 만큼 충분한 frames를 할당하지 않으면, 프로세스는 thrash될 것이다.  

- Thrashing을 피하기 위해서는,
  - 프로세스 locality size의 합을 계산한다.
  - Policy
    - 만약 `프로세스 locality size의 합` > `전체 memory size`라면,  
    -> 프로세스 중 하나를 suspend 하거나 swap out한다.  

- Issue : 어떻게 "프로세스 locality size의 합"을 계산하는가.  

<br>

### 10. Working Set Model  
- `Δ`(delta) ≡ working-set window ≡ 고정된 수의 page references

- Working-set model은,  
  - locality의 추정을 기반으로 한다.
  - 이에 대한 접근법은, 가장 최근 `Δ` page references를 고려하는 것이다.  

- Working-set은 가장 최근 `Δ` page references의 page 집합이다.  
![moving window][def19]
  - 만약 `Δ`=`10`이면, `t`<sub>`1`</sub>에 대한 `WS`는 `{1, 2, 5, 6, 7}`  
  - 만약 `Δ`=`10`이면, `t`<sub>`2`</sub>에 대한 `WS`는 `{3, 4}`
  - a.k.a. "a moving window"  

<br>

- Working sets와 page faults rate
![working set and page fault][def20]  
  - 프로세스의 working set과 page fault rate는 직접적인 관계가 있다.  
  - Working set이 시간에 따라 변화하면서, Peak와 Valley가 발생한다.  

<br>

- `WSS`<sub>`i`</sub> = 최근 `Δ` time 동안 referenced된 page의 총 개수  
  - 만약 `Δ`가 너무 작다면, 전체 locality를 포함하지 못할 수 있다.  
  - 만약 `Δ`가 너무 크다면, 여러 개의 localities나 전체 프로그램을 포함해버릴 수 있다.
  - `D` = `∑ WSS`<sub>`i`</sub>≡ 전체 demand frames  
    - Approximation of locality  
  - `m` = frames의 총 개수  
  - 만약 `D` > `m` -> Thrashing  
  - `D` > `m`일 때의 Policy  
    - 프로세스들 중 하나를 suspend하거나 swap out  
    - 또는 불필요한 경우 더 많은 frames 할당  

<br>

- Working set 추적하기  
  - interval timer + a reference bit로 추정한다.  
  - Example : `Δ`=`10000` references
    - timer가 `5000` references마다 interrupt를 발생시킨다고 가정한다.
    - 각 Page에 대해 `2`bits를 둔다.
      - `B1` -> 이전 구간 (`10000` references)  
      - `B2` -> 현재 구간 (`15000` references)  
    - Timer가 interrupt를 발생시키면,  
      - 각 페이지의 reference bit를 확인하여, 해당 페이지가 최근에 접근되었는 지를 `B1`또는 `B2`에 기록
      - 그리고, reference bit를 모두 `0`으로 초기화 (다음 구간 추적을 위해)
    - 만약 `B1`또는 `B2`가 `1`이라면, 해당 페이지는 working set에 속한다.  

  - 만약 history bits의 수나 interrupt의 빈도를 늘리면, 정확도 또한 증가할 것이다.  
    - e.g., `10` bits & `1000` references마다 interrupt 발생  

<br>

### 11. Page-Fault Frequency  
- Working-set model은 성공적이고 유용하지만, Thrashing을 컨트롤하기엔 부족한 방법처럼 보인다.

- **Page-Fault Frequency**(PFF)는 Thrashing을 다루는 더 직접적인 접근법이다.  
![Page-Fault Frequency][def21]
  - Rationale  
    - Threshing은 높은 page-fault rate를 가진다.
    - 만약 rate가 너무 높으면, 프로세스가 더 많은 frames를 필요로 한다고 본다.
    - 반대로 rate가 너무 낮으면, 프로세스가 너무 많은 frames를 가지고 있다고 본다.  

  - 원하는 page-fault rate에 **upper**와 **lower** bounds를 둔다.  
    - 만약 실제 page-fault rate가 upper bound를 초과한다면, 프로세스에 더 많은 frames를 할당한다.
    - 만약 lower limit 아래로 떨어진다면, 프로세스로부터 frames를 회수한다.  
    - 따라서, 우리는 thrashing을 방지하기 위해 직접적으로 page faults rate를 측정하고 컨트롤할 수 있다.  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">  

이 포스팅은 강원대학교 송원준 교수님의 운영체제 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.  

</div>
</details>

[def]: https://i.imgur.com/cmHA2aj.png
[def2]: https://i.imgur.com/hs47XRb.png
[def3]: https://i.imgur.com/MxgsvPn.png
[def4]: https://i.imgur.com/j67RFrI.png
[def5]: https://i.imgur.com/hHraXgP.png
[def6]: https://i.imgur.com/S5pmhlu.png
[def7]: https://i.imgur.com/tUlPNF1.png
[def8]: https://i.imgur.com/xL0Gdv2.png
[def9]: https://i.imgur.com/AMEHxVH.png
[def10]: https://i.imgur.com/5Q6oxNI.png
[def11]: https://i.imgur.com/Vud6Llb.png
[def12]: https://i.imgur.com/zFHqDrG.png
[def13]: https://i.imgur.com/m6f6nP6.png
[def14]: https://i.imgur.com/zhWssEc.png
[def15]: https://i.imgur.com/YkZLZnj.png
[def16]: https://i.imgur.com/9Oh3Yhq.png
[def17]: https://i.imgur.com/wvrleZM.png
[def18]: https://i.imgur.com/rYvrfsV.png
[def19]: https://i.imgur.com/AUs0sMI.png
[def20]: https://i.imgur.com/GwhngjW.png
[def21]: https://i.imgur.com/TA8x5zM.png