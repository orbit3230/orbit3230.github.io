---
layout: post
title: "[운영체제] 7주차 - CPU Scheduling"
excerpt: "CPU Scheduler, Preemptive / Non-Preemptive, Scheduling Algorithms, Thread Scheduling, Multiple-processor Scheduling"

tags:
  - [운영체제]

toc: true

date: 2025-04-14
last_modified_at: 2025-04-24
---
## CPU Scheduling
- CPU 또한 OS에 의해 관리되어야 하는 컴퓨터 리소스들 중 하나이다.  
- **CPU utilization을 최대화**
- CPU가 항상 바쁘게 일하도록 유지해야 한다.
- CPU-I/O burst Cycle  
![CPU-I/O burst Cycle][def]  
  - 프로세스 실행은 CPU execution과 I/O wait **cycle**로 이루어져 있다.
  - CPU burst 분배가 주요 관심사가 된다.  
- Multiprogramming을 가능하게끔 한다.  
- 용어 (모두 같은 의미)
  - CPU scheduling
  - Process scheduling
  - Kernel thread scheduling

<br>

- CPU-burst 패턴을 분석해보면, 아래와 같은 그래프로 나타난다.  
![CPU-burst][def2]
  - 많은 수의 짧은 CPU burst
  - 적은 수의 긴 CPU burst
  - 이 분포는 CPU-schedular 알고리즘을 구현할 때 중요하다.  

  <br>

### 1. CPU Scheduler
- **CPU schedular**는 ready queue에 있는 프로세스 중에서 하나를 선택하여, CPU 코어에게 할당해주는 역할을 한다.  
  - Queue는 다양한 방식으로 정렬되어 있을 수 있다.  

- CPU scheduing decision은 크게 네 가지 순간에 이루어진다.  
  - (1) running -> waiting (I/O burst)
  - (2) running -> ready
  - (3) waiting -> ready
  - (4) Terminates

- (1)과 (4) 상황의 경우, 반드시 새로운 프로세스가 할당이 되어야 한다. (no choice)
- 그러나 (2)와 (3)의 경우, There is a choice.

<br>

### 2. Preemptive / Non-Preemptive
- 스케쥴링이 (1)번과 (4)번 상황에서 이루어질 때, Scheduling scheme은 **non-preemptive**이다.

- 그렇지 않으면, **preemptive**이다.  

- Non-preemptive scheduling 하에서, 일단 CPU가 프로세스에 할당되었다면 프로세스는 CPU가 terminating or waiting 상태가 되어 놓아줄 때까지 CPU를 점유한다.

- 그래서 거의 모든 현대 OS들은 preemptive scheduling을 사용한다.

<br>

- **Preemptive Scheduling과 Race Conditions**
  - Preemptive Scheduling은 Race Condition을 유발할 수 있다.
  - 두 프로세스가 같은 데이터를 공유하고 있는 경우를 고려해보자.  
  일단 한 프로세스가 데이터를 업데이트하면, preempted되므로 두 번째 프로세스가 동작할 수 있다.  
  두 번째 프로세스가 그 데이터를 읽으려고 하면, 그 데이터는 일관되지 않은(inconsistent) 상태가 된다.  
  - 이 Issue에 대해서는 Chapter 6에서 자세히 다룬다.  

<br>

### 3. Scheduling Algorithms
- **Dispatcher** 모듈은 CPU 스케쥴러에 의해 선택된 프로세스에게 CPU의 제어를 넘겨주는 역할을 한다; this involves  
  - switching context
  - switching to user mode
  - jumping to the proper location  

- **Dispatch latency** : Dispatcher가 한 프로세스를 중지하고 다른 프로세스를 시작하는 데 걸리는 시간.  
![Dispatch latency][def3]  

<br>

- **Scheduling Criteria**
  - **CPU utilization** : CPU가 가능한 바쁘게 일하도록 하는 것
  - **Throughput** : unit time에 execution을 완료한 프로세스의 수
  - **Turnaround time** : 특정 프로세스가 execute 하는데 걸린 총 시간 (CPU 사용, waiting in I/O, ready queue 모두 포함)
  - **Waiting time** : 프로세스가 ready queue에서 기다린 총 시간
  - **Response time** : request가 제출되고, 첫 response가 돌아오기까지 걸린 시간.   

<br>

- CPU Scheduling 알고리즘
  - "CPU"라는 분야는 정했지만, 어느 프로세스가 ready queue에 있을 지, CPU 코어에 할당될 지에 대한 질문이 남아있다.  
  -> CPU scheduilng에 대한 알고리즘이 필요하다.

- **First-Come, First-Serverd (FCFS)**
- **Shortest Job First (SJF)**
- **Priority Scheduling**
- **Round Robin Scheduling (RR)**

- Scheduling 알고리즘을 비교하기 위해, 우리는 주로 평균 대기 시간을 metric으로 사용한다.  

#### [1] First-Come, First-Served (FCFS)
- CPU에 먼저 request한 프로세스가 CPU에 먼저 할당된다.
- FCFS 알고리즘은 FIFO queue structure를 사용해 쉽게 구현할 수 있다.  
![FCFS][def4]  
  - 프로세스가 ready queue에 들어오면, 프로세스의 PCB가 FIFO 구조의 시작부분에 삽입된다.
  - CPU가 idle 상태가 되면, FIFO 구조의 끝에 있는 PCB가 CPU에 할당된다.  

- 세 개의 프로세스가 `P1`, `P2`, `P3` 순서대로 도착했다고 가정하자.  
![FCFS_example][def5]  

- Gantt char는 특정한 스케쥴링을 표현하는, 각 프로세스의 시작 시간과 끝 시간을 포함하는 바 차트이다.
- 위에 대한 Gantt chart는 아래와 같다.  
![FCFS_Gantt][def6]  
- 각 프로세스에 대한 Waiting time은, `P1 = 0`, `P2 = 24`, `P3 = 27`  
- **평균 대기 시간** = `(0 + 24 + 27)` / `3` = `17`

<br>

- 그런데 만약 프로세스들이 `P2`, `P3`, `P1` 순서로 도착했다고 가정해보자.   

- 그렇다면 Gantt chart는 아래와 같다.  
![FCFS_Gantt2][def7]  

- 각 프로세스에 대한 Waiting time은, `P1 = 6`, `P2 = 0`, `P3 = 3`
- **평균 대기 시간** = `(6 + 0 + 3)` / `3` = `3`   
- 이전 케이스보다 훨씬 좋다.
- **Convoy effect** : 짧은 프로세스들이 긴 프로세스에 의해 뒤에서 대기하는 현상.  

<br>

- FCFS Scheduling 알고리즘은 **non-preemptive**이다.  
  - 일단 CPU가 프로세스에 할당되면, 그 프로세스는 CPU를 점유한다.
  - Interactive system에서는 문제가 될 수 있다.  

<br>

- Example  
![FCFS_example2][def8]  

<br>

#### [2] Shortest Job First (SJF)  
- 이 알고리즘은 각 프로세스의 다음 CPU burst time의 길이와 관련이 있다.
- CPU에 다음 CPU burst time이 가장 짧은 프로세스를 할당한다.  
- SJF 알고리즘은 주어진 프로세스 집합에 대한 minimum average waiting time을 보장한다.  

<br>

- 다음과 같은 CPU burst를 가진 프로세스 집합을 가정해보자.  
![SJF_example][def9]  

- 위 의 프로세스 집합에 대해, SJF 알고리즘을 적용하면 아래와 같은 Gantt chart가 나온다.  
![SJF_Gantt][def10]  

- **평균 대기 시간** = `(0 + 3 + 9 + 16)` / `4` = `7`  
  - 참고로 FCFS 알고리즘으로는 `10.25`ms !  

<br>

- Non-preemptive vs. Preemptive
  - Non-preemptive SJF - 만약 CPU가 프로세스에 할당되면, 오직 프로세스가 CPU burst를 완료할 때까지 CPU를 점유한다.
  - Preemptive SJF - 만약 도착한 프로세스가 shortest-next-CPU burst라면, 현재 CPU를 사용하던 프로세스는 CPU 점유를 놓아주고 도착한 프로세스가 CPU를 점유한다.  
  -> a.k.a, **Shortest Remaining Time First (SRTF)**  

<br>

- non-preemptive SJF 스케쥴링의 Example  
![SJF_example2][def11]  
  - Burst time이 같다면, Arrival time이 빠른 것을 우선

- Gantt chart는 아래와 같다.  
![SJF_Gantt2][def12]  

- **평균 대기 시간** = `(0 + 6 + 3 + 7)` / `4` = `4`  

<br>

- Preemptive SJF 스케쥴링의 Example  
![SJF_example3][def13]  

- Gantt chart는 아래와 같다.  
![SJF_Gantt3][def14]  

- **평균 대기 시간** = `(9 + 1 + 0 + 2)` / `4` = `3`  

<br>

- Example of Preemptive SJF  
![SJF_example4][def15]  

- Example of Non-preemptive SJF  
![SJF_example5][def16]  

<br>

- SJF Scheduling의 단점 - next CPU burst가 얼마인 지 어떻게 아는가 ?!  
-> 다음 CPU burst를 알 수 있는 방법은 없다. 하지만..

- length를 추정하는 것이다. 즉, 이전 것과 비슷할 것이라고 가정하는 것이다.  
  - 그리고는 가장 CPU burst가 짧을 것이라 예측한 프로세스를 고른다.

- 지수 평균을 사용해, 이전 CPU bursts의 길이를 기반으로 이루어질 수 있다.  
  - (1) `t`<sub>`n`</sub> = `n`th의 실제 CPU burst time
  - (2) `𝜏`<sub>`n+1`</sub> = `n+1`th의 예측한 CPU burst time
  - (3) `𝛼`, `0 <= 𝛼 <= 1`
  - (4) Define:

- 일반적으로, `𝛼` set `𝜏`<sub>`n+1`</sub> = `𝛼t`<sub>`n`</sub>+`(1 - 𝛼)𝜏`<sub>`n`</sub>

- 다음 CPU burst의 길이 예측 Example  
![SJF_example6][def17]  

<br>

- SJF 알고리즘의 실제 사용 예  
  - "Information-Agnostic Flow Scheduling for Commodity Data Centers", Wei Bai, et al., USENIX NSDI, 2015  
  ![SJF_example7][def18]  
  ![SJF_example8][def19]

  - "DRAM Scheduling Policy for GPGPU Architectures Based on a Potential Function”, Nagesh, et al., IEEE CAL, 2012  
  ![SJF_example9][def20]  
  ![SJF_example10][def21]  

  <br>

#### [3] Round Robin (RR)
- 각 프로세스는 작은 unit CPU time (**time quantum** `q`) 동안 CPU를 점유한다.  
이는 주로 10-100ms 정도이며, 이 시간이 끝나면 프로세스는 preempted되고, ready queue의 끝에 삽입된다.  

- `n`개의 프로세스가 ready queue에 있고 time quantum이 `q`라고 하면,  
각 프로세스는 CPU time의 `1/n` 정도를 사용할 수 있고, 어떠한 프로세스도 `(n-1)q`보다 더 많은 CPU time을 사용할 수 없다.  

- Timer는 매 quantum마다 다음 프로세스를 스케쥴링 하기 위해 interrupt를 발생시킨다.  

- 성능은 time quantum의 크기에 크게 의존한다.  
  - 만약 `q`가 극도로 크다면 -> FCFS와 같아진다.
  - 만약 `q`가 극도로 작다면 -> context switch가 너무 많이 발생하여, overhead가 너무 커진다.  

<br>

- 다음과 같은 CPU burst를 가진 프로세스 집합을 가정해보자.  
![RR_example][def22]  

- 위 의 프로세스 집합에 대해, RR 알고리즘을 적용하면 아래와 같은 Gantt chart가 나온다.  
![RR_Gantt][def23]  

- 일반적으로 SJF의 평균 소요 시간보다 크다. (e.g., context-switching overhead)  
하지만, 더 나은 **Response**를 제공한다.  

- `q`는 context switch time과 비교했을 때, 충분히 커야 한다.  
  - `q`는 일반적으로 10-100ms 정도이다.
  - Context switch time은 10ms보다 작다.  

<br>

- Time Quantum and Context Switch Time  
![RR_example2][def24]  
  - 프로세스의 CPU burst time이 `10`이라고 해보자.  
    - 만약 time slice가 `12`라면, 프로세스는 CPU를 계속 점유하여 context-switch overhead가 발생하지 않는다.
    - 만약 time slice가 `1`이라면, 프로세스는 총 `9`번의 context switch를 해야 한다.  

    <br>

- 소요 시간은 time quantum에 따라 달라진다.  
![RR_example3][def25]  
  - time-quantum size의 증가는 평균 소요시간 향상에 크게 중요하지 않다.
  - 평균 소요시간은 대부분의 프로세스가 single time quantum에 완수될 때에 향상된다.
  - 대체로 80%의 CPU bursts는 time quantum `q`보다 짧아야 한다.  

<br>

#### [3] Priority Scheduling  
- 각 프로세스와 관련된 priority number가 있다.  

- CPU는 가장 우선순위가 높은 프로세스에 할당된다.  
(여기서는 `0`이 가장 높은 우선순위라고 가정한다.)
  - Preemptive
  - Non-preemptive -> 새로운 프로세스를 ready queue의 헤드에 삽입  

- SJF는 우선순위가 예측한 다음 CPU burst time의 역순인 Priority scheduling의 특수한 경우이다.  

- 문제 : **Starvation** - 낮은 우선순위의 프로세스가 쫄쫄 굶는다.

- Solution : **Aging** - 시간이 지남에 따라 프로세스의 우선순위를 높인다.  

<br>

- 다음과 같은 CPU burst를 가진 프로세스 집합을 가정해보자.   
![Priority_example][def26]  

- 위 의 프로세스 집합에 대해, Priority scheduling 알고리즘 (Non-preemptive) 을 적용하면 아래와 같은 Gantt chart가 나온다.  
![Priority_Gantt][def27]

<br>

#### [4] Multi-level Queue
- Single queue 구조에서, 가장 높은 우선수위를 가진 프로세스를 결정하는 데 `O(n)`의 탐색이 필요하다.  

- Priority Scheduling과 함께, 각 우선순위에 대한 각각의 queue를 가지는 방식이다.  

- highest-priority queue에서 프로세스를 스케쥴링하자 !  
![Multi-level Queue][def28]  

- 우선순위 결정은 프로세스 타입에 기반한다.  

- Examples
  - 두 개의 queue로 이루어진 Multi-level queue scheduling algorithm
    - foreground(interactive) 프로세스를 위한 queue
    - background(batch) 프로세스를 위한 queue  

  - 네 개의 queue로 이루어진 Multi-level queue scheduling algorithm  
  ![Multi-level Queue2][def29]  

  <br>

- 디자인에 따라 queue 스케쥴링을 결정한다.  
  - **Fixed-priority scheduling**
    - 각 queue는 정해진 우선순위를 가진다.
    - e.g., 낮은 우선순위의 큐 내 프로세스는 오직 높은 우선순위의 큐가 비어있을 때만 CPU를 점유할 수 있다.  

  - **Time slice scheduling**
    - 각 queue에는 가중치가 부여될 수 있고, CPU는 가중치에 따라 스케쥴링된다.
    - e.g., foreground queue가 80%의 CPU time을 점유하는 반면, background queue는 20%의 CPU time을 점유할 수도 있다.  

- 각 queue는 자신만의 scheduling algorithm을 가질 수 있다.  
  - e.g., multi-level queue의 모든 queues가 RR scheduling algorithm을 사용할 수도 있다.
  - e.g., 가장 높은 우선순위의 큐만 RR을 사용하고, 가장 낮은 우선순위의 큐는 FCFS를 채택할 수도 있다.  

  <br>

#### [5] Multi-level Feedback Queue
- multi-level queue는 스케쥴링 overhead가 작다는 장점이 있지만, **Inflexible**하다. (e.g., starvation)

- **Multi-level feedback queue**는 가장 general한 CPU-scheduling 알고리즘이다.  

- 프로세스가 다양한 queues 사이에서 이동할 수 있다.  

- Multi-level feedback queue 스케쥴러는 다음과 같은 파라미터로 정의된다.  
  - queue의 개수
  - 각 queue의 스케쥴링 알고리즘
  - 프로세스를 승진시킬 때를 정하는 기준
  - 프로세스를 강등시킬 때를 정하는 기준
  - 프로세스가 서비스를 필요로 할 때 어느 queue에 들어갈 것인지 정하는 기준  

- **Aging**은 multi-level feedback queue를 사용하여 구현될 수 있다.  

<br>

- Example
  - 세 개의 queues
    - `Q0` - `8`ms quantum RR (interactive)
    - `Q1` - `16`ms quantum RR (interactive)
    - `Q2` - FCFS (batch)  

  - Scheduling  
  ![Multi-level feedback queue][def30]  
    - 새로운 프로세스가 RR을 제공하는 `Q0`에 들어간다.
      - 이 프로세스가 CPU를 얻을 때, 프로세스는 `8`ms를 받는다.
      - 만약 `8`ms 내에 완료되지 않았다면, 프로세스는 `Q1`로 이동한다.

    - `Q1`에서 프로세스는 `16`ms를 받는다.
      - 그러나 여전히 완료되지 않았다면, preempted되고 `Q2`로 이동한다.  

    <br>

### 4. Thread Scheduling
- user-level 쓰레드와 kernel-level 쓰레드가 있다.

- 쓰레드가 지원될 때에는 프로세스가 아니라 쓰레드가 스케쥴링된다.

- Many-to-one과 Many-to-many 모델에서, 쓰레드 라이브러리가 user-level 쓰레드를 스케쥴링한다.
  - **process-contention scope**(PCS)로 알려져있다. (프로제스 내에서 스케쥴링 경쟁이 일어나기 때문에)
  - 커널은 user-level 쓰레드에 대해 알지 못한다.

- One-to-one 모델에서,
  - 각 user-level 쓰레드는 대응되는 kernel-thread를 가지며 OS에 의해 스케쥴링된다.
  - **system-contention scope**(SCS)로 알려져있다. (시스템 내 모든 쓰레드와 경쟁하기 때문에)  

<br>

### 5. Multiple-Processor Scheduling
- CPU 스케쥴링은 여러 개의 CPU들이 available할 때 더 복잡해진다.  

- Multi-process는 아래 아키텍처들 중 하나일 것이다.
  - Multicore CPUs
  - Multithreads cores
  - NUMA systems
  - Heterogeneous multiprocessing

<br>

- Symmetric Multiprocessing (SMP) : 각 프로세서가 self-scheduling

- 모든 쓰레드들은 common ready queue에 있을 수 있다.
  - locking 메커니즘이 없다면, 프로세서 간 잠재적인 race condition이 있을 수 있다.  
  - single shared-queue와 locking 메커니즘은 병목 현상을 유발할 수 있다.

- 각 프로세서는 쓰레드 당 자신만의 private queue를 가질 수도 있다.  
![ready_queue][def31]  

<br>

- 만약 SMP가 효율을 위해 모든 CPUs가 loaded되도록 유지할 필요가 있다면,
- **Load balancing**은 모든 워크로드가 even하게 분배되도록 시도한다.
- **Push migration** : periodic task check가 각 프로세서에 로드
- **Pull migration** : idle 프로세서가 busy 프로세서에게 task를 요청
- e.g., Linux에서, 각 CPU는 migration jobs를 수행하기 위해 하나의 migration daemon을 가진다.  

<br>

- 쓰레드가 하나의 프로세서에서 동작했을 때, 그 프로세서의 캐시 콘텐츠는 그 쓰레드에 의해 접근되는 메모리에 저장된다.
- 우리는 이것을 "쓰레드가 프로세서에 대해 **affinity**를 가진다** 라고 말한다. (즉 **processor affinity**)
- 로드 밸런싱은 processor affinity에 영향을 줄 수 있다. 쓰레드가 한 프로세서에서 다른 프로세서로 이동함으로써.  
쓰레드가 가지고 있언 프로세서에 대한 캐시 콘텐츠를 이동하면서 잃어버리기 때문이다.  
- **Soft affinity** - 운영체제가 쓰레드로 하여금 같은 프로세서에서 동작하도록 시도 (no guarantees)
- **Hard affinity** - 프로세서로 하여금 그 위에서 동작할 수 있는 프로세서의 집합을 지정하도록 함 (guarantees)

<br>

- **Multicore Processors**
  - 최근 트렌드는 여러 프로세스 코어를 하나의 물리적 칩에 두는 것이다.

  - 더 빠르지만, 전력은 덜 소모한다.  

  - 코어 당 여러 개의 쓰레드를 두는 것 또한 보편화되었다.
    - memory retrieve가 일어나는 동안 다른 쓰레드가 무언가 할 수 있도록 memory stall의 이점을 챙긴다.  

  - Figure  
  ![figure][def32]  

<br>

- **Multithreaded Multicore System**
  - 각 코어가 하나보다 많은 개수의 쓰레드를 가지는 것이다.
  - 만약 한 쓰레드가 memory stall 상태라면, 다른 쓰레드를 실행한다.  
  ![thread_stall][def33]
  - **Chip-multithreading(CMT)**는 각 코어에 여러 개의 쓰레드를 할당한다. (hyperthreading)
  - 완전한 아키텍처 state 집합을 유지한다.  
  ![chip_multithreading][def34]
    - General purpose registers
    - Control register
    - Advanced Programmable Interrupt Controller (APIC) register  
      - 각 인터럽트가 개별적으로 다루어질 수 있게 한다.
  - 다른 리소스는 공유된다.
    - Caches
    - Execution units
    - Control logics

  <br>

  - 예를 들어, 4개의 코어를 가진 시스템이 각 코어 당 2개의 쓰레드를 가진다고 가정해보자.  
    - 그렇다면 운영체네는 8개의 logical processor로 인식한다.  
    ![4_core_2_threads][def35]

  - 16 코어 시스템이 각 코어 당 2개의 쓰레드를 가진다면,  
    - 운영체제는 32개의 logical processor로 인식한다.  
    `$ lscpu`  
    `$ cat /proc/cpuinfo`  

    <br>

  - Two levels of scheduling  
  ![two_levels_of_scheduling][def36]  
    - (1) 운영체제는 어느 software thread를 logical CPU 위에서 작동시킬 지 결정한다.
    - (2) 각 코어는 어느 hardware thread를 physical core 위에서 작동시킬 지 결정한다.

<br>

  - NUMA & CPU Scheduling  
  ![NUMA_CPU_Scheduling][def37]  
    - NUMA 시스템은 멀티 프로세서 시스템 내 메모리 디자인으로서,  
    프로세서가 자신만의 local memory를 가지며 이들은 remote memory보다 빠르게 액세스 될 수 있게 한다.  

  - SMT 성능 비교  
  ![SMT_performance][def38]  

  - NUMA & CPU Scheduling - cont'd
    - 만약 운영체제가 NUMA-aware라면,  
    메모리를 쓰레드가 작동중인 CPU에 가깝게 할당할 것이다.  
    ![numa_aware][def39]

    - **NUMA non-aware** vs. **aware OS scheduler**
    - **Authomatic NUMA Balancing**
      - strategies based on (NEED TO REWRITE)
        - CPU follows memory -> 메모리가 있는 노드에 작업을 옮김 (task migration)
          - e.g., 어떤 페이지가 계속 node 1에 접근되면, 작업 자체를 node 1로 이동
        - Memory follows CPU -> 작업이 있는 노드로 메모리 페이지를 복사 (page migration)
          - e.g., 작업이 node 0에서 실행되면, 자주 사용하는 메모리 페이지를 node 0으로 옮김


      - Examples
        - Task grouping  
        ![task_grouping][def40]  
          - 멀티 스레드를 많이 쓰는 프로그램 (e.g., JVM, 가상머신, 웹브라우저)
          - 공유 메모리를 사용하는 프로세스 (e.g., DB)

        - Pseudo-interleaving  
        ![pseudo-interleaving][def41]  
          - 작업을 여러 노드에 even하게 분산시켜서 메모리 대역폭을 극대화  

<br>
  
  - **OS and Interconnect**
    - **Interconnect contention in NUMA system**
      - NUMA system challenges
        - Remote memory latency and performance (원격 메모리 접근 지연)
          - CPU가 자신의 노드가 아닌 다른 노드의 메모리에 접근하면 big latency

        - **Interconnect contention** (인터커넥트 혼잡)
          - CPU와 메모리 사이 데이터를 전달하는 interconnect가 과부하되면 성능이 급격히 저하

      - Related work  
        - Localization [ASPLOS '13]
          - Thread migration
          - Memory (page) migration  

        - Memory Interleaving
        - Placement optimization
          - Asymmetry interconnect [ATC '15]
          - Cache, Memory and interconnect [ATC '18]  
          ![adaptive_routing_in_NUMA_interconnect][def42]


      - Observation  
        - 기본 리눅스 스케쥴러 : First-touch policy (처음 데이터를 접근 한 CPU 노드에 메모리 할당)
        - NUMA-aware 스케쥴러 : NUMA techniques (Redhas's NUMA automatic balancing)  
        ![numa_aware][def43]
          - 그러나 근본적으로 interconnect traffic을 줄여주지는 않는다.
      
      - Example of fixed routing paths among 4 NUMA nodes  
      ![example][def44]

      - Bandwidth utilizations on the routing paths  
      ![example_bandwidth][def45]

      - Interconnect contention을 최소화하는 방법으로서 "Software-based Adaptive Routing in NUMA systems" 연구가 있었다. [ICCD 2019]  
      ![software_based_adaptive_routing][def46]

      <br>

### 6. Linux Scheduling Algorithm
- 커널 버전 `2.5` 전 까지는, `O(n)` 표준 스케쥴링 알고리즘의 바리에이션을 사용했다.

- `2.5` 버전은 constant order `O(1)` 스케쥴링 사용했다. (preemptive)  
  - `O(1)` 스케쥴링은 **프로세서마다 runqueue(RQ)를 가지는 구조**이며,  
  **상수 시간** 내에 프로세스를 스케쥴링할 수 있는 디자인이다.  
  (OS에서 동작하는 프로세스 개수에 상관없이)  

  - RQ structure
    - 각 프로세서 RQ 마다 **Active** & **expired** arrays
    - 타임슬라이스에 남은 시간에서 실행 가능한 가능한 긴 Task (**Active**)
    - 시간이 남지 않았다면(**Expired**), 다른 모든 tasks가 타임슬라이스를 사용하기 전까지 not run-able

  - 왜 `O(1)` 인가?
    - RQ array는 포인터 연산을 사용해 액세스된다.
    - 더이상 active가 존재하지 않으면, expired와 actie를 스위치 (포인터 연산으로 빠르게)  
    - 위 과정들이 스케쥴링 결정을 상수 시간 내에 가능하도록 해준다. (프로세서 수에 상관없이)  

  - Limitation?
    - 큰 서버 워크로드에 좋다. (interative processes가 적은)  
    - 그러나 `O(1)` 스케쥴러는 **latency-sensitive** 애플리케이션 스케쥴링에서는 좋지 못하다.  
    (즉, interactive processes에 대해서 poor response times)  
    - Unfairness  

<br>

- 현대 리눅스 스케쥴러는 모듈화되어 있고, 서로 다른 알고리즘이 서로 다른 타입의 프로세스를 스케쥴링 할 수 있게 한다.  
  - Called schedular class  
  `sched.h`  

- Traditional Unix-like system scheduling  
  - 두 가지 공통 컨셉
    - 프로세스 우선순위 (얼마나 자주 프로세스가 동작할까?)
    - 타임슬라이스 (얼마나 오래 프로세스가 동작할까?)
  - 우선순위는 nice-value 형태로 user-space로 export 되었다.
    - `-20` ~ `19` (`100` ~ `139`) -> nice value가 작을 수록(`-20`), 더 높은 우선순위를 가진다.  
    (nice한 value는 성격이 nice해서 다른 프로세스에게 우선순위를 내준다)

<br>

- Consideration on the nice value  
  - 어떻게 nice values를 타임슬라이스에 매핑시키는가?
    - Naive한 접근법 -> 각 nice value에 고정된 타임슬라이스를 매핑
      - e.g., RQ에 서로 다른 우선순위를 가진 두 프로세스가 있을 때
        - 하나의 default nice value (`zero`)를 타임슬라이스 `100`ms에 매핑
        - 다른 가장 높은 nice value (`+20`, the lowest priority)는 타임슬라이스 `5`ms에 매핑
        - `20`/`21` (`100` out of `105`ms)
        - `1`/`21` (`5` out of `105`ms)  

      - e.g., RQ에 낮은 우선순위를 가진 두 프로세스가 있을 때
        - 각 프로세스가 오직 그 순간에 `5`ms (`5` out of `10`ms each) ?

    - 이런 Naive한 접근법에는 문제가 있다.
      - e.g., `O(1)` 스케쥴러에서 두 프로세스가
        - `0`과 `1`의 nice value를 가진다면 -> 타임슬라이스 `100`ms와 `95`ms에 매핑
        - 두 타임슬라이스가 거의 가타서, 하나 차이나는 nice value 간 차이가 작다
        - 그러나 nice value `18`과 `19`의 차이는 어떠한가? -> `10`ms와 `5`ms에 매핑  
        -> 2x 타임슬라이스

    - 우선순위 기반 스케쥴러에서 프로세서를 다루는 것은 interactive tasks를 빠르게 처리하길 원한다.  
      - 대표적으로 I/O-bound 프로세스가 있는데, 빠르게 응답해줌으로써 쾌적한 사용자 경험을 제공한다.
      - 이러한 시스템에서, 한가지 최적화 테크닉은 "방금 깨어난(woken-up) task에게 우선권을 주는 것이다.  
      (비록 타임 슬라이스가 만료되었더라고, 즉시 실행 가능하도록 boost 제공)  
      -> 프로세스가 **unfair**한 CPU time을 제공받을 수 있다.  

    - Motivation  
      - 타임슬라이스 재설계 필요
      - Fairness

      <br>

- **Linux Scheduling in Version 2.6.8.1+**
  - **Completely Fair Scheduler (CFS)**
    - fair-share 스케쥴링 구현
      - 각 job이 **특정 퍼센테이지**의 CPU time을 갖도록 보장한다. (not time-slice)
    - 효율적이고 Scalable
      - 빠르게 스케쥴링 결정을 내린다. -> use Rbtree (just 가장 왼쪽 끝 리프노드를 고르는 방식)
    - 스케쥴링 퍼포먼스가 중요
      - Google의 Datacenter CPU time의 5%만 스케쥴링이 차지한다.  

  - **CFS는 normal processes를 위한 schedular class로서, Linux에서 `SCHED_NORMAL`라고 불린다.**  
  `kernel/sched/fair.c`  

  - **CFS Operation Basics**
    - 모든 competing 프로세스가 CPU를 even하게 공평하게 나누는 것
      - 고정된 time slice를 사용하지 않고
    - 프로세스의 "**virtual runtime**(vruntime)"을 사용한다.  
      - 프로세스가 동작함에 따라 누적된다.
        - 왜?
        - Considering
          - Switching cost
          - Overhead of swap-out / in
          - the effects on caches
      - 프로세스를 스케쥴링 할 때, 가장 작은 vruntime을 고르면 된다.

    - 언제 스케쥴링하는가?
      - 스위칭을 자주 하면 fairness를 향상시키지만 overhead가 커짐
      - 스위칭을 적게 하면 성능이 향상되지만 fairness를 대가로 함

    - `sysctl_sched_latency` 파라미터에 의해 컨트롤 된다. (upperbound)
      - A.k.a., `target latency`  
      ![sysctl_sched_latency][def47]  
      - Maximum time : 프로세스가 스위칭하기 전 동작 가능한 시간 (e.g., `20`ms)  
      - 이 시간은 프로세스가 타임슬라이스를 얻기 위해, 실행가능한 프로세스의 개수로 나누어진다.
      - CFS는 이 time period에 있어 completely fair할 것이다.

  - **CFS Example**
    - `sysctl_sched_latency` = `48`ms
    - 네 개의 프로세스가 실행할 준비가 되어있다.
      - 각 프로세스의 타임슬라이스는 `12`ms
      - `vruntime`은 `0`에서 시작
    - 가장 작은 `vruntime`을 가진 job을 선택 (이 경우, `A`, `B`, `C`, `D`)
    -  job `A`를 `vruntime`이 `12`ms가 될 때까지 실행
      - 그리고는 스케쥴링 결정을 내린다.
      - 다음 가장 작은 `vruntime`을 가진 job을 선택 (이 경우, `B`, `C`, `D`)
    - `C`와 `D`가 real time `96`ms에 끝났다면,  
      - 타임슬라이스가 `24`ms (`48`/`2`)  
    ![cfs_example][def48]  

    <br>

  - **Too many processes runnable?**
    - 각 프로세스의 타임슬라이스는 `sysctl_sched_latency` / 실행가능한 프로세스 수
      - 많은 수의 프로세스는 작은 타임슬라이스로 연결된다.
        - 이는 곧 더 많은 context switch와 더 많은 overhead

    - "`sysctl_sched_min_granularity`" 파라미터 (lower bound)
      - 프로세스의 최소 타임슬라이스를 정의 (e.g., `6`ms)
      - CFS는 절대 이 값보다 작은 타임슬라이스를 설정하지 않는다.
      - 이 경우, CFS는 **완벽하게 fair하지 않을 수도** 있다.
        - e.g., `sysctl_sched_latency` = `48`ms 이며 `10`개의 실행가능한 프로세스가 있다면
        - 타임슬라이스 `4.8` -> `6`ms 로 설정 (lower bound에 의해)
        - 모든 job들이 `48`ms 내에 끝나지 않을 수 있다.  
      ![sysctl_sched_min_granularity][def47]

<br>

  - **Niceness levels**
    - 사용자에게 프로세스 우선순위에 대한 컨트롤을 제공
      - 몇몇 프로세스에 더 높은 CPU share를 부여할 수 있다.

    - 프로세스의 **nice** 레벨
      - job이 얼마나 다른 프로세스들에 대해 nice 한 지를 나타내는 척도 (introduced before)
      - `19` (가장 낮은 우선순위)
      - `-20` (가장 높은 우선순위)

    - **[updated] Nice level이 프로세서에 있어 효율적인 타임슬라이스를 계산하는데 사용된 가중치(weight)에 매핑된다.**  

  - **Niceness Weightings**  
  ![niceness_weightings][def49]  
    - 모든 nice value 변화에 따라 `10`% 정도의 변화가 존재한다. (`0` ~ `39`)
      - 한 단계 올라가면, `-10`%의 CPU 사용량
      - 한 단계 내려가면, `+10`&의 CPU 사용량 
    ![timeslice_weightings][def50]  

  - **Niceness Weightings Example**
    - 두 프로세스 `A`와 `B`가 있을 때,
      - `A`의 niceness level은 `-5` (boost in priority)  
      - `B`의 niceness level은 `0` (default)
    - `A`와 `B`에 대한 타임슬라이스 계산
      - weight `A` : `3121`, weight `B` : `1024`, total weight : `4145`
      - 타임슬라이스 `A` : `3121`/`4145` = `0.753` * `sysctl_sched_latency`
      - 타임슬라이스 `B` : `1024`/`4145` = `0.247` * `sysctl_sched_latency`  
    - `48`ms `sysctl_sched_latency`를 가정하면,
      - `A`는 약 `75`%의 `sysctl_sched_latency`를 가짐
      - `B`는 약 `25`%의 `sysctl_sched_latency`를 가짐

    - Example  
    ![niceness_weightings_example][def51]  
      - 즉, CPU time은 weight 뿐만 아니라 RQ 내 프로세스의 개수에도 의존한다.  

    <br>

  - **Calculating vruntime**
    - 높은 우선순위를 가진 프로세서가 더 긴 타임슬라이스를 갖는다.
    - 하지만 우리는 다음 실행할 프로세스로서 `vruntime`이 가장 작은 것을 고른다.
      - 우선순위를 적절하게 다루기 위해, `vruntime`은 반드시 우선순위와 반비례해야한다.
    - 이전 Example에서,
      - `A`의 `vruntime`은 `B`의 약 `1/3`으로 누적되어야한다.  
      ![vruntime_of_a][def52]  

      - `weight`이 높을 수록, 우선순위가 낮을 것이다.  

    <br>

  - **CFS efficiency**
    - 스케쥴러는 얼마나 빠르게 다음으로 실행할 job을 찾을 수 있을까?  
      - 리스트 자료구조는 프로세스가 수천 개 있을 때 millisecond 내에 탐색하기 좋지 않을 것이다.

    - CFS는 프로세스를 **red-black tree** 에 유지한다.  
      - balanced tree의 일종
      - low depth를 유지하는 데 크게 신경쓰지 않는다
      - 각 연산 (search, insert, delete)에 `O(log n)`
    ![red_black_tree][def53]  
    ![struct_cfs_rq][def54]  

    - CFS는 이 트리 구조 내에서 오직 실행중인/실행가능한 프로세스만 유지/관리한다.
      - 만약 프로세스가 I/O에서 대기 중이라면, 트리에서 삭제되고 어딘가에서 계속 track 될 것이다.
      - 프로세스가 깨어나면(wakes up) 무엇을 할까?
        - `vruntime`이 다른 것들 보다 뒤처질 것이며, CPU를 독점할 것이다.
        - CFS는 해당 job의 `vruntime`을 트리에서 찾은 최솟값으로 설정할 것이다.  
        ![vruntime_wake_up][def55]

<br>

  - **Linux CFS Summary**
    - 현존하는 가장 널리 쓰이는 fair-share 스케쥴러
    - 약간 weighted round-robin with dynamic time-slice 같은 것이다.
    - 확장성과 부하 처리 능력

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">  

이 포스팅은 강원대학교 송원준 교수님의 운영체제 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.  

</div>
</details>

[def]: https://i.imgur.com/0mW82jZ.png
[def2]: https://i.imgur.com/F4Jvquc.png
[def3]: https://i.imgur.com/1rddWL9.png
[def4]: https://i.imgur.com/6gqa7gz.png
[def5]: https://i.imgur.com/rHzeWTO.png
[def6]: https://i.imgur.com/V5bKxVL.png
[def7]: https://i.imgur.com/r20nfYp.png
[def8]: https://i.imgur.com/4PuAZxJ.png
[def9]: https://i.imgur.com/DeVzZOF.png
[def10]: https://i.imgur.com/GbnmRhb.png
[def11]: https://i.imgur.com/RZR1JEN.png
[def12]: https://i.imgur.com/4iqnLfv.png
[def13]: https://i.imgur.com/N3G5DDh.png
[def14]: https://i.imgur.com/PKoxhLl.png
[def15]: https://i.imgur.com/NXp3zSL.png
[def16]: https://i.imgur.com/raTnO6t.png
[def17]: https://i.imgur.com/u47CeYi.png
[def18]: https://i.imgur.com/ABdsb17.png
[def19]: https://i.imgur.com/aMpUt1C.png
[def20]: https://i.imgur.com/jTyQJWq.png
[def21]: https://i.imgur.com/A1RsMH1.png
[def22]: https://i.imgur.com/K6ZyQzy.png
[def23]: https://i.imgur.com/BnbXcKD.png
[def24]: https://i.imgur.com/mfmpIlQ.png
[def25]: https://i.imgur.com/84bmman.png
[def26]: https://i.imgur.com/vEHR12e.png
[def27]: https://i.imgur.com/L7rm7YO.png
[def28]: https://i.imgur.com/YOc8tiy.png
[def29]: https://i.imgur.com/DSAZH5p.png
[def30]: https://i.imgur.com/up3dI0K.png
[def31]: https://i.imgur.com/jrVC2Jv.png
[def32]: https://i.imgur.com/hiVlxYy.png
[def33]: https://i.imgur.com/gOPoQrJ.png
[def34]: https://i.imgur.com/n1HJ8Bc.png
[def35]: https://i.imgur.com/4ai5Vqc.png
[def36]: https://i.imgur.com/ISqcdXu.png
[def37]: https://i.imgur.com/b50S6BC.png
[def38]: https://i.imgur.com/Lq2UQQR.png
[def39]: https://i.imgur.com/zepyurh.png
[def40]: https://i.imgur.com/yu5Yd05.png
[def41]: https://i.imgur.com/R5Udbwt.png
[def42]: https://i.imgur.com/a7UodzF.png
[def43]: https://i.imgur.com/ONbbjVb.png
[def44]: https://i.imgur.com/DwevK7x.png
[def45]: https://i.imgur.com/TuthGlN.png
[def46]: https://i.imgur.com/WyT9rWa.png
[def47]: https://i.imgur.com/7q3qnCW.png
[def48]: https://i.imgur.com/3zCbT6D.png
[def49]: https://i.imgur.com/eWPCiV1.png
[def50]: https://i.imgur.com/xzOqiLR.png
[def51]: https://i.imgur.com/VKwze7R.png
[def52]: https://i.imgur.com/kntxR6o.png
[def53]: https://i.imgur.com/osgWNDw.png
[def54]: https://i.imgur.com/7an2qF4.png
[def55]: https://i.imgur.com/BXpI3OJ.png