---
layout: post
title: "[알고리즘] 8주차 - Greedy Approach"
excerpt: "Greedy Algorithm, Giving change with the minimum number of coins, Minimum Spanning Tree, Prim's Algorithm, Kruskal's Algorithm, Dijkstra's Algorithm for single-source shortest path, Scheduling, Huffman Code"
tags:
  - [알고리즘, CPP]

toc: true

date: 2024-10-21
last_modified_at: 2024-11-11
---
## Greedy Algorithm
- Greedy Algorithm - 욕심이 그득그득한 알고리즘.  

- **매 순간 마다 best를 선택**한다.  

- 매번 최적의 솔루션을 선택하는 것이  
궁극적으로 최적의 솔루션으로 이어지길 바란다.  
  - 그렇지만 **항상 최적의 솔루션이 보장되지는 않는다**.  

- 그렇기에 **"가끔은"** Greedy approach가 간단하고 효율적인 솔루션이 될 수 있다.  

<br>

### 1. Giving change with the minimum number of coins  
- 가지고 있는 동전이 여러 종류 존재할 때,  
가장 동전을 적게 사용하여 일정 금액을 맞추는 문제이다.  

- 일반적으로 사용 가능한 가장 가치가 큰 동전부터 Greedy하게 사용하여 채워나가면, optimal solution이 된다.  

- 그러나, 그렇지 않을 때도 있다. 
  - 예를들어 {12, 10, 5, 1} 의 가치를 지니는 동전을이 존재할 때, 16의 가치를 만들고 싶다면   
  단순히 Greedy하게 접근하게되면 {12, 1, 1, 1, 1} 이 되어 최적의 솔루션이 아니다.  
  왜냐하면 16 = 10 + 5 + 1 이기 때문이다.  

<br>

- 따라서 Greedy Algorithm을 사용할 때는 **항상** 최적의 솔루션이 보장되는지 확인해야 한다.  

- Greedy Algorithm은 empty set에서 시작하여,  
해당 set이 최적의 solution이 될 때까지 순차적으로 items를 추가한다.  

- 각 iteration은,  
  - **Selection procedure** : set에 추가할 item을 선택한다.
  - **Feasibility check** : 새로운 set이 feasible한지 확인한다.  
  - **Solution check** : 새로운 set이 최적의 solution이 되었는지 확인한다.  

<br>

### 2. Minimum Spanning Tree
- ***Minimum Spanning Tree*** : 그래프 상의 모든 vertex를 가장 적은 cost로 연결하는 트리.  

- undirected graph의 formal한 definition은 이러하다.  
  - undirected graph `G`는, `G`에 속한 vertex 멤버들로 이루어진 집합 `V`와, `V`의 vertex 쌍에 대한 집합 `E`로 구성된다.  
  이 쌍들을 `G`의 edge라고 부른다.  
  `G = (V, E)`  

- Spanning Tree `T`와 `G`에 대하여 `T = (V, F)`로 표기될 때,  
  - `T`와 `G`는 같은 vertex 집합 `V`를 가진다.  
  - `T`의 edge 집합 `F`는 `G`의 edge 집합 `E`의 부분집합이다.  
  `F ⊂ E`

#### [1] Prim's Algorithm
- Minimum Spanning Tree를 찾는 알고리즘 중 하나.  

- 방법
  - 우선 임의의 vertex 하나를 선택하여 시작점으로 설정한다.  
  해당 vertex를 집합에 추가한다.  
  - 이후, 집합에서 나가는 edge 중 **가장 작은 cost**를 가지는 edge를 선택하여 집합에 추가한다.  
    - 단, **cycle을 형성하지 않도록** 해야한다.  
    - 즉, 선택한 edge에서 이미 방문한 vertex만을 포함하는 경우엔 선택하지 않는다.  
    (union-find는 필요없는 이유 -> 그래프 탐색처럼 한 지점에서 뻗어나가기 때문에)  
  - 이 과정을 **`n-1`개의 edge**를 선택할 때까지 반복한다.    
    - `n`은 vertex의 개수이다.  

- Every-case Time Complexity : `T(n) = 2(n-1)(n-1) = O(n`<sup>`2`</sup>`)`

  <br>

- Greedy Algorithmd은 optimal solution을 보장하지 않으므로,  
output tree가 **Minimum Spanning Tree**임을 증명해야 한다.  
![minimum_spanning_tree][def]  

- 위와 같은 Minimum Spanning Tree가 만들어질 수 있을 때,  
선택된 edge는 **promising**하다고 하자.  
  - `{(v`<sub>`1`</sub>`, v`<sub>`2`</sub>`), (v`<sub>`1`</sub>`, v`<sub>`3`</sub>`)}` -> promising
  - `{(v`<sub>`2`</sub>`, v`<sub>`4`</sub>`)}` -> not promising  

  <br>

- **Lemma**  
  > `G = (V, E)`가 connected, weighted, undirected graph이다.  
  `F`가 `E`의 promising subset이며, `Y`는 `F`에 속한 edge들에 의해 연결된 vertex들의 집합이라고 하자.  
  만약 `e`가 `Y`에 속한 vertex를 `V - Y`에 속한 vertex와 연결하는 minimum weight의 edge라면,  
  `F ∪ {e}`는 promising하다.    

  - proof  
    - `F`가 promising -> `F ⊆ F'`를 만족하는 `F'`가 존재하며, `(V, F')`는 Minimum Spanning Tree이다.  
    - 만약 `e ∈ F'` 이면, `F ∪ {e} ⊆ F'`이다. (trivial)  
    - 그러나 만약 `e ∉ F'` 이면,
      - (1) `(V, F')`가 minimum spanning tree이므로, `F' ∪ {e}`는 cycle을 형성한다.  
      - (2) cycle을 제거하기 위하여, `e' ∈ F'`를 제거한다.  
      이제 `F' ∪ {e} - {e'}`는 spanning tree이다. (minimum 인 지는 모름)  
      - (3) `e`는 `Y`에 속한 vertex를 `V - Y`에 속한 vertex와 연결하는 minimum weight의 edge이므로,  
      -> `e`의 weight는 `e'`의 weight보다 작거나 같아야만 한다.  
      - (4) 따라서 `F' ∪ {e} ⊆ F' ∪ {e} - {e'}`(minimum spanning tree) 이다.  
      즉, `F' ∪ {e}`는 promising하다.  

      <br>

- **Theorem**
   > Prim's Algorithm은 항상 Minimum Spanning Tree를 찾는다.  

   - proof
     - **Induction base** : `∅` 는 promising하다.  

     - **Induction hypothesis** : 주어진 반복문의 iteration 이후, 선택된 edges들인 `F`이 promising하다고 가정하자.  

     - **Induction step** : 다음번 iteration에서 선택된 `e`와의 `F ∪ {e}`가 promising함을 증명해야 한다.  
     (*`e`는 `Y`에 속한 vertex를 `V - Y`에 속한 vertex와 연결하는 minimum weight edge이다.)  
       - `F ∪ {e}`는 promising하다. ∵ Lemma
       - 따라서 Prim's Algorithm은 spanning tree를 찾아내고, 그것은 promising하다.  
       -> Minimum Spanning Tree.  

   <br>

#### [2] Kruskal's Algorithm  
- Minimum Spanning Tree를 찾는 또다른 알고리즘 중 하나.

- 방법
  - (1) 모든 edge를 weight가 작은 순서대로 정렬한다.  
  - (2) **가장 작은 cost**를 가지는 edge부터 순서대로 선택한다.  
    - 단, **cycle을 형성하지 않도록** 해야한다.
    - 즉, 선택한 edge가 이미 모두 집합에 포함된 vertex들을 연결하는 경우엔 선택하지 않는다. (union-find)  
  - (3) 이 과정을 **`n-1`개의 edge**를 선택할 때까지 반복한다.  
    - `n`은 vertex의 개수이다.  

- Worst-case Time Complexity : `Θ(n`<sup>`2`</sup>`)`  

  <br>

<br>

- **Lemma**  
  > `G = (V, E)`가 connected, weighted, undirected graph이다. 
  `F`가 `E`의 promising subset이며, `e`는 `E-F`에 속하면서 `F ∪ {e}`가 simple cycle을 형성하지 않도록 하는 minimum weight의 edge라고 하자.  
  그렇다면, `F ∪ {e}`는 promising하다.  

  - proof
    - `F`가 promising -> `F ⊆ F'`를 만족하는 `F'`가 존재하며, `(V, F')`는 Minimum Spanning Tree이다.  
    - 만약 `e ∈ F'` 이면, `F ∪ {e} = F'`이다. (trivial)  
    - 그러나 만약 `e ∉ F'` 이면,
      - (1) `(V, F')`가 minimum spanning tree이므로, `F' ∪ {e}`는 cycle을 형성한다.  
      - (2) `F ∪ {e}`는 cycle을 형성하지 않기 때문에, cycle에 속하는 몇몇 `e'`은 `e' ∈ F'`이고 `e' ∉ F`이다.  
      -> `e' ∈ E - F`  
      - (3) `F ∪ {e'} ⊆ F'` -> no cycle -> `e`는 `e'`보다 weight가 작거나 같아야 한다.  
      - (4) 따라서 `F' ∪ {e} - {e'}`는 minimum spanning tree이다.  
      -> `F ∪ {e} ⊆ F' ∪ {e} - {e'}`   
      => `F ∪ {e}`는 promising하다.  

      <br>

- **Theorem**  
  > Kruskal's Algorithm은 항상 Minimum Spanning Tree를 찾는다.  
  
  - proof  
    - **Induction base** : `∅` 는 promising하다.  

    - **Induction hypothesis** : 주어진 반복문의 iteration 이후, 선택된 edges들인 `F`이 promising하다고 가정하자.  

    - **Induction step** : 다음번 iteration에서 선택된 `e`와의 `F ∪ {e}`가 promising함을 증명해야 한다.  
    (*`e`는 `E-F`에 속하면서 `F ∪ {e}`가 simple cycle을 형성하지 않도록 하는 minimum weight의 edge이다.)  
      - `F ∪ {e}`는 promising하다. ∵ Lemma
      - 따라서 Kruskal's Algorithm은 spanning tree를 찾아내고, 그것은 promising하다.  
      -> Minimum Spanning Tree.  

      <br>

### 3. Dijkstra's Algorithm for single-source shortest path
- **Single-source shortest path** : 하나의 정해진 출발점에서 모든 다른 vertex로의 최단 경로를 찾는 문제.  
  - 이 문제는 Dijkstra's Algorithm이라 불리는 `Θ(n`<sup>`2`</sup>`)` 알고리즘으로 해결된다.  

- 방법
  - (1) 출발점의 거리는 `0`, 나머지의 거리는 `INF`로 initialize
  - (2) 현재 노드에서 뻗어나가는 edge들에 대하여  
  `dist[current] + weight < dist[next]` 인 경우, 최소 거리를 업데이트.  
  - (3) 아직 방문하지 않은 vertex 중 가장 가까운 vertex를 선택하여 (2) 반복.  

<br>

- Every-case time complexity  
  - Prim's Algorithm의 time complexity와 같다.  
  - `T(n) = 2(n-1)(n-1) = Θ(n`<sup>`2`</sup>`)`  

- Dijkstra Algorithm의 Correctness는 Prim's Algorithm과 비슷하게 증명된다.  

- Theorem
  > Dijkstra's Algorithm은 항상 single-source shortest path를 찾는다.  

  - proof  
  `V` : vertex set, `s` : 시작 vertex, `S` : `s`로부터 최단 경로를 찾은 vertex set
    - **Induction base** : `|S| = 1` 일 때, vertex가 하나만 존재하므로 최단 경로의 가중치는 `0`이다. (trivial)
    - **Induction hypothesis** : `|S| = k` 일 때, `S`에 속한 vertex들에 대한 최단 경로를 찾았다고 가정하자.  
    - **Induction step** : `|S| = k+1` 일 때, `S`에 속한 vertex들에 대한 최단 경로를 찾아야 한다.  
      - `V-S` vertex 중 가장 가까운 vertex를 선택하여 `S`에 추가한다.  
        - 이 때, `V-S` vertex 중 가장 가까운 vertex를 `v`라고 하자.  
      - `v`를 추가하기 전까지의 최단 경로는 이미 찾아졌다고 가정했으므로,  
      `s`->`v`라는 새로운 최단 경로를 추가했기 때문에,  
      - 따라서 Dijkstra's Algorithm은 single-source shortest path를 찾는다.  

      <br>

<br>

### 4. Scheduling  
- Scheduling problem type  
  - #1 Minimizing total time in the system
    - Time in the system : waiting time과 service time이 함께 spent.  
    - Goal : minimize the total time in the system. (by scheduling)  
  - #2 Scheduling with deadlines  
    - 모든 작업은 각 deadline을 가지고, 각각은 이익 산출을 위하여 시작되어야 한다.  
    - Goad : maximize the total profit. (by scheduling)  

    <br>

#### [1] Minimizing total time in the system  
- 3개의 jobs에 대한 Service time이 이러할 때,  
`t`<sub>`1`</sub>`= 5`, `t`<sub>`2`</sub>`= 10`, `t`<sub>`3`</sub>`= 4`  

  - 만약 `1`->`2`->`3`의 순서로 served 되면 : `5` + `15` + `19` = `39`  

  - 하지만 `3`->`1`->`2`의 순서로 served 되면 : `4` + `9` + `19` = `32`  

- 즉, Sertive time이 작은 순서대로 Greedy하게 선택함으로써 total time을 minimize할 수 있다.  
-> **Greedy Algorithm**  

<br>

- **Theorem**  
  > total time in the system을 minimize하는 scheduling은,  
  Service time 오름차순으로 scheduling 하는 것이다.  

  - Proof (by using contradiction)  
    - `1` <= `i` <= `n-1`에 대하여 `t`<sub>`i`</sub>는 `i`번째 job의 optimal schedule 내 service time 이라고 하자.  
    - `T`는 optimal schedule에서 total time이라고 하자.  
    - 만약 optimal schedule이 오름차순 service time 순서를 따르지 않는다고 가정하자.  
    (즉, `t`<sub>`i`</sub> > `t`<sub>`i+1`</sub>를 만족하는 `i`가 존재한다.)  
    - 그렇다면 `t`<sub>`i`</sub>> `t`<sub>`i+1`</sub>인 `i`번째와 `i+1`번째 job을 interchange 해보자.  
    - 이 경우 total time이 `T` -> `T`-`t`<sub>`i`</sub>+`t`<sub>`i+1`</sub>로 변화한다.  
    - 가정에 따르면 `T` > `T`-`t`<sub>`i`</sub>+`t`<sub>`i+1`</sub> 여야한다.  
    그러나, `t`<sub>`i`</sub>> `t`<sub>`i+1`</sub> 이므로, ***이는 모순이다.***  

    <br>

#### [2] Scheduling with deadlines  
- 각 job은 deadline과 profit을 가지고 있다.  

|Job|Deadline|Profit|  
|:---:|:---:|:---:|
|1|2|30|
|2|1|35|
|3|2|25|
|4|1|40|

<sub>Deadline is 1 -> job can start at time 1</sub>
<sub>Deadline is 2 -> job can start at time 1 or time 2</sub>

- 만약 `[2, 3]`을 선택한다면, profit은 `60`이다.  

- 하지만 `[1, 4]`를 선택한다면, profit은 `70`이다.  

- 즉, profit이 가장 큰 순서대로 Greedy하게 선택함으로써 total profit을 maximize할 수 있다.  
-> **Greedy Algorithm**

  - 단, 선택한 set이 feasible한지 확인해야 한다.  

<br>

- feasibility check  
  - 선택한 job들을 deadline 순서대로 정렬한다.  
  - 그리고 time slot에 순서대로 job을 배치한다.  
  만약 이 때 배치 불가능한 job이 있다면, 해당 set은 feasible 하지 않다.  

  <br>

- **Lemma** for efficient identification of feasible sets  
  > `S`는 선택한 job set이다. `S`에 선택된 job들을 deadline 오름차순으로 정렬한 것이 feasible 하다면, `S`는 feasible하다.  

  - proof for forward direction
    - `S`가 feasible 하다면 -> 적어도 하나의 feasible sequence가 존재한다.  
    - `[..x..y..]`에서 `y`의 deadline < `x`의 deadline인 feasible sequence가 존재할 때,  
    - `x`와 `y`를 interchange 해도, 여전히 feasible sequence하다. (`S`가 feasible 하므로)
      - 즉, `y`의 deadline이 더 작다.  

  - proof for backward direction
    - ordered sequence가 feasible 하다 -> `S`는 feasible 하다. (by definition)  

    <br>

- worst-case time complexity
  - sort by profit : `Θ(nlogn)`
  - for-loop
    - deadline 비교 : `Θ(i-1)`
    - feasible check : `Θ(i)`  
    -> `Θ(n`<sup>`2`</sup>`)`

<br>

- **Theorem**
  > Scheduling with deadlines은 항상 optimal set of jobs를 찾는다.  
  
  - proof
    - **Induction base** : `|S| = 1` 일 때, `S`는 optimal set이다.
    - **Induction hypothesis** : `|S| = k` 일 때, `S`는 optimal set이라고 가정하자.  
    - **Induction Step** : `|S| = k+1` 일 때, `S`는 optimal set임을 증명하자.  
      - `S`에 속한 job들을 dealine 오름차순으로 정렬한다.  
      정렬된 job들을 순서대로 `J1`, `J2`, ... `Jk+1`이라고 하자.  
        - 정렬된 작업 집합 `S`가 feasible 하다면,  
        즉 모든 작업을 시간 내에 완료할 수 있다면 optimal set이다.
        - 만약 `S`가 feasible하지 않다면,  
        `Jk+1`을 마감 시간 내에 완료할 수 없으므로 제거한다.  
        `J1`, `J2`, ... `Jk`는 optimal set으로 가정했으므로,  
        `Jk+1`을 제거한 `S`는 optimal set이다.  

      <br>

<br>

### 5. Huffman Code
#### Data Encoding
- Data는 효율적으로 저장되기 위하여 compressed(encoded) 되어야 한다.  

- Encoding examples
  - Fixed-length binary code  
    - `[a, b, c]` 를 2 bits로 encoding 해보자.  
    `a` : `00`, `b` : `01`, `c` : `11`  
    
    - `ababcbbbc`는, `000100011101010111`로 encoding된다. (18 bits)

  - Variable-length binary code (more efficient)
    - `[a, b, c]`를 서로 다른 bits로 encoding 해보자.  
    `a` : `10`, `b` : `0`, `c` : `11`

    - `ababcbbbc`는, `1001001100011`로 encoding된다. (13 bits)  

    <br>

  - Optimal binary code problem
    - 우리의 목표는, **최소한의 bits로 encoding**하여 문자들을 표현하는 binary character code를 찾는 것이다.  

  - 하지만, codeword 간 혼동이 발생하여 decoding 시에 **ambiguity**가 발생해서는 안된다.  
    - 즉, 어떠한 문자의 codeword가 다른 문자의 시작, 즉 **prefix가 되어서는 안된다**.  
    - 이는 트리 구조로 표현할 수 있다.  
    ![huffman_tree][def2]  
      - 즉 이 트리에서, leaf node 만 문자를 가질 수 있다.  

  <br>

- Example of prefix code
  - 우리의 character set이 `[a, b, c, d, e, f]` 일 때,  

  |Character|Frequency|Fixed-length|Variable-length|Huffman|
  |:---:|:---:|:---:|:---:|:---:|
  |`a`|16|`000`|`110`|`00`|
  |`b`|5|`001`|`11111`|`1110`|
  |`c`|12|`010`|`1110`|`110`|
  |`d`|17|`011`|`10`|`01`|
  |`e`|10|`100`|`11110`|`1111`|
  |`f`|25|`101`|`0`|`10`|

  ![example_tree][def3]

  - 이와 같이 codeword를 선택하면,  
    - Variable-length code : total `231` bits
    - Huffman code : total `212` bits  
    -> Huffman code가 더 효율적이다.  
    Huffman code는 어떻게 생성하는 걸까?  

<br>

#### Huffman Code
- How to generate Huffman code
  - Using priority_queue (`PQ`)
  - 더 낮은 frequence가 높은 priority를 가지도록 한다.  

- 방법
  - (1) priority_queue에 모든 character & frequency를 넣는다.  
  - (2) `PQ`에서 가장 낮은 두개의 frequency를 가지는 character를 묶는다.  
  ![huffman_priority_queue_1][def4]  
  - (3) 묶음을 새로운 node로 만들어 합산한 frequence로 `PQ`에 넣는다.  
  ![huffman_priority_queue_2][def5]
  - (4) 이 과정을 반복한다.  
  ![huffman_priority_queue_3][def6]
  ![huffman_priority_queue_4][def7]  
  .  
  .  
  .  
  ![huffman_priority_queue_5][def8]
  - (5) huffman tree 완성  
  ![huffman_tree_complete][def9]  

  <br>

- time complexity
  - priority_queue는 heap을 사용하여 구현된다.  
  -> initialized in `O(n)`
  - 각각의 heap operation은 `O(logn)`, 그리고 for-loop을 통해 `n-1`회 반복한다.  
  -> runs in `O(nlogn)`  

  <br>

- **Lemma**  
  > optimal binary prefix code를 담는 binary tree는 full binary tree이다.  
  이 말인 즉슨, 모든 non-leaf node들이 두 개의 childred을 갖는다.  

  - proof using contradiction
    - 만약 optimal tree `T`의 non-leaf node가 하나의 child만을 가진다면,  
    - 해당 node를 무너뜨리고 child에 해당하는 sub-tree를 위로 끌어올렸을 때,  
    - 새로 만들어진 tree는 더 적은 total cost를 가지게 된다.  
    - 따라서 `T`는 optimal tree가 아니게 된다.  

- **Theorem**  
  > Huffman code는 optimal binary code를 만들어 낸다.  

  - Proof by induction
    - induction sketch
      - `i`번째 step에서 tree 집합이 optimal code에 상응하는 binary tree에 속하는 branches라면,  
      `i+1`번째 step에서의 tree 집합도 optimal code에 상응하는 binary tree에 속하는 branches가 됨을 보이면 되겠다.  

    - **Induction base**  
      - single node 집합은 optimal code에 상응하는 binary tree에 속한다.  
    - **Induction hypothesis**  
      - `i`번째 step에서 tree 집합이 optimal code에 상응하는 binary tree에 속하는 branches라고 가정하자.  
      optimal tree를 `T`라고 부르자.  
    - **Induction step**
      - `u`와 `v`가 `i+1`번째 step에서 결합되는 두 roots라고 하자.  
        - (1) 만약 `u`와 `v`가 `T`에서 sibling(같은 depth)이라면,  
        -> `i+1`번째 step에서의 tree 집합은 `T`의 branches를 포함한다.  
        - (2) 만약 `u`와 `v`가 `T`에서 sibling이 아니라면,  
        -> `u`의 level >= `v`의 level 이라고 놓자.(트리에서 더 아래에 위치)  
        -> `freq(v)` = `v` 아래 subtree의 모든 노드의 frequency의 합  
        -> `u`는 가령 `w`와 같은 sibling이 존재한다. (by Lemma)  
        -> `i+1`번째 step에서 `v`는 `u`와 함께 선택되었다. (not `w`)  
        즉, `freq(w)` >= `freq(v)`  
        -> `T`에서, `depth(w)` >= `depth(v)`  
        -> `T'`는 `v`와 `w`의 위치를 바꾸어 생성된 tree라고 할 때,  
        -> `bits(T')` = `bits(T) + [depth(w) - depth(v)][freq(v) - freq(w)]` <= `bits(T)`  
        -> 따라서 `T'`에 따른 code가 오히려 더 optimal한 code가 된다.  
        ![huffman_theorem][def10]

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown=   "1">

이 포스팅은 강원대학교 김도형 교수님의 알고리즘 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 

[def]: https://i.imgur.com/ESdE7cx.png
[def2]: https://i.imgur.com/MrZJoaG.png
[def3]: https://i.imgur.com/AvDFxiN.png
[def4]: https://i.imgur.com/tFoNV61.png
[def5]: https://i.imgur.com/DEXffvn.png
[def6]: https://i.imgur.com/UJ3xFnE.png
[def7]: https://i.imgur.com/VV4TpF4.png
[def8]: https://i.imgur.com/H9Tesxe.png
[def9]: https://i.imgur.com/VKWQOTB.png
[def10]: https://i.imgur.com/3VsuWwi.png