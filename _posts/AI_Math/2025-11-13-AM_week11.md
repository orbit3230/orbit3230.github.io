---
layout: post
title: "[인공지능수학] 11주차 - 확률과 확률분포"
excerpt: "조건부 확률과 베이즈 정리, 이산확률분포, 연속확률분포"

tags:
  - [인공지능수학, Math]

toc: true

date: 2025-11-13
last_modified_at: 2025-11-27
---
## 확률과 확률분포
### 1. 조건부 확률과 베이즈 정리
- 유한한 표본공간 `S`가 주어질 때, `S`의 부분집합인 사건 `A`가 일어날 **확률**(probability)은  
`P(A)` = `|A| / |S|` 이다.  

- 사건 `A`가 일어났을 때 사건 `B`가 일어날 확률을 사건 `A`에 대한 사건 `B`의 **조건부 확률**(conditional probability)이라 하고, `P(B | A)`로 표기하며 다음과 같이 정의한다.  
`P(B | A)` = `P(A ∩ B) / P(A)`  

  - **조건부 확률**은 **표본 공간의 축소** (my favorite sentence)

<br>

- 두 사건 `A`, `B`가 동시에 일어나지 않을 때, 즉 `P(A ∩ B)` = `0`일 때, 두 사건 `A`, `B`를 **상호 배타적인 사건**(mutually exclusive events)이라 한다.  

- `P(B | A)` = `P(B)`일 때, 즉, 사건 `A`가 일어났을 때 사건 `B`가 일어날 확률이 사건 `B`가 일어나는 확률과 같을 때, 두 사건 `A`, `B`를 **독립 사건**(independent events)이라 한다. 따라서 독립사건 `A`, `B`는 다음을 만족한다.  
`P(B | A)` = `P(A ∩ B)` / `P(A)` = `P(B)`  ⟺  `P(A ∩ B)` = `P(A)P(B)`  

<br>

- 다음과 같은 식을 **베이즈 정리**(Bayes' theorem) 또는 **베이즈 룰**(Bayes' rule)이라 한다.  
![bayes_rule][def]  
  - `P(A | B)` : 사건 `B`가 주어졌을 때 사건 `A`의 **사후확률**(posterior probability)
  - `P(B | A)` : 사건 `A`의 **우도**(likelihood)  
  - `P(A)` : **사전확률**(prior probability)
  - `P(B)` : **주변우도**(marginal likelihood)  

<br>

### 2. 이산확률분포
- 베르누이 시행 : 성공과 실패 두 가지 결과만을 가지는 확률실험

- 베르누이 시행을 `n`번 할 때, 성공 횟수가 `x`일 경우의 확률 `P(X = x)`는 다음과 같다.  
`P(X = x)` = <sub>`n`</sub> `C`<sub>`x`</sub> `p`<sup>`x`</sup> `(1 - p)`<sup>`n - x`</sup> (단, `x`는 `0` ≤ `x` ≤ `n`인 정수)  
  - 이와 같은 확률분포를 **이항분포**(binomial distribution)라 하고, `X` ~ `B(n, p)` 또는 간단히 `B(n, p)`로 표기한다.  

- 이항분포의 성질
  - 기댓값 : `E(X)` = `np`
  - 분산 : `V(X)` = `np(1 - p)` = `npq` (단, `q` = `1 - p`)  
  - `V(X)` = `E(X`<sup>`2`</sup>`) - (E(X))`<sup>`2`</sup>  
  - `SD(X)` = `σ` = `√(V(X))`  
  - `E(X + Y)` = `E(X)` + `E(Y)`
  - `E(X - Y)` = `E(X)` - `E(Y)`  
  - `V(X + Y)` = `V(X)` + `V(Y)` (단, `X`, `Y`가 독립일 때)  

<br>

- 확률 질량 함수(probability mass function, PMF) : 이산확률변수에서 특정 값에 대한 확률을 나타내는 함수  
![pmf][def2]  

- 누적 분포 함수(cumulative distribution function, CDF) : 확률변수가 특정 값 이하의 값을 가질 확률을 나타내는 함수  
![cdf][def3]  

<br>

- 주어진 시간 또는 공간에서 어떤 사건이 일어나는 횟수 `X`에 대한 확률 `P(X = k)`가 다음ㅁ과 같을 때, 이 확률분포는 매개변수 `λ` > `0`을 갖는 **푸아송분포**(Poisson distribution)라고 하고, `X` ~ `P(λ)` 또는 간단히 `P(λ)`로 표기한다.  
![poisson_distribution][def4]  

  - 푸아송 분포의 기댓값과 분산은 `λ`와 같다. 즉, `E(X)` = `λ` = `V(X)`  

- `n`이 매우 크고(`n` > `1000`), `p`가 매우 작으며(`p` < `0.01`), `np` = `λ`를 만족할 때, 푸아송분포 `P(λ)`는 이항분포 `B(n, p)`로 근사한다.  

<br>

### 3. 연속확률분포
- 연속확률변수 `X`에 함수 `f(x)`를 대응하는 것을 **연속확률분포**(continuous probability distribution)라 한다.  
  - 이때 `f(x)`를 확률변수 `X`의 **확률밀도함수**(probability density function, PDF)라 한다.  

- 연속확률변수 `X`의 확률밀도함수가 아래와 같을 때,  
![pdf][def5]  
`X`에 대한 확률분포를 **정규분포**(normal distribution) 또는 **가우시안 분포**(Gaussian distribution)라 하고, `X` ~ `N(μ, σ`<sup>`2`</sup>`)` 또는 간단히 `N(μ, σ`<sup>`2`</sup>`)`로 표기한다.  

- 정규분포의 확률  
![normal_distribution_probability][def6]  

- 정규분포의 누적분포함수 `Φ(x)`  
![normal_distribution_cdf][def7]  

- 정규분포의 성질
  - 기댓값은 `E(X)` = `μ`
  - 분산은 `V(X)` = `σ`<sup>`2`</sup>  
  - `E(X + Y)` = `E(X)` + `E(Y)`
  - `E(X - Y)` = `E(X)` - `E(Y)`
  - `V(X)` = `E(X`<sup>`2`</sup>`) - (E(X))`<sup>`2`</sup>
  - 정규분포 곡선은 `x` = `μ`를 기준으로 좌우 대칭이고, 최댓값 `f(μ)` = `1 / (√(2π)σ)`을 갖는다.  
  - 두 변곡점은 `x` = `μ - σ`, `x` = `μ + σ`에 위치한다.  
  - 정규분포의 확률밀도함수 `f(x)`의 도함수 `f'(x)`는 `f'(x)` = `-(x - μ) / σ`<sup>`2`</sup> `f(x)`이다.  

<br>

- `μ` = `0`, `σ` = `1`인 정규분포 `N(0, 1)`를 **표준정규분포**(standard normal distribution)라 한다. 이 경우의 확률밀도함수는 다음과 같다.  
![standard_normal_distribution_pdf][def8]  

- 확률 변수 `X`가 정규분포 `N(μ, σ`<sup>`2`</sup>`)`를 따른다고 할 때, `Z` = `(X - μ) / σ`로 치환하면 `Z` ~ `N(0, 1)`을 따른다. 이를 **정규화**(standardization)라 한다.  

- 확률변수 `X`가 정규분포 `N(μ, σ`<sup>`2`</sup>`)`를 따를 때, 다음이 성립한다.  
  - `P(μ - σ < X < μ + σ)` ≈ `0.68` = `68%`  
  - `P(μ - 2σ < X < μ + 2σ)` ≈ `0.95` = `95%`
  - `P(μ - 3σ < X < μ + 3σ)` ≈ `0.99` = `99%`  

<br>

- 이산확률변수 `X`가 이항분포 `B(n, p)`를 따를 때, `n`이 커지면 `X`는 `N(np, np(1 - p))`인 정규분포를 따른다. 따라서 `Z = (X - μ) / σ`로 치환하면 `n` → `∞`일 때, `Z` ~ `N(0, 1)`을 만족하고 다음과 같이 확률을 구할 수 있다.  
![binomial_to_normal_approximation][def9] 

<br>

- 모집단의 평균이 `μ`이고 분산이 `σ`<sup>`2`</sup>이라고 하자. 이 모집단으로부터 추출한 크기가 `n`인 표본들의 표본평균 `X̄`의 확률분포는 `n` → `∞`일 때 정규분포 `N(μ, σ`<sup>`2`</sup> / `n)`에 수렴한다. 따라서 `X̄`를 `Z = (X̄ - μ) / (σ / √(n))`로 치환하면 `n` → `∞`일 때 표준정규분포 `N(0, 1)`에 수렴한다. 이를 **중심극한정리**(central limit theorem)라 한다.  
  - 표본평균의 평균은 모평균. (my favorite sentence)

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown=   "1">

이 포스팅은 강원대학교 이구연 교수님의 인공지능수학 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 

[def]: https://i.imgur.com/J8dWeVN.png
[def2]: https://i.imgur.com/QU3xG6q.png
[def3]: https://i.imgur.com/Nnnu1rH.png
[def4]: https://i.imgur.com/CQbLaQY.png
[def5]: https://i.imgur.com/ByA6C1A.png
[def6]: https://i.imgur.com/bwxtw9R.png
[def7]: https://i.imgur.com/LGiKrvq.png
[def8]: https://i.imgur.com/q6ApfKh.png
[def9]: https://i.imgur.com/WWVUfkg.png