---
layout: post
title: "[인공지능수학] 10주차 - 편미분과 경사 하강법"
excerpt: "편미분, 경사 하강법"

tags:
  - [인공지능수학, Math]

toc: true

date: 2025-11-06
last_modified_at: 2025-11-13
---
## 편미분과 경사 하강법
### 1. 편미분
- `ℝ`<sup>`n`</sup>의 부분집합을 `D`라고 할 때 함수 `f` : `D` → `ℝ`을 **다변수함수**(function with several variables)라고 한다. 즉 `x` = `(x`<sub>`1`</sub>`, ..., x`<sub>`n`</sub>`)` ∈ `D`에 대하여 `z` = `f(x`<sub>`1`</sub>`, ..., x`<sub>`n`</sub>`)`이 대응하는 함숫값이다. 이 때 `D`를 함수 `f`의 **정의역**(domain)이라 하고, 모든 함숫값의 집합을 함수 `f`의 **치역**(range, image)이라고 한다.  

<br>

- 다변수함수 `f` : `D` → `ℝ`의 **그래프**(graph)는 집합 `{(x, f(x)) | x = (x`<sub>`1`</sub>`, ..., x`<sub>`n`</sub>`) ∈ D}`이고, 이 집합은 `ℝ`<sup>`n+1`</sup>의 부분집합이다.  

<br>

- 다변수함수 `f`와 상수 `k`에 대하여, `f(x)` = `k`를 만족하는 `x`들의 집합을 함수 `f`의 **레벨집합**(level set)이라고 한다.  

<br>

- 다변수함수 `z` = `f(x)`에 대하여 벡터 `x` = `(x`<sub>`1`</sub>`, ..., x`<sub>`n`</sub>`)`과 `a` = `(a`<sub>`1`</sub>`, ..., a`<sub>`n`</sub>`)`이 함수 `f`의 정의역 원소라고 하자. 임의의 `ε` > `0`엥 대하여 `0` < `‖x - a‖`<sub>`2`</sub> < `δ`인 모든 `x`에 대해 
`|f(x) - L` < `ε`를 만족하는 `δ` > `0`이 존재할 때, `L`을 `x`가 `a`에 가까이 갈 때의 함수 `f`의 **극한**(limit)이라 하고 다음과 같이 나타낸다.  
![limit_definition][def]  
또는 `x → a`일 때 `f(x)` → `L'`로 표기하기도 한다.  

- 극한의 성질 : 다변수함수 `f`와 `g`가 같은 정의역에서 정의된다고 하고, `a` = `(a`<sub>`1`</sub>`, ..., a`<sub>`n`</sub>`)`이 두 함수의 정의역 원소라고 하자. `lim`<sub>`(x→a)`</sub>`f(x) = L`<sub>`1`</sub>이고 `lim`<sub>`(x→a)`</sub>`g(x) = L`<sub>`2`</sub>라고 하면 다음이 성립한다.  
![limit_properties][def2]  

<br>

- 다변수함수 `z` = `f(x)`가 `ℝ`<sup>`n`</sup> 위에서 정의된다고 하자. 함수 `f`의 정의역 원소 `x` = `(x`<sub>`1`</sub>`, ..., x`<sub>`n`</sub>`)`과 `a` = `(a`<sub>`1`</sub>`, ..., a`<sub>`n`</sub>`)`에 대하여 다음이 성립할 때, 함수 `f`는 `x` = `a`에서 **연속**(continuous)이라고 한다.  
![continuity_definition][def3]  
만약 함수 `f`의 정의역의 모든 점에서 연속이면 함수 `f`를 **연속함수**(continuous function)라고 한다.  

- 연속함수의 성질 : 다변수함수 `f`와 `g`가 같은 정의역에서 정의된다고 하고, `a` = `(a`<sub>`1`</sub>`, ..., a`<sub>`n`</sub>`)`이 두 함수의 정의역 원소라고 하자. 두 함수 `f`·`g`가 `x` = `a`에서 연속일 때, 다음 함수들도 `x` = `a`에서 연속이다.  
  - (1) `f`±`g`
  - (2) `fg`
  - (3) `f/g` (단, `g(a)` ≠ `0`)  
  - (4) `cf` (단, `c`는 상수)

<br>

- 다변수함수 `x` = `f(x)`가 `ℝ`<sup>`n`</sup> 위에서 정의된다고 할 때 정의역 원소 `x` = `(x`<sub>`1`</sub>`, ..., x`<sub>`n`</sub>`)`에 대하여, 함수 `f`의 변수 `x`<sub>`i`</sub>에 대한 **편도함수**(partial derivative) `∂f/∂x`<sub>`i`</sub>는 다음과 같이 정의된다.  
![partial_derivative_definition][def4]  
편도함수는 `f`<sub>`x`<sub>`i`</sub></sub>`(x)`, `f`<sub>`x`<sub>`i`</sub></sub>, `f`<sub>`i`</sub>, `D`<sub>`i`</sub>`f`, `D`<sub>`x`<sub>`i`</sub></sub>`f` 등으로도 표기한다.  

<br>

- 다변수함수 `f` : `ℝ`<sup>`n`</sup> → `ℝ`에 대하여, 단위벡터 `u` = `(u`<sub>`1`</sub>`, ..., u`<sub>`n`</sub>`)` 방향으로의 함수 `f`의 **방향도함수**(directional derivative)는 다음과 같이 정의하며, 간단히 `D`<sub>`u`</sub>`f`로 표기한다.  
![directional_derivative_definition][def5]  

- 다변수함수 `f` : `ℝ`<sup>`n`</sup> → `ℝ`에 대하여, 단위벡터 `u` = `(u`<sub>`1`</sub>`, ..., u`<sub>`n`</sub>`)` 방향으로의 함수 `f`의 방향도함수를 `D`<sub>`u`</sub>`f`라고 할 때, 다음이 성립한다.  
![directional_derivative_property][def6]  
  - 함수 `f`의 그래디언트를 단위벡터 `u`와 내적한 값이 방향도함수 `D`<sub>`u`</sub>`f`이다.  

<br>

- 다변수함수 `f` : `ℝ`<sup>`n`</sup> → `ℝ`과 벡터 `a` = `(a`<sub>`1`</sub>`, ..., a`<sub>`n`</sub>`)` ∈ `ℝ`<sup>`n`</sup>에 대하여, 함수 `f`의 증분 `Δf`를 다음과 같이 정의한다.  
`Δf` = `f(a`<sub>`1`</sub> + `Δx`<sub>`1`</sub>`, ..., a`<sub>`n`</sub> + `Δx`<sub>`n`</sub>`)` - `f(a`<sub>`1`</sub>`, ..., a`<sub>`n`</sub>`)`  
이때, ![differential_definition][def7]가 성립하면 함수 `f`는 벡터 `a`에서 **미분가능**(differentiable)하다고 한다. 단, 여기서 각 `i`에 대하여 `ε`<sub>`i`</sub>는 `Δx`<sub>`1`</sub>, ..., `Δx`<sub>`n`</sub>에 관한 함수이고, `Δx` → `0`일 때 `ε`<sub>`i`</sub> → `0`을 만족한다.
  - 다변수함수가 미분가능하다는 것은, 곧 모든 단위벡터에 대해 방향도함수가 존재한다는 내용을 포함한다.  

<br>

- 다변수함수의 연쇄법칙 1
  - 다변수함수 `z` = `f(x`<sub>`1`</sub>`, ..., x`<sub>`n`</sub>`)`은 각 변수 `x`<sub>`i`</sub>에 대하여 미분가능하고, 각 변수 `x`<sub>`i`</sub>는 또 다른 변수 `t`에 대하여 미분가능한 함수, 즉 `x`<sub>`i`</sub> = `x`<sub>`i`</sub>`(t)`라고 하자. 그러면 `z` = `f(x`<sub>`1`</sub>`, ..., x`<sub>`n`</sub>`)` = `f(x`<sub>`1`</sub>`(t), ..., x`<sub>`n`</sub>`(t))` ∈ `ℝ`은 `t`에 대하여 미분가능하고, 도함수 `dz/dt`는 다음과 같다.  
  ![chain_rule_1][def8]  

- 다변수함수의 연쇄법칙 2
  - 다변수함수 `z` = `f(x`<sub>`1`</sub>`, ..., x`<sub>`n`</sub>`)`이 각 변수 `x`<sub>`i`</sub>에 대하여 미분가능하고, 각 변수 `x`<sub>`i`</sub>는 또 다른 변수들 `t`<sub>`i`</sub>`(i = 1, ..., k)`에 대해 미분가능한 함수, 즉 `x`<sub>`i`</sub> = `x`<sub>`i`</sub>`(t`<sub>`1`</sub>`, ..., t`<sub>`k`</sub>`)`라고 하자. 그러면 `z` = `f(x`<sub>`1`</sub>`, ..., x`<sub>`n`</sub>`)`은 각 `t`<sub>`j`</sub>에 대해 미분가능한 함수이고, 도함수 `∂z/∂t`<sub>`i</sub>는 다음과 같다.  
  ![chain_rule_2][def9]  

<br>

### 2. 경사 하강법
- 다변수함수 `f` : `ℝ`<sup>`n`</sup> → `ℝ`이 가장 빨리 증가하는 방향은 그래디언트 `∇f` 방향이다. 또한 임의의 단위 벡터 `u`에 대해 다음이 성립한다.  
![gradient_ascent][def10]  

<br>

- 라그랑즈 승수법 (Lagrange multipliers)
  - 두 다변수함수 `f` : `ℝ`<sup>`n`</sup> → `ℝ`과 `g` : `ℝ`<sup>`n`</sup> → `ℝ`이 미분가능하다고 하자. 이때 `g(x)` = `0`을 만족하는 모든 `x`에 대하여 `f(x)`의 최댓값 또는 최솟값에 대응하는 해 `x`<sup>`*`</sup>은 적당한 실수 `λ`에 대하여 다음을 만족한다.  
  `∇f(x`<sup>`*`</sup>`)` = `λ∇g(x`<sup>`*`</sup>`)`  

- 라그랑주 승수법의 일반화
  - 다변수함수 `f` : `ℝ`<sup>`n`</sup> → `ℝ`과 `g`<sub>`i`</sub> : `ℝ`<sup>`n`</sup> → `ℝ` (`i` = `1`, ..., `k`)이 미분가능하다고 하자. 이때 `g`<sub>`i`</sub>`(x)` = `0` (`i` = `1`, ..., `k`)을 만족하는 모든 `x`에 대하여 `f(x)`의 최댓값 또는 최솟값에 대응하는 해 `x`<sup>`*`</sup>은 적당한 실수 `λ`<sub>`i`</sub> (`i` = `1`, ..., `k`)에 대하여 다음을 만족한다.  
  `∇f(x`<sup>`*`</sup>`)` = `λ`<sub>`1`</sub>`∇g`<sub>`1`</sub>`(x`<sup>`*`</sup>`)` + ... + `λ`<sub>`k`</sub>`∇g`<sub>`k`</sub>`(x`<sup>`*`</sup>`)`

<br>

- 다변수함수 `f` : `ℝ`<sup>`n`</sup> → `ℝ`이 각 변수에 대하여 두 번 미분가능하다고 하자. 그러면 주어진 점 `a` = `(a`<sub>`1`</sub>`, ..., a`<sub>`n`</sub>`)` ∈ `ℝ`<sup>`n`</sup>에서의 함수 `f`의 **헤시안 행렬**(Hessian matrix) `H(f)(a)`는 다음과 같다.  
![hessian_definition](TODO)  

<br>

- 행렬 `A` ∈ `ℝ`<sup>`n×n`</sup>이 대칭행렬이라고 할 때, `0`가 아닌 임의의 벡터 `x` ∈ `ℝ`<sup>`n`</sup>에 대하여 다음과 같다.  
  - `x`<sup>`T`</sup>`Ax` > `0`을 만족하면, 행렬 `A`를 **양의 정부호 행렬**(positive definite matrix)이라 하고 `A` > `0`으로 표기한다.
  - `x`<sup>`T`</sup>`Ax` ≥ `0`을 만족하면, 행렬 `A`를 **양의 준정부호 행렬**(positive semi-definite matrix)이라 하고 `A` ≥ `0`으로 표기한다.  
  - `x`<sup>`T`</sup>`Ax` < `0`을 만족하면, 행렬 `A`를 **음의 정부호 행렬**(negative definite matrix)이라 하고 `A` < `0`으로 표기한다.  
  - `x`<sup>`T`</sup>`Ax` ≤ `0`을 만족하면, 행렬 `A`를 **음의 준정부호 행렬**(negative semi-definite matrix)이라 하고 `A` ≤ `0`으로 표기한다.  
  - 그 외의 경우, 행렬 `A`를 **부정부호 행렬**(indefinite matrix)이라 한다.  

- 행렬 `A`가 positive definite matrix이기 위한 필요충분조건은 행렬 `A`의 모든 고윳값이 양수인 것이다.  
- 행렬 `A`가 negative definite matrix이기 위한 필요충분조건은 행렬 `A`의 모든 고윳값이 음수인 것이다.  

- 다변수함수 `f` : `ℝ`<sup>`n`</sup> → `ℝ`이 각 변수에 대해 두 번 미분가능하고, 점 P에서 `∇f(P)` = `0`를 만족하면 다음이 성립한다.
  - 헤시안 행렬 `H(f)(P)`가 positive definite matrix이면, 점 `P`는 극소점이다.
  - 헤시안 행렬 `H(f)(P)`가 negative definite matrix이면, 점 `P`는 극대점이다.  
  - `det(H(f)(P))` < `0`이면, 점 `P`는 **안장점**(saddle point)이다.  
  ![saddle_point](TODO)  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown=   "1">

이 포스팅은 강원대학교 이구연 교수님의 인공지능수학 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 

[def]: https://i.imgur.com/Wah8keP.png
[def2]: https://i.imgur.com/RGdUKXL.png
[def3]: https://i.imgur.com/K68hNZH.png
[def4]: https://i.imgur.com/ih7y1zp.png
[def5]: https://i.imgur.com/fcU77Fp.png
[def6]: https://i.imgur.com/ljclOjN.png
[def7]: https://i.imgur.com/VgPgj4T.png
[def8]: https://i.imgur.com/TVqtkoC.png
[def9]: https://i.imgur.com/xIjePy2.png
[def10]: https://i.imgur.com/3pUTNuC.png