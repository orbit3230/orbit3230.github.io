---
layout: post
title: "[인공지능수학] 4주차 - 선형변환과 랭크 정리"
excerpt: "선형변환, 랭크 정리"

tags:
  - [인공지능수학, Math]

toc: true

date: 2025-09-22
last_modified_at: 2025-09-25
---
## 선형변환과 랭크 정리
### 1. 선형변환
- 선형변환(linear transformation) : 두 벡터공간 사이의 함수로서, 덧셈과 스칼라곱을 보존하는 함수  
  - 벡터공간 `V`에서 벡터공간 `W`로 가는 함수 `L` : `V` → `W`가 다음 두 조건을 만족하면 `L`을 **선형변환**(linear transformation, linear map)이라고 한다.  
    - (1) 모든 `x`, `y` ∈ `V`에 대해 `L(x + y)` = `L(x)` + `L(y)` ∈ `W`이다.  
    - (2) 모든 `x` ∈ `V`와 스칼라 `α`에 대해 `L(αx)` = `αL(x)` ∈ `W`이다.  
    ![linear transformation][def2]  

<br>

- 선형변환과 행렬의 관계
  - 두 벡터공간 `V` = `ℝ`<sup>`n`</sup>, `W` = `ℝ`<sup>`m`</sup>과 실수 위에서 정의된 `m` x `n` 행렬 `A`가 주어졌다고 하자. 그러면 `n`x`1` 열벡터 `x` ∈ `ℝ`<sup>`n`</sup>에 대해 `L(x)` = `Ax` ∈ `ℝ`<sup>`m`</sup>으로 정의한 함수 `L`은 선형변환이다.  
  - 즉 임의의 선형변환은 행렬곱으로 표현할 수 있다.  

- `L(x)` = `Ax`에서 행렬 `A`를 선형변환 `L`의 **표준행렬**(standard matrix)이라고 한다.  

<br>

- [아래 선형변환들에 대한 더 자세한 설명들은 컴퓨터 그래픽스에서 확인][def]

- **반사변환**(reflection transformation) : `ℝ`<sup>`2`</sup>의 벡터 `(x, y)`를 `x`축 또는 `y`축을 기준으로 반사하는 선형변환  
  - `x`축을 기준으로 반사하는 변환의 표준행렬 : ![reflection_x][def3]  
  - `y`축을 기준으로 반사하는 변환의 표준행렬 : ![reflection_y][def4]  

- **회전변환**(rotation transformation) : `ℝ`<sup>`2`</sup>의 벡터 `(x, y)`를 반시계방향으로 각 `θ`만큼 회전하는 선형변환  
  - 표준행렬 : ![rotation][def5]  

- **합성변환**(composite transformation) : 세 벡터공간 `U`, `V`, `W`에 대하여 두 선형변환 `L`<sub>`1`</sub> : `U` → `V`와 `L`<sub>`2`</sub> : `V` → `W`를 합성한 `L`<sub>`2`</sub> ∘ `L`<sub>`1`</sub> : `U` → `W`도 선형변환이다. 이를 두 선형변환 `L`<sub>`1`</sub>, `L`<sub>`2`</sub>의 **합성변환**(composite transformation)이라고 한다.  
![composite_transformation][def6]  

- **항등변환**(identity linear transformation) : 벡터공간 `V`와 임의의 벡터 `x` ∈ `V`에 대하여 `I`<sub>`V`</sub>: `V` → `V`, `I`<sub>`V`</sub>(`x`) = `x`를 만족하는 선형변환 `I`<sub>`V`</sub>를 **항등변환**(identity linear transformation)이라고 한다.  
  - `ℝ`<sup>`n`</sup>에서의 항등변환의 표준행렬은 `n` x `n` 단위행렬 `I`<sub>`n`</sub>이다.  

- **역변환**(inverse linear transformation) : 선형변환 `L`<sub>`1`</sub> : `U` → `V`와 `L`<sub>`2`</sub> : `V` → `U`에 대하여 `L`<sub>`2`</sub> ∘ `L`<sub>`1`</sub> = `I`<sub>`U`</sub>, `L`<sub>`1`</sub> ∘ `L`<sub>`2`</sub> = `I`<sub>`V`</sub>가 성립할 때, `L`<sub>`2`</sub>를 `L`<sub>`1`</sub>의 **역변환**(inverse linear transformation)이라고 한다.  
`L`<sub>`2`</sub> = `L`<sub>`1`</sub><sup>`-1`</sup>로 표기한다.  
마찬가지로 `L`<sub>`1`</sub> = `L`<sub>`2`</sub><sup>`-1`</sup>이다.  

<br>

- 선형연산자 `L` : `V` → `V`와 모든 `x`, `y` ∈ `V`에 대하여 `L(x)` · `L(y)` = `x` · `y`이면 `L`을 **직교연산자**(orthogonal linear operator)라고 한다. 참고로 `·`은 내적을 의미한다.  

- 선형연산자 `L` : `ℝ`<sup>`n`</sup> → `ℝ`<sup>`n`</sup>이 모든 `x` ∈ `ℝ`<sup>`n`</sup>에 대해 `‖L(x)‖` = `‖x‖`일 필요충분조건은 모든 `x`, `y` ∈ `ℝ`<sup>`n`</sup>에 대해 `L(x)` · `L(y)` = `x` · `y`가 성립하는 것이다.  
  - 따라서 직교연산자는 **노름을 보존하는 선형연산자**(norm-preserving linear operator)라고도 한다.  

<br>

### 2. 랭크 정리
- 선형변환 `L` : `ℝ`<sup>`n`</sup> → `ℝ`<sup>`m`</sup>의 표준행렬인 `m` x `n` 행렬 `A`에 대하여 다음과 같이 정의한다.  
  - (1) 행렬 `A`의 열벡터로 생성된 벡터공간을 `A`의 **열공간**(column space)이라 하고 `Col(A)`로 표기한다.  
  `Col(A)` :=`span{ 행렬 A의 열벡터 }` ⊆ `ℝ`<sup>`m`</sup>  
  - (2) 행렬 `A`의 행벡터로 생성된 벡터공간을 `A`의 **행공간**(row space)이라 하고 `Row(A)`로 표기한다.  
  `Row(A)` :=`span{ 행렬 A의 행벡터 }` ⊆ `ℝ`<sup>`n`</sup>  
  - (3) `L(x)` = `Ax` = `0`을 만족하는 벡터 `x` ∈ `ℝ`<sup>`n`</sup>의 집합을 `A`의 **영공간**(null space) 또는 **핵**(kernel)이라 하고 `Nul(A)`로 표기한다.  
  `Nul(A)` := `{ x ∈ ℝ`<sup>`n`</sup>`| Ax = 0 }` ⊆ `ℝ`<sup>`n`</sup>  

- Example  
![rank_example][def7]   

- `m` x `n` 행렬 `A`의 열공간의 차원을 `A`의 **랭크**(rank)또는 **계수**라 하고 `rank(A)`로 표기한다.  
`rank(A)` = `dim(Col(A))` = `dim(Row(A))`  

- Summary  
![rank_summary_1][def8]  
![rank_summary_2][def9]  

- 선형변환 `L` : `ℝ`<sup>`n`</sup> → `ℝ`<sup>`m`</sup>의 표준행렬 `A`의 영공간은 정의역 `ℝ`<sup>`n`</sup>의 부분공간이다.  

- 행렬 `A`의 영공간의 차원을 **퇴화차수**(nullity)라 하고 `nullity(A)`로 표기한다. 즉 `nullity(A)` = `dim(Nul(A))`이다.  

- `m` x `n` 행렬 `A`에 대하여 다음이 성립한다.  
`dim(Col(A)) + dim(Nul(A))` = `n`  
다시 말해 행렬 `A`의 랭크와 퇴화차수의 합은 `A`의 열벡터 개수와 같다.  
`rank(A) + nullity(A) = n`  
  - 이를 **랭크 정리**(rank theorem)라고 한다.  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown=   "1">

이 포스팅은 강원대학교 이구연 교수님의 인공지능수학 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 

[def]: https://orbit3230.github.io/2025/03/12/CG_week3/
[def2]: https://i.imgur.com/ONAIXEY.png
[def3]: https://i.imgur.com/l9MwpYy.png
[def4]: https://i.imgur.com/ztrzlRT.png
[def5]: https://i.imgur.com/XxYJejd.png
[def6]: https://i.imgur.com/yjJmzLX.png
[def7]: https://i.imgur.com/iOapLi6.png
[def8]: https://i.imgur.com/AbG49WF.png
[def9]: https://i.imgur.com/LhTddxv.png