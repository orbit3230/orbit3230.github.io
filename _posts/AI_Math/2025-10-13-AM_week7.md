---
layout: post
title: "[인공지능수학] 7주차 - 행렬 분해"
excerpt: "LU 분해, 특잇값 분해"

tags:
  - [인공지능수학, Math]

toc: true

date: 2025-10-13
last_modified_at: 2025-10-13
---
## 행렬 분해
### 1. LU 분해
- **LU 분해** : `n`차 Square matrix `A`를 Lower Triangular matrix `L`과 Upper Triangular matrix `U`의 곱인 `LU`로 나타낼 수 있을 때, 이를 행렬 `A`의 LU 분해라고 한다.  
  - LU 분해를 이용하여 연립선형방정식을 풀 수도 있음

<br>

- Upper Triangular matrix를 만드는 절차
  - (1) `i`행과 `j`행을 교환
  - (2) `i`행에 `0`이 아닌 상수 `c`를 곱함
  - (3) `j`행에서 `i`행에 `c`를 곱한 것을 뺌 (단, `i` < `j`)
  - (4) 위 과정을 Upper Triangular matrix가 될 때까지 반복

- Lower Triangular matrix를 만드는 절차
  - (1) Upper Triangular matrix를 만드는 절차에서 `i`, `j`, `c`를 기억
  - (2) Identity matrix의 `i`행에 `c`를 곱한 것을 `j`행에 더함 (단, `i` < `j`)
  - (3) 이렇게 만들어진 기본행렬들을 모두 곱함

<br>

- `n`차 Identity matrix `I`에 세 가지 행 연산 중에서 하나를 적용하여 얻은 행렬을 **기본행렬**(elementary matrix)이라고 한다.  
  - (1) 유형 I : Identity matrix에서 `i`행과 `j`행을 교환한 행렬 `E`<sub>`ij`</sub>  
  - (2) 유형 II : Identity matrix에서 `i`행에 `0`이 아닌 상수 `k`를 곱한 행렬 `E`<sub>`i`</sub><sup>`(k)`</sup>  
  - (3) 유형 III : Identity matrix에서 `i`행에 `k`를 곱한 것을 `j`행에 더한 행렬 `E`<sub>`ij`</sub><sup>`(k)`</sup> (단, `i` < `j`)  

- 모든 기본행렬은 invertible하다.
- 유형 II의 기본행렬은 diagonal matrix이다.  
- 유형 III의 기본행렬은 대각 성분이 모두 `1`인 lower triangular matrix이다.  

<br>

- `n`차 Square matrix `A`에 유형 III의 기본행렬 `E`<sub>`ij`</sub><sup>`(k)`</sup>를 적용하여 Upper Triangular matrix로 만들 수 있으면, 행렬 `A`는 LU 분해가 가능하다.  

<br>

- `A = LU`로 LU 분해를 할 수 없는 경우, **치환행렬**(permutation matrix) `P`를 도입하여 `A = PLU`로 PLU 분해를 할 수 있다.  
  - 치환행렬 : `0`과 `1`로 이루어진 Square matrix로, 각 행과 각 열에 `1`이 하나씩만 존재하는 행렬 (like sudoku)
  - `A`에 치환행렬을 곱하면 `A`의 행들이 서로 교환된다.
  - 따라서 사실상 `PA = LU`로 표현하는 것이 더 자연스럽다.  

<br>

### 2. 특잇값 분해
- **특잇값**(singular value) : `m`×`n` 실수행렬 `A`에 대하여, 행렬 `A`<sup>`T`</sup>`A`의 고윳값 `λ`에 대한 양의 제곱근 `σ` = `√λ`를 행렬 `A`의 특잇값이라고 한다.
  - `A`<sup>`T`</sup>`A`의 고윳값은 모두 `0` 이상이다.  

- **특잇값 분해**(singular value decomposition, SVD) : `A`가 `m` × `n` 실수행렬일 때, `m`차 Orthogonal matrix `U`와 `n`차 Orthogonal matrix `V`, 그리고 행렬 `A`의 특잇값들을 큰 것부터 순서대로 main diagonal element에 대입한 `m` x `n` rectangular diagonal matrix `Σ`에 대하여, 행렬 `A`를 `A = UΣV`<sup>`T`</sup>로 나타낼 수 있을 때, 이를 행렬 `A`의 특잇값 분해라고 한다.  

<br>

- `A`가 `m` x `n` 실수행렬이라고 하자. `i` = `1`, ... `n`에 대하여 행렬 `A`<sup>`T`</sup>`A`의 고윳값이 `λ`<sub>`i`</sub>이고, 이에 대응하는 고유벡터 `x`<sub>`i`</sub>가 `||x`<sub>`i`</sub>`||`를 만족할 때, `{Ax`<sub>`1`</sub>, `Ax`<sub>`2`</sub>, ..., `Ax`<sub>`n`</sub>`}`은 직교집합이다.  
이때 `||Ax`<sub>`i`</sub>`||` = `√λ`<sub>`i`</sub> = `σ`<sub>`i`</sub> 이다.  

<br>

- 임의의 `m` x `n` 실수행렬 `A`에 대하여 특잇값 분해 `A` = `UΣV`<sup>`T`</sup>는 항상 존재한다.  

- 임의의 `m` x `n` 실수행렬 `A`를 `A` = `UΣV`<sup>`T`</sup>로 특잇값 분해하였을 때, 특잇값 분해를 구성하는 행렬 `V`는 행렬 `A`<sup>`T`</sup>`A`의 고유벡터를 열로 갖는 `n`차 Orthogonal matrix이고, 행렬 `Σ`는 행렬 `A`의 특잇값을 main diagonal element로 갖는 `m` x `n` rectangular diagonal matrix이며, 행렬 `U`는 행렬 `AA`<sup>`T`</sup>의 고유벡터를 열로 갖는 `m`차 Orthogonal matrix이다.  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown=   "1">

이 포스팅은 강원대학교 이구연 교수님의 인공지능수학 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 