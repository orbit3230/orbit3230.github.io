---
layout: post
title: "[시스템 프로그래밍] 13주차 - The Memory Hierarchy (2)"
excerpt: "Example Memory Hierarchy, Cache Memory, Cache Read, Direct Mapped Cache, E-way Set Associative Cache, Fully Associative Cache, Cache misses, Flush+Reload Attack, Cache Write, Cache Performance Metrics, Performance impact of caches"

tags:
  - [시스템 프로그래밍]

toc: true

date: 2024-11-25
last_modified_at: 2024-11-28
---
## Cache memory organization and operation
### 1. Example Memoty Hierarchy
![memory_hierarchy][def]  

<br>

### 2. Cache Memory
- Cache memory는 작고 빠른 SRAM 기반 메모리로, 하드웨어에서 자동적으로 관리된다.  

- CPU는 데이터를 찾을 때 가장 먼저 cache를 본다.  

- Typical system structure  
![cache_memory_structure][def2]  

<br>

- 일반적인 Cache 구조 (S, E, B)  
![cache_structure][def3]  

  - S : Set의 수  
  - E : Set당 Line의 수  
  - B : Block의 크기 (cache block 당 `2`<sup>`b`</sup> bytes)  
  - Cache size = `S` x `E` x `B` data bytes  

  <br>

### 3. Cache Read
- Cache를 읽는 과정은 다음과 같다.  
  - 데이터가 cache의 어느 address에 있을 지는 데이터의 일부인 `t` bits, `s` bits, `b` bits 로 결정한다.  
  ![cache_read][def4]

  - `set index`번째 set 내에 일치하는 `tag`를 가진 line이 있는 지 확인한다.  

  - 만약 존재하고, valid bit가 1이라면, cache hit이다.  
  
  - hit이 발생하면, block의 `offset`부터 시작하는 위치에 데이터를 위치시킨다.  

#### [1] Direct Mapped Cache
- `E = 1`, 즉 set 당 line이 하나인 cache 구조이다.  

- Set Indexing & Tag searching  
![direct_mapped_cache][def5]

- Cache hit & offset
![direct_mapped_cache_hit][def6]

<br>

- 예를들어, 4-bit addresses를 가진 cache가 있다고 가정하자.  
![direct_mapped_cache_example][def7]
  - `t = 1`, `s = 2`, `b = 1`  
  - `t` : tag bits  
  - `s` : set index bits  
  - `b` : block offset bits  

- 이 때, `0`, `1`, `7`, `8`, `0` 데이터를 읽는다면 miss/hit 여부와 최종 cache sets의 모습은 다음과 같다.  
![direct_mapped_cache_example2][def8]
  - 안타깝게도 하나의 set에 하나의 line만 존재하기 때문에, `0`과 `8`은 conflict miss가 발생하여 `8`은 `0`을 쫒아냈다.  
  - 그래서 `0`이라는 데이터가 다시 읽혔지만, cache에서 쫒겨난 상태였기 때문에 miss가 발생하였다.  
  - 이와같이 Direct Mapped Cache는 conflict miss가 빈번하게 발생한다.  

<br>

#### [2] E-way Set Associative Cache  
- `E > 1`, 즉 set 당 line이 여러 개인 cache 구조이다.
- `E = 2`인 경우를 예로 들어보자.  

- Set Indexing  
![set_associative_cache][def9]

- Tag searching
![set_associative_cache_tag][def10]
  - line이 두 개이므로, comparison이 한 번 더 필요하다.  

- Cache hit & offset  
![set_associative_cache_hit][def11]

<br>

- 이번에도 4-bit addresses를 가진 cache가 있다고 가정하자. (내부 비트분배는 다름)  
![set_associative_cache_example][def12]
  - `t = 2`, `s = 1`, `b = 1`
  - `t` : tag bits
  - `s` : set index bits
  - `b` : block offset bits  

- 아까와 같은 데이터를 읽는다면 miss/hit 여부와 최종 cache sets의 모습은 다음과 같다.  
![set_associative_cache_example2][def13]
  - `0`과 `8`은 같은 set에 들어갔지만, 두 개의 line이 있기 때문에 conflict miss가 발생하지 않았다.  
  - 따라서 `0`이 다시 읽혔을 때, cache에 존재하고 있었기 때문에 hit에 성공했다.  

  <br>

#### [3] Fully Associative Cache
- Single set, multiple lines

- Tag searching  
![fully_associative_cache][def14]

- Pros and Cons
  - Pros : conflict miss가 없다.
  - Cons : line 개수 만큼의 comparison이 필요하다.  

### 4. Types of Cache misses
- (1) Cold (compulsory) miss
  - cache가 비어있어서 발생하는 miss

- (2) Conflict miss
  - 여러 데이터들이 모두 같은 level `k` block에 mapping될 때 발생하는 miss  

- (3) Capacity miss
  - 용량이 부족해서 발생하는 miss  

<br>

### 5. Flush+Reload Attack  
- 피해자와 공격자가 같은 데이터를 공유할 때,  

- 공격자가 cache line을 flush하고 피해자가 실행하길 기다렸다가,  
그러고 나서 data를 re-access 하였을 때의 속도 차이를 이용하여  
어느 데이터가 cache에 올라가 있었는 지를 알아내는 공격 방법.  

![flush_reload_attack][def15]

<br>

### 5. Cache Write
- 데이터에 대한 여러 copies들이 memory hierarchy에 존재할 수 있다.
  - L1, L2, L3, Main memory, Disk

- Write-hit이 발생하면 어떻게 write 할까?
  - (1) **Write-through**
    - 일관성이 유지되도록 memory와 cache에 동시에 write한다(동기화).
    - 느리지만, 안정적이다.
  - (2) **Wrtie-back**
    - line replacement가 일어날 때 까지 memory에 write 하는 것을 미룬다.  
    - 빠르지만, 불안정하다.

    <br>

- Write-miss가 발생하면 어떻게 write 할까?
  - (1) **Write-allocate**
    - cache에 데이터를 올리고, cache line을 업데이트 한다.  
    - 이후에 다시 읽을 때 빠르다. 하지만 누군가는 cache에서 쫒겨날 것이다.  
  - (2) **No-write-allocate**
    - memory에 바로 write 하고, cache에는 올리지 않는다.

    <br>

- 대부분은 **write-back**과 **write-allocate**를 사용한다.  

<br>

### 6. Cache Performance Metrics
- Miss Rate : cache에서 찾지 못한 메모리 참조의 비율  
  - `misses` / `accesses` = `1` - `hit rate`  
  - Typical miss rate : `3`% ~ `10`%  

- Hit Time : cache에서 line을 processor에 전달하는 시간  
  - cache에 line이 있는 지를 판별하는 시간을 포함한다.  
  - Typical hit time : `4` clock cycle for L1, `10` clock cycle for L2  

- Miss Penalty : cache miss가 발생했을 때 추가적으로 소요되는 시간  
  - Typical miss penalty : `50` ~ `200` clock cycle (증가하는 추세)  

  <br>

- 이처럼 hit과 miss의 시간 차이가 매우 크다. (almost `100x`)  

- `99%` hits는 `97%`보다 두 배는 좋다.  
  - `97%` hit rate : `1` cycle + `0.03` * `100` cycles = `4` cycles
  - `99%` hit rate : `1` cycle + `0.01` * `100` cycles = `2` cycles  

- Hit rate 대신 Miss rate라는 metric을 사용하는 이유이다.  

<br>

- Cache Friendly 코드를 작성하려면..
  - common case를 빠르게 처리하도록 작성해야 한다.  
    - 핵심 함수의 inner loops에 초점을 맞추자.

  - inner loop에서의 misses를 최소화하자.  
    - 반복된 변수 참조는 성능 향상에 좋다. (temporal locality)
    - Stride-1 참조 패턴은 성능 향상에 좋다. (spatial locality)  

    <br>

## Performance impact of caches
### 1. The Memory Mountain
- Read throughput (read bandwidth) : memory에서 1초 동안 읽어오는 데이터의 양 (`MB/s`)

- Memory mountain : spatial & temporal locality function으로 측정된 read throughput의 그래프  

<br>

- 아래와 같은 memory mountain test function을 작성해보자.  

```c
long data[MAXELEMS];

/* test - iterate over first "elems" elements of
  *        array "data" with stride of "stride", using
  *        4x4 loop unrolling
  */
int test(int elems, int stride) {
  long i, sx2=stride*2, sx3=stride*3, sx4=stride*4;
  long acc0 = 0, acc1 = 0, acc2 = 0, acc3 = 0;
  long length = elems, limit = length - sx4;

  /* Combine 4 elements at a time */
  for(i = 0; i < limit; i += sx4) {
    acc0 = acc0 + data[i];
    acc1 = acc1 + data[i+stride];
    acc2 = acc2 + data[i+sx2];
    acc3 = acc3 + data[i+sx3];
  }

  /* Finish any remaining elements */
  for(; i < length; i++) {
    acc0 = acc0 + data[i];
  }
  return ((acc0 + acc1) + (acc2 + acc3));
}
```

- Memory mountain  
![memory_mountain][def16]  

<br>

### 2. Rearranging loops to improve spatial locality  
- Matrix Multiplication Example

```c
for(i = 0 ; i < n ; i++) {
  for(j = 0 ; j < n ; j++) {
    sum = 0.0;
    for(k = 0 ; k < n ; k++) {
      sum += a[i][k] * b[k][j];
    }
    c[i][j] = sum;
  }
}
```

- `N` x `N` matrices를 곱하는 함수이다.  
- 시간 복잡도는 `O(N`<sup>`3`</sup>`)`이다.  
- Cache는 여러 개의 행들을 모두 저장할 만큼 충분히 크지 못하다고 하자.  

<br>

- Remind - C 배열은 row-major order로 할당된다.  
  - 각 행은 연속된 메모리에 저장된다.  

  <br>

- 한 행의 열 단위로 순회한다면,  

```c
for(i = 0 ; i < N ; i++)
  sum += a[0][i];
```

- 연속된 elements에 접근한다.  
- 만약 block size (`B`) > `sizeof(a`<sub>`ij`</sub>`)`라면, spatial locality를 이용할 수 있다.  
  - miss rate = `sizeof(a`<sub>`ij`</sub>`)` / `B`  

  <br>

- 그러나 만약 한 열의 행 단위로 순회한다면,  

```c
for(i = 0 ; i < N ; i++)
  sum += a[i][0];
```

- 떨어져있는 elements에 접근한다.
- no spatial locality !
  - miss rate = `1` (i.e. `100`%)  

<br>

- 따라서 Matrix Multiplication 또한 variable `i`, `j`, `k`의 순서에 따라 성능이 달라질 수 있다.  

  - (1) `ijk` order  
  ![ijk_order][def17]

  - (2) `jik` order  
  ![ikj_order][def18]

  - (3) `kij` order  
  ![jik_order][def19]

  - (4) `ikj` order  
  ![kij_order][def20]

  - (5) `jki` order  
  ![jki_order][def21]

  - (6) `kji` order  
  ![kji_order][def22]  

- 각 performance를 그래프로 비교해보자면,  
![matrix_multiplication_performance][def23]  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">  

이 포스팅은 강원대학교 송원준 교수님의 시스템 프로그래밍 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.  

</div>
</details>

[def]: https://i.imgur.com/l6V9EB8.png
[def2]: https://i.imgur.com/eaNEfCN.png
[def3]: https://i.imgur.com/KCPx6DB.png
[def4]: https://i.imgur.com/LkxqKKv.png
[def5]: https://i.imgur.com/QnUANGy.png
[def6]: https://i.imgur.com/2meBwsh.png
[def7]: https://i.imgur.com/P3PyIRY.png
[def8]: https://i.imgur.com/KBFft4X.png
[def9]: https://i.imgur.com/JuJA2Dh.png
[def10]: https://i.imgur.com/yqPrUKG.png
[def11]: https://i.imgur.com/LZLzsaI.png
[def12]: https://i.imgur.com/cLXvjgX.png
[def13]: https://i.imgur.com/Hgejocv.png
[def14]: https://i.imgur.com/FDEdboX.png
[def15]: https://i.imgur.com/zqh2ihk.png
[def16]: https://i.imgur.com/NJZwghG.png
[def17]: https://i.imgur.com/Y93txYu.png
[def18]: https://i.imgur.com/1bNEwKx.png
[def19]: https://i.imgur.com/vgKst7V.png
[def20]: https://i.imgur.com/bsSDILX.png
[def21]: https://i.imgur.com/48tAg3F.png
[def22]: https://i.imgur.com/6l76Sat.png
[def23]: https://i.imgur.com/lqWZlCn.png