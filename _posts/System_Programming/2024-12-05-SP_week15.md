---
layout: post
title: "[시스템 프로그래밍] 15주차 - Program Optimization"
excerpt: "Program Optimization, Overview, Optimizing Compilers, Limitations of Optimizing Compilers, Code Motion, Reduction in Strength, Share Common Subexpressions, Optimization Blocker, Procedure Calls, Memory Aliasing, Exploiting Instruction-Level Parallelism, Benchmark Computation, Cycles Per Element (CPE), Basic Optimizations"

tags:
  - [시스템 프로그래밍]

toc: true

date: 2024-12-05
last_modified_at: 2024-12-05
---
## Program Optimization
### 1. Overview
- *단순히 asymptotic complexity를 줄이는 것 만이 성능을 향상시키는 유일한 요인은 아니다.*  

- **상수 요소들 또한 중요하다** !
  - 반드시 여러가지 단계에서 optimize를 해야한다.
    - algorithm, data representation, procedures, and loops  

- 성능을 최적화 시키려면, 반드시 시스템을 이해해야 한다.  
  - 어떻게 프로그램이 컴파일되고 실행되는 지
  - 어떻게 현대 프로세서와 메모리 시스템이 동작하는 지
  - 프로그램 성능을 어떻게 측정하고 병목을 찾는 지
  - 코드 modularity와 generality를 유지하면서 어떻게 성능을 개선할 지  

  <br>

### 2. Optimization
#### [1] Optimizing Compilers  
- 프로그램을 기계어로 효율적으로 매핑시켜야 한다.
  - register allocation
  - code selection and ordering (scheduling)
  - dead code elimination
  - eliminating minor inefficiencies

- (일반적으로) asymtotic efficiency를 향상시키는 것은 아니다.  
  - 전반적으로 가장 괜찮은 알고리즘을 선택하는 것은 프로그래머에게 달렸다.  
  - big-O는 보통 상수 요소들보다 중요하다.
    - 하지만 상수 요소들 또한 중요하다는 것이다.  

- 일련의 "optimization blockers"를 극복해야하는 어려움이 있다.  

<br>

#### Limitations of Optimizing Compilers
- 아래와 같은 근본적인 제약이 존재한다.  
  - 프로그램 동작에는 어떠한 변화는 없어야한다.  
  - 종종 난감한 조건 하에서 행동에 영향을 주는 optimization을 할 수 없도록 막힌다.  

- 프로그래머에게는 명확한 행동들이지만, language나 coding style에 의해 혼란을 줄 수 있다.  
  - e.g., Data ranges는 변수 타입이 제안하는 것 보다 더 제한적일 수 있다.  

- 대부분의 분석은 오직 procedures 내에서만 수행된다.  
  - 프로그램 전체에 대한 분석은 대부분 너무 expensive 하다.  
  - 최신 버전의 GCC는 각각의 파일에서 interprocedual 분석을 해주기는 한다.  
    - 하지만, 서로 다른 파일들 간의 코드 분석은 아니다.  

- 대부분의 분석은 오직 `static` 정보에 기반하여 이루어진다.  
  - 컴파일러는 run-time inputs를 예측하는데 어려움을 겪는다.  

- ***컴파일러는 의심이 되는 부분에 대해서는 보수적인 태도를 취한다.***  

<br>

#### [2] Code Motion
- 프로세서나 컴파일러에 관계없이, 프로그래머나 컴파일러가 할 수 있는 최적화 방법이다.  

- Code Motion  
  - 수행되는 연산의 빈도를 줄이는 것이다. 
    - 만약 항상 같은 결과를 낸다면, 반복되는 계산은 불필요하다.
    - 특히 loop로부터 코드를 밖으로 빼내는 것을 말한다.  

```c
void set_row(double *a, double *b, long i, long n) {
  long j;
  for(j = 0 ; j < n ; j++) {
    a[i * n + j] = b[j];
  }
}
```

- 위 코드에서 `i * n`은 loop 내에서 계속해서 반복되지만, 변하지 않는 연산이다.  
  - 하지만 컴파일러는 해당 연산에 대하여 값이 바뀌는지에 대한 의심을 가지기 때문에,  
  보수적인 태도를 취하여 연산을 반복 수행한다.  

- 따라서 위 코드에서 `i * n`을 loop 밖으로 빼내는 code motion을 통하여 성능을 개선할 수 있다.  

```c
long j;
int ni = n*i;
for(j = 0 ; j < n ; j++) {
  a[ni + j] = b[j];
}
```

- 여기서 추가적으로 배열 indexing 또한 상황에 따라 cache missing이 발생하는 경우 cost가 발생할 수 있기 때문에,  
배열의 시작 주소를 loop 밖으로 빼내어 추가적인 code motion을 수행할 수 있다.  

```c
long j;
long ni = n*i;
double *rowp = a + ni;
for(j = 0 ; j < n ; j++) {
  *row++ = b[j];
}
```

  <br>

#### [3] Reduction in Strength
- costly한 연산을 간단한 하나의 연산으로 대체하는 것이다.  
- 대표적으로 곱셈이나 나눗셈연산 대신, 시프트나 덧셈 연산을 이용하는 것이다.  
`16 * x` -> `x << 4`  
  - 사용하는 machine에 의존적이다.  
  - 곱셈이나 나눗셈 명령어의 cost에 의존한다.  
    - Intel Nehalem에서는 integer multiply가 3 CPU cycles를 소모한다.  

```c
for(i = 0 ; i < n ; i++) {
  inf ni = n * i;
  for(j = 0 ; j < n ; j++) {
    a[ni + j] = b[j];
  }
}
```

```c
int ni = 0;
for(i = 0 ; i < n ; i++) {
  for(j = 0 ; j < n ; j++) {
    a[ni + j] = b[j];
  }
  ni += n;
}
```

<br>

#### [4] Share Common Subexpressions
- expression의 일부를 재사용하는 것이다.  
- GCC는 `-O1` flag로 이를 수행할 수 있다.  

![share_common_subexpressions][def2]  

<br>

### 3. Optimization Blocker
#### [1] Procedure Calls
- String을 lower case로 바꾸는 함수가 있다.  

```c
void lower(char *s) {
    size_t i;
    for(i = 0 ; i < strlen(s) ; i++) {
        if(s[i] >= 'A' && s[i] <= 'Z') {
            s[i] -= ('A' - 'a');
        }
    }
}
```
- 이 함수의 performance는 Quadratic이다.  
![lower_case][def3]  

- 이는 위 함수를 Goto 형태로 바꾸어보면 이유를 더 직관적으로 알 수 있는데,  

```c
void lower(char *s) {
    size_t i = 0;
    if(i >= strlen(s)) goto done;
loop :
    if(s[i] >= 'A' && s[i] <= 'Z') {
        s[i] -= ('A' - 'a');
    }
    i++;
    if(i < strlen(s)) goto loop;
done :
    return;
}
```

- 이와 같이 컴파일러는 함수에 인자로 주어지는 `s`가 변하지 않는다는 것을 알 수 없기 때문에,  
보수적으로 판단하여 `strlen(s)`를 반복적으로 호출하게 된다.  
  - 따라서 `strlen(s)`이 `O(n)`이기 때문에, 위 함수의 performance가 Quadratic이 되는 것이다.  

- 그렇기 때문에 고정된 값으로서 `strlen(s)`을 저장해두고 사용하는 것이 성능을 향상시킨다.  

```c
void lower(char *s) {
  size_t i;
  size_t len = strlen(s);
  for(i = 0 ; i < len ; i++) {
    if(s[i] >= 'A' && s[i] <= 'Z') {
      s[i] -= ('A' - 'a');
    }
  }
}
```

- 위 코드는 Linear performance를 보인다.  

<br>

#### [2] Memory Aliasing
- 메모리는 중요하다. 아래와 같은 코드가 있을 때,  

```c
/* Sum rows is of n X n matrix */
/* and store in vector b */
void sum_rows1(double *a, double *b, int n) {
    long i, j;
    for(i = 0 ; i < n ; i++) {
        b[i] = 0;
        for(j = 0 ; j < n ; j++) {
            b[i] += a[i * n + j];
        }
    }
}
```

- 코드는 매 반복마다 `b[i]`를 읽고 쓰며 업데이트 해주고 있다.  
  - 컴파일러는 어째서 이걸 최적화 하지 못할까?  

<br>

- **Aliasing**
  - 두 개의 서로 다른 메모리 참조가 하나의 메모리 위치를 특정하는 문제이다.  
  - C에서 쉽게 발생할 수 있다.  
    - address 산술 연산을 하도록 허용하기 때문이다.  
    - storage 구조체에 직접 접근할 수가 있다.  

  - local variables를 생성하는 습관을 들이자.
    - loop 내에서 값을 누적할 때.
    - 이는 컴파일러에게 aliasing을 체크하지 않아도 되게끔 해준다.  

<br>

```c
void sum_rows2(double *a, double *b, int n) {
    long i, j;
    for(i = 0 ; i < n ; i++) {
        double val = 0;
        for(j = 0 ; j < n ; j++) {
            val += a[i * n + j];
        }
        b[i] = val;
    }
}
```

### 4. Exploiting Instruction-Level Parallelism  
- 하드웨어 또한 optimization에 도움을 줄 수 있다.

- 우선 현대의 프로세서 디자인에 대한 전반적인 이해가 필요하다.  
  - 하드웨어는 여러 instruction을 동시에 실행할 수 있다.  
- 성능은 data dependencies에 의해 제한된다.  
- 간단한 변화로 드라마틱한 성능 향상을 산출할 수 있다.  
  - 컴파일러는 종종 이런 변화를 만들어내지 못한다.
  - floating-point 산술 연산에서의 associativity와 distributivity의 부족  

  <br>

- Benchmark Computation

```c
void combine1(vec_ptr v, data_t *dest) {
    long i;
    *dest = IDENT;
    for(i = 0 ; i < vec_length(v) ; i++) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

- Data types
  - `data_t`
  - `int`, `long`, `float`, `double`

- Operations
  - `OP` and `IDENT`
  - `+` -> `0`
  - `*` -> `1`  

  <br>

#### Cycles Per Element (CPE)
- 프로그램의 성능을 표현하는 가장 간편한 방법은, vector나 list에서 일어나는 연산의 수를 측정하는 것이다.  
  - 이를 Cycles Per Element (CPE)이라고 한다.  

- 우리의 경우엔, `CPE` = cycles per `OP`

- `T` = `CPE`*`n` + Overhead
  - CPE는 그래프의 기울기를 나타낸다.  

![cpe][def4]  

<br>

```c
void combine1(vec_ptr v, data_t *dest) {
  long int i;
  *dest = IDENT;
  for(i = 0 ; i < vec_length(v) ; i++) {
    data_t val;
    get_vec_element(v, i, &val);
    *dest = *dest OP val;
  }
}
```

- 위 코드는 데이터 타입과 연산의 종류에 따라 성능이 달라지며,  
컴파일 단계 최적화의 여부에 따라서도 성능이 달라진다.  
![cpe2][def5]  

<br>

- Basic Optimizations

```c
void combine4(vec_ptr v, data_t *dest) {
  long i;
  long length = vec_length(v);
  data_t *data = get_vec_start(v);
  data_t t = IDENT;
  for(i = 0 ; i < length ; i++) {
    t = t OP data[i];
  }
  *dest = t;
}
```

- `vec_length` 함수를 loop 밖으로 이동 (code motion)  
- 각 cycle마다 bounds check 자제
- 임시 변수를 사용하여 누적값을 저장  
<br>

- 위와 같은 기본적인 최적화로 성능이 크게 향상되는 것을 볼 수 있다.  
![cpe3][def6]

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">  

이 포스팅은 강원대학교 송원준 교수님의 시스템 프로그래밍 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.  

</div>
</details>

[def]: https://i.imgur.com/9eH7d73.png
[def2]: https://i.imgur.com/9eH7d73.png
[def3]: https://i.imgur.com/bwl6kHP.png
[def4]: https://i.imgur.com/koJKQNL.png
[def5]: https://i.imgur.com/rBEySk0.png
[def6]: https://i.imgur.com/yf4VL3E.png