---
layout: post
title: "[시스템 프로그래밍] 15주차 - Program Optimization"
excerpt: "Program Optimization, Overview, Optimizing Compilers, Limitations of Optimizing Compilers, Code Motion, Reduction in Strength, Share Common Subexpressions, Optimization Blocker, Procedure Calls, Memory Aliasing, Exploiting Instruction-Level Parallelism, Benchmark Computation, Cycles Per Element (CPE), Basic Optimizations, Modern CPU Design, Superscalar Processor, Pipelined Functional Units, Haswell CPU, x86-64 Compilation of Combine4, Branch Prediction, Summary : Getting High Performance"

tags:
  - [시스템 프로그래밍]

toc: true

date: 2024-12-05
last_modified_at: 2024-12-09
---
## Program Optimization
### 1. Overview
- *단순히 asymptotic complexity를 줄이는 것 만이 성능을 향상시키는 유일한 요인은 아니다.*  

- **상수 요소들 또한 중요하다** !
  - 반드시 여러가지 단계에서 optimize를 해야한다.
    - algorithm, data representation, procedures, and loops  

- 성능을 최적화 시키려면, 반드시 시스템을 이해해야 한다.  
  - 어떻게 프로그램이 컴파일되고 실행되는 지
  - 어떻게 현대 프로세서와 메모리 시스템이 동작하는 지
  - 프로그램 성능을 어떻게 측정하고 병목을 찾는 지
  - 코드 modularity와 generality를 유지하면서 어떻게 성능을 개선할 지  

  <br>

### 2. Optimization
#### [1] Optimizing Compilers  
- 프로그램을 기계어로 효율적으로 매핑시켜야 한다.
  - register allocation
  - code selection and ordering (scheduling)
  - dead code elimination
  - eliminating minor inefficiencies

- (일반적으로) asymtotic efficiency를 향상시키는 것은 아니다.  
  - 전반적으로 가장 괜찮은 알고리즘을 선택하는 것은 프로그래머에게 달렸다.  
  - big-O는 보통 상수 요소들보다 중요하다.
    - 하지만 상수 요소들 또한 중요하다는 것이다.  

- 일련의 "optimization blockers"를 극복해야하는 어려움이 있다.  

<br>

#### Limitations of Optimizing Compilers
- 아래와 같은 근본적인 제약이 존재한다.  
  - 프로그램 동작에는 어떠한 변화는 없어야한다.  
  - 종종 난감한 조건 하에서 행동에 영향을 주는 optimization을 할 수 없도록 막힌다.  

- 프로그래머에게는 명확한 행동들이지만, language나 coding style에 의해 혼란을 줄 수 있다.  
  - e.g., Data ranges는 변수 타입이 제안하는 것 보다 더 제한적일 수 있다.  

- 대부분의 분석은 오직 procedures 내에서만 수행된다.  
  - 프로그램 전체에 대한 분석은 대부분 너무 expensive 하다.  
  - 최신 버전의 GCC는 각각의 파일에서 interprocedual 분석을 해주기는 한다.  
    - 하지만, 서로 다른 파일들 간의 코드 분석은 아니다.  

- 대부분의 분석은 오직 `static` 정보에 기반하여 이루어진다.  
  - 컴파일러는 run-time inputs를 예측하는데 어려움을 겪는다.  

- ***컴파일러는 의심이 되는 부분에 대해서는 보수적인 태도를 취한다.***  

<br>

#### [2] Code Motion
- 프로세서나 컴파일러에 관계없이, 프로그래머나 컴파일러가 할 수 있는 최적화 방법이다.  

- Code Motion  
  - 수행되는 연산의 빈도를 줄이는 것이다. 
    - 만약 항상 같은 결과를 낸다면, 반복되는 계산은 불필요하다.
    - 특히 loop로부터 코드를 밖으로 빼내는 것을 말한다.  

```c
void set_row(double *a, double *b, long i, long n) {
  long j;
  for(j = 0 ; j < n ; j++) {
    a[i * n + j] = b[j];
  }
}
```

- 위 코드에서 `i * n`은 loop 내에서 계속해서 반복되지만, 변하지 않는 연산이다.  
  - 하지만 컴파일러는 해당 연산에 대하여 값이 바뀌는지에 대한 의심을 가지기 때문에,  
  보수적인 태도를 취하여 연산을 반복 수행한다.  

- 따라서 위 코드에서 `i * n`을 loop 밖으로 빼내는 code motion을 통하여 성능을 개선할 수 있다.  

```c
long j;
int ni = n*i;
for(j = 0 ; j < n ; j++) {
  a[ni + j] = b[j];
}
```

- 여기서 추가적으로 배열 indexing 또한 상황에 따라 cache missing이 발생하는 경우 cost가 발생할 수 있기 때문에,  
배열의 시작 주소를 loop 밖으로 빼내어 추가적인 code motion을 수행할 수 있다.  

```c
long j;
long ni = n*i;
double *rowp = a + ni;
for(j = 0 ; j < n ; j++) {
  *row++ = b[j];
}
```

  <br>

#### [3] Reduction in Strength
- costly한 연산을 간단한 하나의 연산으로 대체하는 것이다.  
- 대표적으로 곱셈이나 나눗셈연산 대신, 시프트나 덧셈 연산을 이용하는 것이다.  
`16 * x` -> `x << 4`  
  - 사용하는 machine에 의존적이다.  
  - 곱셈이나 나눗셈 명령어의 cost에 의존한다.  
    - Intel Nehalem에서는 integer multiply가 3 CPU cycles를 소모한다.  

```c
for(i = 0 ; i < n ; i++) {
  inf ni = n * i;
  for(j = 0 ; j < n ; j++) {
    a[ni + j] = b[j];
  }
}
```

```c
int ni = 0;
for(i = 0 ; i < n ; i++) {
  for(j = 0 ; j < n ; j++) {
    a[ni + j] = b[j];
  }
  ni += n;
}
```

<br>

#### [4] Share Common Subexpressions
- expression의 일부를 재사용하는 것이다.  
- GCC는 `-O1` flag로 이를 수행할 수 있다.  

![share_common_subexpressions][def2]  

<br>

### 3. Optimization Blocker
#### [1] Procedure Calls
- String을 lower case로 바꾸는 함수가 있다.  

```c
void lower(char *s) {
    size_t i;
    for(i = 0 ; i < strlen(s) ; i++) {
        if(s[i] >= 'A' && s[i] <= 'Z') {
            s[i] -= ('A' - 'a');
        }
    }
}
```
- 이 함수의 performance는 Quadratic이다.  
![lower_case][def3]  

- 이는 위 함수를 Goto 형태로 바꾸어보면 이유를 더 직관적으로 알 수 있는데,  

```c
void lower(char *s) {
    size_t i = 0;
    if(i >= strlen(s)) goto done;
loop :
    if(s[i] >= 'A' && s[i] <= 'Z') {
        s[i] -= ('A' - 'a');
    }
    i++;
    if(i < strlen(s)) goto loop;
done :
    return;
}
```

- 이와 같이 컴파일러는 함수에 인자로 주어지는 `s`가 변하지 않는다는 것을 알 수 없기 때문에,  
보수적으로 판단하여 `strlen(s)`를 반복적으로 호출하게 된다.  
  - 따라서 `strlen(s)`이 `O(n)`이기 때문에, 위 함수의 performance가 Quadratic이 되는 것이다.  

- 그렇기 때문에 고정된 값으로서 `strlen(s)`을 저장해두고 사용하는 것이 성능을 향상시킨다.  

```c
void lower(char *s) {
  size_t i;
  size_t len = strlen(s);
  for(i = 0 ; i < len ; i++) {
    if(s[i] >= 'A' && s[i] <= 'Z') {
      s[i] -= ('A' - 'a');
    }
  }
}
```

- 위 코드는 Linear performance를 보인다.  

<br>

#### [2] Memory Aliasing
- 메모리는 중요하다. 아래와 같은 코드가 있을 때,  

```c
/* Sum rows is of n X n matrix */
/* and store in vector b */
void sum_rows1(double *a, double *b, int n) {
    long i, j;
    for(i = 0 ; i < n ; i++) {
        b[i] = 0;
        for(j = 0 ; j < n ; j++) {
            b[i] += a[i * n + j];
        }
    }
}
```

- 코드는 매 반복마다 `b[i]`를 읽고 쓰며 업데이트 해주고 있다.  
  - 컴파일러는 어째서 이걸 최적화 하지 못할까?  

<br>

- **Aliasing**
  - 두 개의 서로 다른 메모리 참조가 하나의 메모리 위치를 특정하는 문제이다.  
  - C에서 쉽게 발생할 수 있다.  
    - address 산술 연산을 하도록 허용하기 때문이다.  
    - storage 구조체에 직접 접근할 수가 있다.  

  - local variables를 생성하는 습관을 들이자.
    - loop 내에서 값을 누적할 때.
    - 이는 컴파일러에게 aliasing을 체크하지 않아도 되게끔 해준다.  

<br>

```c
void sum_rows2(double *a, double *b, int n) {
    long i, j;
    for(i = 0 ; i < n ; i++) {
        double val = 0;
        for(j = 0 ; j < n ; j++) {
            val += a[i * n + j];
        }
        b[i] = val;
    }
}
```

### 4. Exploiting Instruction-Level Parallelism  
- 하드웨어 또한 optimization에 도움을 줄 수 있다.

- 우선 현대의 프로세서 디자인에 대한 전반적인 이해가 필요하다.  
  - 하드웨어는 여러 instruction을 동시에 실행할 수 있다.  
- 성능은 data dependencies에 의해 제한된다.  
- 간단한 변화로 드라마틱한 성능 향상을 산출할 수 있다.  
  - 컴파일러는 종종 이런 변화를 만들어내지 못한다.
  - floating-point 산술 연산에서의 associativity와 distributivity의 부족  

  <br>

- Benchmark Computation

```c
void combine1(vec_ptr v, data_t *dest) {
    long i;
    *dest = IDENT;
    for(i = 0 ; i < vec_length(v) ; i++) {
        data_t val;
        get_vec_element(v, i, &val);
        *dest = *dest OP val;
    }
}
```

- Data types
  - `data_t`
  - `int`, `long`, `float`, `double`

- Operations
  - `OP` and `IDENT`
  - `+` -> `0`
  - `*` -> `1`  

  <br>

#### Cycles Per Element (CPE)
- 프로그램의 성능을 표현하는 가장 간편한 방법은, vector나 list에서 일어나는 연산의 수를 측정하는 것이다.  
  - 이를 Cycles Per Element (CPE)이라고 한다.  

- 우리의 경우엔, `CPE` = cycles per `OP`

- `T` = `CPE`*`n` + Overhead
  - CPE는 그래프의 기울기를 나타낸다.  

![cpe][def4]  

<br>

```c
void combine1(vec_ptr v, data_t *dest) {
  long int i;
  *dest = IDENT;
  for(i = 0 ; i < vec_length(v) ; i++) {
    data_t val;
    get_vec_element(v, i, &val);
    *dest = *dest OP val;
  }
}
```

- 위 코드는 데이터 타입과 연산의 종류에 따라 성능이 달라지며,  
컴파일 단계 최적화의 여부에 따라서도 성능이 달라진다.  
![cpe2][def5]  

<br>

- Basic Optimizations

```c
void combine4(vec_ptr v, data_t *dest) {
  long i;
  long length = vec_length(v);
  data_t *data = get_vec_start(v);
  data_t t = IDENT;
  for(i = 0 ; i < length ; i++) {
    t = t OP data[i];
  }
  *dest = t;
}
```

- `vec_length` 함수를 loop 밖으로 이동 (code motion)  
- 각 cycle마다 bounds check 자제
- 임시 변수를 사용하여 누적값을 저장  
<br>

- 위와 같은 기본적인 최적화로 성능이 크게 향상되는 것을 볼 수 있다.  
![cpe3][def6]  

<br>

### 5. Modern CPU Design
![cpu_design][def7]  

<br>

#### Superscalar Processor
- **여러 instructions를 한 cycle에 실행**할 수 있는 프로세서이다.  
instructions들은 연속적인 instruction stream에서 가져오고, 주로 dynamically scheduled 된다.  

- Benefit : 별도로 프로그래밍하는 노력 없이도, superscalar processor는 대부분의 프로그램들이 가지는 instruction level parallelism의 이점을 챙길 수 있다.  

- 현대의 대부분의 CPU들은 superscalar이다.  
  - since 1993(Intel Pentium)  

<br>

#### Pipelined Functional Units

```c
long mult_eg(long a, long b, long c, long d) {
  long p1 = a * b;
  long p2 = a * c;
  long p3 = p1 * p2;
  return p3;
}
```

- 위 세 개의 곱셈 연산들을 한꺼번에 가져와서,  
각 pipeline stages 별로 연산을 분할한다. 

- 각 stage `i`는 값을 `i+1` stage로 넘기고 나면, 다음 연산을 시작할 수 있게 된다.  

- 따라서 위 코드는 각각의 연산이 `3` cycles를 요구하지만, `7` cycles 만에 세 연산을 모두 수행할 수 있다.  
![pipeline][def8]  

<br>

- 그런데, 각 stage마다 다음 연산을 시작하기 전 약간의 gap이 존재한다.  
  - 이 gap을 제거하기 위해서, 먼저 계산해도 무방한 연산들이 존재한다면 해당 gap 타이밍에 수행하여 gap을 제거할 수도 있다.  

<br>

#### Haswell CPU
- 여러 instruction들은 parallel하게 실행될 수 있다.  
  - `2`개의 load, with address computation
  - `1`개의 store, with address computation
  - `4`개의 integer add, `1`개의 integer multiply
  - `1`개의 FP add, `2`개의 FP multiply
  - `1`개의 FP divide  

- 몇몇 instructions들은 하나의 cycle 이상이 소요되지만, pipelined 될 수는 있다.  

|Instruction|Latency|Cycles/Issue|
|:---:|:---:|:---:|
|Load / Store|4|1|
|Integer Add|1|1|
|Integer Multiply|3|1|
|Integer/Long Divide|3-30|3-30|
|Single/Double FP Multiply|5|1|
|Single/Double FP Add|3|1|
|Single/Double FP Divide|3-15|3-15|

<br>

### 6. x86-64 Compilation of `Combine4`
#### Latency Bound
- 좀 전의 Combine4 코드를 컴파일 한 결과, Inner loop는 다음과 같다. (Integer Multiply의 경우)

```s
.L519:
  imull   (%rax,%rdx,4), %ecx
  addq    $1, %rax
  cmpq    %rdx, %rbp
  jg      .L519
```

- Latency Bound는 연산의 latency를 고려한 CPE의 상한값이다.  
![latency_bound][def9]  

<br>

- 그런데 이러한 Serial Computation은 성능이 OP의 latency에 의해 결정된다.  
(Sequential Dependence)
![serial_computation][def10]

<br>

#### Loop Unrolling
- 따라서 Loop Unrolling을 통하여, 각 loop마다 더 많은 연산을 수행하도록 하여,  
loop의 반복 횟수를 줄여 최적화를 수행할 수 있다.  

- 아래는 한 번의 loop에서 두 개의 요소를 처리하는 2x1 unrolling이다.  

```c
void unroll2a_combine(vec_ptr v, data_t *dest) {
  long i;
  long length = vec_length(v);
  long limit = length - 1;
  data_t *d = get_vec_start(v);
  data_t x = IDENT;
  /* Combine 2 elements at a time */
  for(i = 0 ; i < limit ; i += 2) {
    x = (x OP d[i]) OP d[i+1];
  }
  /* Finish any remaining elements */
  for( ; i < length ; i++) {
    x = x OP d[i];
  }
  *dest = x;
}
```

- 각 iteration 마다 두 배 효율적으로 일을 수행한다.  

![loop_unrolling][def11]

- Unroll 2x1은 integer add에서는 도움이 되었다.
  - latency bound를 달성했다.  

- 하지만, 다른 연산에서는 도움이 되지 않았다.  
  - 여전히 sequential dependency가 존재한다. *Why?*

<br>

#### ILP & Throughput Bound
- Latency Bound가 ILP(Instruction Level Parallelism)의 능력을 제한하는 코드의 Data Dependency를 나타낸다면,  

- Throughput Bound는 프로세서의 기능적 유닛의 raw 연산 능력을 나타낸다.  
가령 Haswell CPU에서는 4개의 integer add를 한 cycle에 수행할 수 있고, 2개의 load를 한 cycle에 수행할 수 있다. 이를 이용한 프로세서의 가능한 최대 성능을 의미한다.  
![throughput_bound][def12]  

<br>

- 우리의 목표는 이 Throughput Bound에 도달하는 것이고,  
이를 위하여 이번엔 2x2 Unrolling을 수행해보자.  

```c
void unroll2a_combine(vec_ptr v, data_t *dest) {
  long i;
  long length = vec_length(v);
  long limit = length - 1;
  data_t *d = get_vec_start(v);
  data_t x0 = IDENT;
  data_t x1 = IDENT;
  /* Combine 2 elements at a time */
  for(i = 0 ; i < limit ; i += 2) {
    x0 = x0 OP d[i];
    x1 = x1 OP d[i+1];
  }
  /* Finish any remaining elements */
  for( ; i < length ; i++) {
    x0 = x0 OP d[i];
  }
  *dest = x0 OP x1;
}
```

![loop_unrolling2][def13]

- integer multiply, FP add, FP multiply에서 unroll 2x1에 비해 2배 성능이 향상된 것을 볼 수 있다.  
  - 두 개씩 unit을 load했고,
  - data dependency가 존재하지 않는다.  

- 다만 Integer add에서는, 성능의 향상이 다소 미미하다.
  - 이는 loop indexing과, increment가 overhead를 발생시키는 문제 등이 영향을 주기 때문이다.  

  <br>

![loop_unrolling3][def14]

- 2x2 Unrolling은 두 개의 독립적인 연산의 "stream"을 생성한다.  

- 따라서 전반적인 성능은,
  - `N`개의 elements, `D` cycles latency/OP
  - 따라서 `(N/2+1) * D` cycles : `CPE` = `D/2`
  - CPE가 에측과 맞아떨어졌다!  

  <br>

- 정리해보자면,
  - 어떠한 degree `L`로 unroll을 할 수 있고,
  - parallel에서 `K`개의 results가 누적된다.
  - 그리고 `L`은 반드시 `K`의 배수여야 한다.  

- 하지만 한계또한 존재한다.  
  - Diminishing returns : execution units의 throughput limitations를 뛰어 넘을 수는 없다.  

<br>

- 그렇다면 가장 최선의 unrolling은 어떻게 결정할 수 있을까?
  - 가능한 경우의 수들에 대하여 실험을 통해 최적의 unrolling을 찾아낼 수 있다.  
  - Case 1 - Double Multiply (Latency bound : 5.00 / Throughput bound : 0.50)  
  ![case1][def15]  
  - Case 2 - Integer Add (Latency bound : 1.00 / Throughput bound : 0.50)  
  ![case2][def16]
    - 두 경우 모두, 일정 수준 이상의 unrolling은 Diminishing returns를 초래하는 것을 볼 수 있다.  
    (overhead가 이득을 상회)  

<br>

- 따라서 최적의 Unrolling을 통하여, Throughput Bound에 근접하게 도달할 수 있겠다.  
![throughput_bound2][def17]  
  - 전혀 optimize 되지 않았던 초기와 비교했을 때, 무려 42배의 성능 향상에 성공했다.  

  <br>

### 7. Branch Prediction
- Instruction Control Unit은 반드시 실행 Unit보다 먼저 작동하여 instruction을 가져와야 한다.  
  - 그런데, 아래와 같이 branch가 존재하는 경우, 다음으로 어느 instruction을 가져올 지 알 수 없게 된다.  
  ![branch_prediction][def18]  

- 이렇게 conditional branch를 만나게되면, 어디로 fetching을 계속할 지를 결정할 수 없어진다.  
  - Branch Taken : Branch의 target으로 제어를 이동시킨다.
  - Branch Not-Taken : 다음 sequential instruction으로 계속 진행한다.

- 이는 branch/integer unit에 의해 결과가 결정될 때 까지 해결할 수 없다.  
![branch_prediction2][def19]  

<br>

- 따라서, Branch Prediction을 수행하게 된다.  
  - branch가 어디로 갈 지를 예측하는 것이다.  
  - 예측된 위치에서 instruction fetching을 재개한다.  
    - 하지만, 실제로 register나 memory data를 변경하는 것은 아니다.  
    
  ![branch_prediction3][def20]

  <br>

- Branch Prediction은 물론 실패할 수도 있다.  
  - 이러한 경우에는 Invalidate한 instruction은 읽지 않고, 다시 돌아가서 pipeline을 reload한다.  
  ![branch_prediction4][def21]  
  ![branch_prediction5][def22]  

<br>

### 8. Summary : Getting High Performance  
- 좋은 컴파일러를 사용하고, optimization flag를 사용하자.  
- 멍청하게 아무것도 하지 않는 것은 금물.
  - 숨어있는 알고리즘적 비효율성을 찾아내자.
  - compiler-frinedly code를 작성하자.
    - optimization blockers : procedure calls, memory references를 조심하자.  
  - innermost loops(대부분의 동작이 이루어지는)를 유심히 보자.

- 코드를 machine에 최적화하자.
  - 코드를 arch-friendly하게 작성하자.
  - intruction-level parallelism을 활용하자.
  - unpredictable branch를 피하자.  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">  

이 포스팅은 강원대학교 송원준 교수님의 시스템 프로그래밍 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.  

</div>
</details>

[def]: https://i.imgur.com/9eH7d73.png
[def2]: https://i.imgur.com/9eH7d73.png
[def3]: https://i.imgur.com/bwl6kHP.png
[def4]: https://i.imgur.com/koJKQNL.png
[def5]: https://i.imgur.com/rBEySk0.png
[def6]: https://i.imgur.com/yf4VL3E.png
[def7]: https://i.imgur.com/GhJRCdG.png
[def8]: https://i.imgur.com/JgYboeL.png
[def9]: https://i.imgur.com/PYyQQjo.png
[def10]: https://i.imgur.com/2tPiqiP.png
[def11]: https://i.imgur.com/ggbGSpK.png
[def12]: https://i.imgur.com/iCmqkDr.png
[def13]: https://i.imgur.com/DdyAJTX.png
[def14]: https://i.imgur.com/MiFGDQc.png
[def15]: https://i.imgur.com/2DIHIx2.png
[def16]: https://i.imgur.com/FGZrKja.png
[def17]: https://i.imgur.com/8S1gMMT.png
[def18]: https://i.imgur.com/ZUyj4C8.png
[def19]: https://i.imgur.com/6gF0BKa.png
[def20]: https://i.imgur.com/XfUjKJn.png
[def21]: https://i.imgur.com/rpI2FnK.png
[def22]: https://i.imgur.com/kqmHbv4.png