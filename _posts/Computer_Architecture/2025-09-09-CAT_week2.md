---
layout: post
title: "[컴퓨터구조] 2주차 - Computer Abstractions and Technology & Performance
excerpt: "Components of a Computer, Inside a Computer (Past & Now), Eight Great Ideas, End of Moore's Law, Future Opportunities, Understanding Performance, Relative Performance, Measuring Execution Time, CPU Clocking, CPU Time, Amdahl's Law"

tags:
  - [컴퓨터구조]

toc: true

date: 2025-09-09
last_modified_at: 2025-09-16
---
## Computer Abstractions and Technology
### 1. Components of a Computer
- Processor
- Memory
- Interconnects
  - NoC(Network-on-Chip), Processor-interconnect, large-scale network
- I/Os
  - User-interface devices: 디스플레이, 키보드, 마우스, 사운드 장치, 카메라, ...
- Storage devices: HDD, SSD, CD/DVD, ...
- Network adaptors: 이더넷, 3G/4G/5G, WiFi, Bluetooth, ...  

<br>

### 2. Inside a Computer (Past)
- Inside the Processor(CPU)  
![inside_cpu_1][def]  
  - Datapath : 데이터에 대한 연산을 수행
  - Control : Datapath와 메모리, I/O 장치들에게 무엇을 해야 할 지 지시
![inside_cpu_2][def2]  

<br>

- Inside the Memory  
  - Offchip memory controller (~2008)  
  ![offchip_memory_1][def3]  
  ![onchip_memory_2][def4]  
    - memory controller : DRAM 칩을 제어  

  - DRAM Technology  
  ![dram][def5]  

<br>

### 3. Inside a Computer (Now)
- What Happened?  
![what_happened][def6]  

<br>

- Reviewing 40 years of Moore's Law  
![moores_law][def7]  
  - 40+년간 매 해 1.4x의 performance 향상  

<br>

- Inside the Processor(CPU)
  - Status Quo (Intel I7-3960X)  
  ![inside_cpu_now][def8]  

  - Status Quo (AMD Ryzen 5000, Zen 3rd)  
  ![inside_cpu_amd][def9]  

<br>

- Inside the Memory
  - High-Bandwidth, 3D stacked memory  
  ![hmc_memory_chip_architecture][def10]  
  ![stacked_memory][def11]  

<br>

- Interconnect in CPU  
  - Interconnect는 compute unit의 수가 증가함에 따라 중요해진다.  
  ![interconnect][def12]  

  - Network-on-Chip (NoC)  
  ![noc][def13]  

  - Network-on-Chip (NoC) - Mesh topology  
  ![noc_mesh][def14]  

<br>

### 4. Eight Great Ideas
- Design for ***Moore's Law***
- Use ***Abstraction*** to Simplify Design
- Make the ***Common Case*** Fast
- Performance via ***Parallelism***
- Performance via ***Pipelining***
- Performance via ***Prediction***
- ***Hierarchy*** of Memories
- ***Dependability*** via Redundancy

<br>

#### [1] Abstractions  
![abstraction][def17]  
- 추상화는 복잡한 디테일을 숨겨 쉽게 이해하고 다룰 수 있게 한다.
- API (Application Programming Interface)
- ABI (Application Binary Interface)
- ISA (Instruction Set Architecture)

<br>

#### [2] Parallelism
- Implicit Parallelism : Instruction-Level Parallelism (ILP)  
  - 프로그래머의 관점에서, 일련의 명령어는 순차적으로 실행된다.
  - 그러나 실제로 하드웨어는 병렬로 실행한다.
  - Pipelining
  - Speculation (Prediction)
  - Caching
  - Superscalar (multiple instructions per cycle)
  - Dynamic Scheduling (out-of-order execution)

- Explicit Parallelism : Data & Thread-Level Parallelism
  - 하드웨어는 명령어를 동시에 실행하기 위해 병렬 리소스를 제공한다.
  - 왜? -> instruction-level parallelism의 한계  

<br>

### 5. End of Moore's Law  
- Uniprocessor Performance Growth (Single-core)  
![uniprocessor_performance_growth_1][def15]  
![uniprocessor_performance_growth_2][def16]  
  - 2003년 이후로 성능 향상이 거의 없음.  

  <br>

- Denard Scaling  
  - 트랜지스터의 크기가 작아짐에 따라 전력 밀도는 일정하게 유지된다는 이론.
  - `Power` = `α` * `C` * `F` * `V`<sup>`2`</sup>
    - `α` : 트랜지스터가 실제로 스위칭되는 시간의 비율
    - `C` : capacitance. 트랜지스터 크기에 비례
    - `F` : 동작 주파수 (클럭 속도)
    - `V` : 전압
  - Capacitance는 트랜지스터 크기에 비례하므로,  
  트랜지스터 크기가 작아지면 같은 전력으로 더 높은 주파수를 쓸 수 있어 성능이 향상되었다.

- End of Demand Scaling  
  - 그러나 Dennard Scaling은 누설 전류(leakage current)와 임계 전압(threshold voltage)을 고려하지 않았다.
  - 따라서 트랜지스터 당 최소 전력 소모량이 생겼다.
  - 결과적으로 발열이 심해져서 **Power Wall**에 부딪혔다.

- End of Dennard Scaling is a Crisis
  - 프로세스들은 power limit에 도달했다.  
  - 에너지 소비는 유저들에게 더 중요한 제약 조건이 되었다.  

<br>

### 6. Future Opportunities  
- Domain-Specific Architecture (DSA)  
  - 특정 도메인에 특화된 아키텍처
  - a.k.a. 'Accelerator'
  - GPU for graphic processing
  - Neural network processor for deep learning
  - Processor for software-defined network
  - [Note] 위들 모두 결국엔 general-purpose processor와 유사한 아키텍처 기법을 공유한다.

  <br>

- Domain-Specific Language (DSL)  
  - DSA는 아키텍처에 고수준 연산을 요구하지만, Python, Java, C와 같은 언어로는 어렵다. (컴파일 과정에서 결국 범용 CPU용 ISA로 변환됨)
  - 따라서 DSL은 이 과정을 가능하게 하여 DSA를 효율적으로 활용할 수 있게 한다.
  - Matlab -> 행렬 연산을 위한 언어
  - TensorFlow -> DNN(Deep Neural Network)을 위한 데이터 흐름 언어
  - P4 -> SDN(Software-Defined Network)을 위한 언어
  - Halide -> 이미지 프로세싱을 위한 언어

  <br>

- Secure Architecture & S/W  
  - Control Isolation (제어 격리)
  - Data Isolation (데이터 격리)
  - Constant-time execution (시간 예측 가능)
  - Avoiding speculative execution (투기적 실행 회피)
  - Avoiding shared resources (공유 자원 회피)

  <br>

- Energy-Efficient Architecture & H/W  
  - 명령어 개수 최소화
  - 더 적은 데이터 이동
  - 더 적은 Communications (e.g., NoC, interconnect, network)
  - Data-centric architecture (e.g., PIM(processor-in-memory))

<br>

## Performance
### 1. Understanding Performance
- Algorithm : 실행되는 연산의 수를 결정
- Programming language, compiler, architecture : 연산 당 실행되는 기계어 명령어 수를 결정
- Processor & Memory system : 명령어들이 얼마나 빠르게 실행되는지를 결정
- I/O system (including OS) : I/O 연산이 얼마나 빠르게 실행되는지를 결정  

<br>

- Execution time : Task를 수행하는 데 얼마나 걸리는 지
- Throughput : 단위 시간 당 얼마나 많은 작업을 수행하는 지
- 아래와 같은 변화에 execution time과 throughput은 어떻게 영향을 받을까?
  - 프로세서를 더 빠른 것으로 교체? -> 둘 다 향상
  - 더 많은 프로세서를 추가? -> Throughput만 향상

<br>

### 2. Relative Performance
- `Performance` = `1 / Execution Time`
- "`X`는 `Y`보다 `n`배 빠르다."  
  - `Performance(X)` / `Performance(Y)`  
  = `Execution Time(Y)` / `Execution Time(X)` = `n`  

- Example
  - 특정 Task를 수행하는 데 A 프로세서는 `10`초, B 프로세서는 `15`초가 걸린다.  
  - `Execution Time(A)` / `Execution Time(B)` = `15` / `10` = `1.5`  
  - 즉, A는 B보다 `1.5`배 빠르다.  

<br>

### 3. Measuring Execution Time
- Elapsed time
  - 총 실행 시간, 모든 측면 포함 (wall time)  
    - 프로세싱, I/O, OS overhead, Idle time
    - OS overhead : System call, context switch
  - 시스템 퍼포먼스를 결정

- CPU time
  - 특정 Job을 수행할 때 CPU가 실제로 일한 시간 (`vruntime` in `task_struct`)  
    - Discount I/O time, other jobs' shares
  - User CPU time과 System CPU time으로 나뉨
    - User CPU time : 유저 프로그램을 실행하는 데 걸린 시간
    - System CPU time : OS 커널을 실행하는 데 걸린 시간
  - 서로 다른 프로그램은 CPU/System performance에 다르게 영향을 받음
    - Batch program, interactive program  

  <br>

### 4. CPU Clocking
- Constant-rate clock에 의해 통제되는 디지털 하드웨어 시스템  
![cpu_clocking][def18]  
  - Clock period : clock cycle의 길이(지속시간)  
    - e.g., `250`ps = `0.25`ns = `250`x`10`<sup>`-12`</sup>s  
  - Clock frequency (rate) : 초 당 cycles
    - e.g., `4.0`GHz = `4000`MHz  = `4000000`kHz = `4.0`x`10`<sup>`9`</sup>Hz  

    <br>

- Scaling Governor in Linux  
`/sys/devices/system/cpu/cpuN/cpufreq`  
  - `scaling_max_freq`  
  - `scaling_cur_freq`  
  - `scaling_min_freq`  
  - `scaling_governor` -> `Documentation/admin-guide/pm/cpufreq.rst` 참고  

  <br>

### 5. CPU Time
- CPU Execution time (CPU time)
  - Task를 수행하는 데 CPU가 실제로 일한 시간  
  - I/O를 위해 기다리거나 다른 프로그램을 실행하는 시간은 제외  

- CPU Time은 다음과 같은 요소들에 의해 향상될 수 있음(줄일 수 있음)
  - clock cycle의 수 감소
  - clock rate의 증가 (즉, clock period의 감소)
  - 하드웨어 디자이너는 종종 clock rate를 cycle count와 trade-off  

- `CPU Time` = `CPU Clock Cycles` * `Clock Cycle Time`  
  = `CPU Clock Cycles` / `Clock Rate`  

- Example
  - Computer A : `2`GHz, `10`s CPU time  
  - Computer B
    - `6`s CPU time이 목표
    - clock을 더 빠르게 할 수 있지만, 그로 인해 cycle count가 `1.2`배 증가  
  - 그렇다면 Computer B의 clock은 얼마나 빨라야 하는가?
    - Computer A : `10`s = `cycles(C)` * `interval` = `C` / `rate` -> `10`s * `rate` = `20`G  
    - Computer B : `6`s = `1.2C` * `interval` = `24`G / `rate` -> `rate` = `4`GHz  

<br>

- Instruction Performance
  - Instruction Count : 프로그램이 실행하는 명령어의 수  
    - 프로그램과 ISA, 컴파일러에 의해 결정됨  

  - CPI (Cycles Per Instruction) : 명령어 하나를 실행하는 데 걸리는 clock cycle 수  
    - 만약 프로그램 내 명령어의 수가 같다면, CPU time은 CPI 값에 의해 결정됨  
    - CPU 하드웨어에 의해 결정되는 값  
    - 다른 명령어는 다른 CPI 값을 가질 수 있음  

- `CPU Time` = `Instruction Count` * `CPI` * `Clock Cycle Time`  
  = (`Instruction Count` * `CPI`) / `Clock Rate`  

- Example
  - Computer A : Cycle Time = `250`ps, CPI = `2.0`  
  - Computer B : Cycle Time = `500`ps, CPI = `1.2`
  - Same ISA
  - CPU Time A = `Instruction Count` * `CPI` * `Cycle Time` = `I` * `2.0` * `250`ps = `I` * `500`ps  
  - CPU Time B = `Instruction Count` * `CPI` * `Cycle Time` = `I` * `1.2` * `500`ps = `I` * `600`ps
  - `CPU Time B` / `CPU Time A` = (`I` * `600`ps) / (`I` * `500`ps) = `1.2`  
  - A is faster by this much  

<br>

- 각각의 instruction들은 서로 다른 cycle 수를 가질 수 있으므로  
![instruction_classes][def19]  

- 따라서 Weighted Average CPI를 사용  
![instruction_classes_example][def20]  

- Example  
  - 하드웨어 디자이너가 다음과 같이 명령어 클래스 당 CPI를 적용했다고 가정  
    - `A` : `1`
    - `B` : `2`
    - `C` : `3`   

  - 컴파일 된 두 코드 시퀀스가 명령어 클래스를 다음과 같이 사용한다고 가정  
    - Code 1 : `A`-`2`, `B`-`1`, `C`-`2`  
    - Code 2 : `A`-`4`, `B`-`1`, `C`-`1`  

  - 만약 당신이 컴파일러 개발자(디자이너)라면, 어느 코드 시퀀스를 당신의 컴파일러에 채택하겠는가?
    - 어느 코드 시퀀스가 더 많은 명령어를 실행하는가? -> Code 2 (`5` vs `6`)
    - 각 시퀀스 당 CPI는? -> (`2` * `1` + `1` * `2` + `2` * `3` = `10`) vs (`4` * `1` + `1` * `2` + `1` * `3` = `9`)
    - Average CPI는? -> Code 1 (`10 / 5 = 2.0`) vs Code 2 (`9 / 6 = 1.5`)  
    - 어느 것이 더 빠른가? -> Code 2  

    <br>

### 6. Amdahl's Law  
- Amdahl's Law의 한 가지 위험한 케이스
  - "컴퓨터의 어떤 측면을 개선하고 전체 성능에서 비례적인 향상을 기대하는 것"
  
- Amdahl's Law : "주어진 개선으로 얻어질 수 있는 성능 향상은, 개선되는 부분이 실제로 사용되는 양에 의해 제한된다."
  - 즉, 전체 성능 향상은 개선되는 부분이 차지하는 비율에 의해 제한된다.

- Example
  - `100`s 중에서 multiply 연산이 `80`s를 차지한다고 가정
  - 전체 성능을 `5`배 향상시키려면, 곱셈의 속도를 얼마나 향상시켜야 하는가?  
    - `Execution Time_improved` = `Execution time_affected` / `Amount of Improvement` + `Execution time_unaffected`
    - `20`s = `80`s / `n` + (`100` - `80`)s
    - Can not be done !  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">  

이 포스팅은 강원대학교 송원준 교수님의 컴퓨터구조 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.  

</div>
</details>

[def]: https://i.imgur.com/sRNgMq3.png
[def2]: https://i.imgur.com/QvIOslR.png
[def3]: https://i.imgur.com/sGeUlKH.png
[def4]: https://i.imgur.com/cRqDFY9.png
[def5]: https://i.imgur.com/wmORDFP.png
[def6]: https://i.imgur.com/arAWZRE.png
[def7]: https://i.imgur.com/ZOta6xP.png
[def8]: https://i.imgur.com/gUx2tSP.png
[def9]: https://i.imgur.com/2P6OmX4.png
[def10]: https://i.imgur.com/0ctAntL.png
[def11]: https://i.imgur.com/N9Ddjpj.png
[def12]: https://i.imgur.com/eI47v1o.png
[def13]: https://i.imgur.com/fYL6QpR.png
[def14]: https://i.imgur.com/SV0FWxh.png
[def15]: https://i.imgur.com/a165P4y.png
[def16]: https://i.imgur.com/IYuOXM8.png
[def17]: https://i.imgur.com/ZMUSEHp.png
[def18]: https://i.imgur.com/s3xt6oG.png
[def19]: https://i.imgur.com/VfWO488.png
[def20]: https://i.imgur.com/P1kg0cK.png