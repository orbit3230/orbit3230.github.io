---
layout: post
title: "[프로그래밍 컴퓨터 비전] Theme 5 - Multiple View Geometry"
excerpt: "Epipolar Geometry, Computing with Cameras and 3D Structure, Multiple View Reconstruction, Stereo Images"

tags:
  - [프로그래밍 컴퓨터 비전]

toc: true

date: 2026-02-08
last_modified_at: 2026-02-08
---
## Multiple View Geometry
- 챕터 목표 : Multiple View를 다루고 이들 간의 Geometric 관계를 사용하여 카메라 위치와 3D 구조를 추정하는 방법 이해하기
  - 여러 위치에서 촬영된 이미지를 사용하여 feature matches를 통해 3D 씬 포인트 뿐만 아니라 카메라 위치도 추정 가능 

### 1. Epipolar Geometry
- Multiple View Geometry : 여러 서로 다른 viewpoints에서 촬영된 이미지들 간의 대응관계가 존재할 때, 카메라와 feature 간 관계를 연구하는 분야

- 하나의 씬에 대한 두 views가 주어지고 이들 간에 대응되는 points가 있다면, 이미지의 points에 기하학적인 **제약조건**이 존재한다.  
(카메라들의 상대적인 방향(orientation)과 특성(properties), 그리고 위치(position) 때문에)  

- 여기서 이 기하학적인 관계는 **Epipolar Geometry** 라고 불리는 것으로 설명된다.  

<br>

- 카메라에 대한 사전 지식이 전혀 없다면, 내재된 모호함이 존재한다.  
  - 어떠한 3차원 point `X`에 대하여 임의의 `4`x`4` 행렬 `H`를 적용해 `HX`로 변환시키더라도,  
  카메라를 `P`에서 `PH`<sup>`-1`</sup>으로 바꾸면 원래 카메라 `P`에서와 동일한 이미지 points를 얻게 된다.  
  `x̂` = `PX` = `PH`<sup>`-1`</sup>`HX` = `P̂X̂`
    - `X` : 실제 3D point
    - `P` : 실제 카메라 행렬
    - `x̂` : 이미지 point

  - 그러니까, 대응되는 points로부터 `P`와 `X`를 복원하려 하지만 실제로는 무한히 많은 해가 존재한다.  
    - 이 중 어떤 해가 진짜인지는 카메라 내부 정보 없이는 절대 알 수 없다.
    - 그래서 **projective reconstruction** 까지만 가능하다.

  - 비유하자면, 세상을 찌그러뜨리고 늘리고 비틀어도, 카메라 위치를 그에 맞게 바꾸면 똑같은 이미지가 나올 수 있다는 뜻이다.  

<br>

- 이러한 모호함 때문에, 카메라에 homography 변환을 적용하여 문제를 단순화한다.  
여기서 homography 변환은 주로 좌표계를 바꾸기 위한 **rigid transformation**이다.  

- 한 가지 좋은 선택은, 좌표계의 원점과 축을 첫 번째 카메라에 맞추는 것이다.  
`P`<sub>`1`</sub> = `K`<sub>`1`</sub>`[I | 0]` and `P`<sub>`2`</sub> = `K`<sub>`2`</sub>`[R | t]`  
  - `[R | t]`는 `R` 행렬과 `t` 벡터를 옆으로 붙인 것 (column-wise concatenation)
  - `P`<sub>`1`</sub> : 첫 번째 카메라 행렬
  - `P`<sub>`2`</sub> : 두 번째 카메라 행렬
  - `K`<sub>`1`</sub>, `K`<sub>`2`</sub> : 각각 첫 번째, 두 번째 카메라의 내부 파라미터 행렬
  - `R` : Rotation matrix (첫 번째 카메라 좌표계에서 두 번째 카메라 좌표계로의 회전)
  - `t` : Translation vector (첫 번째 카메라 좌표계에서 두 번째 카메라 좌표계로의 이동)
  - `[I | 0]` : Do Nothing !

- 따라서 실제 `X` points의 projections인 `x`<sub>`1`</sub>과 `x`<sub>`2`</sub> (각각 `P`<sub>`1`</sub>과 `P`<sub>`2`</sub>에 의해 투영된 것)은  
반드시 하나의 수식적 제약을 만족해야한다.  
  - 이 제약은 **Epipolar Constraint** 라고 불리며, 다음과 같이 표현된다.  
  `x`<sub>`2`</sub><sup>`T`</sup>`F``x`<sub>`1`</sub> = `0`  
    - `F` : Fundamental Matrix (3x3 행렬)
    - `x`<sub>`1`</sub> : 첫 번째 이미지의 point (Homogeneous coordinates)  
    - `x`<sub>`2`</sub> : 두 번째 이미지의 point (Homogeneous coordinates)  

  - 여기서 `F` = `K`<sub>`2`</sub><sup>`-T`</sup>`S`<sub>`t`</sub>`R``K`<sub>`1`</sub><sup>`-1`</sup>  
    - `S`<sub>`t`</sub> : `t` 벡터에 해당하는 Skew-symmetric matrix  
    ![skew_symmetric_matrix][def]  
    - `F`는 rank `2`의 행렬이며, `det(F)` = `0` 이다. (따라서 역행렬이 존재하지 않음)  
    - `F`는 두 카메라 사이의 모든 기하학적 관계를 `3`x`3` 행렬 하나에 압축시킨 것이다.  

<br>

### 2. Computing with Cameras and 3D Structure

<br>

### 3. Multiple View Reconstruction

<br>

### 4. Stereo Images

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">

- Jan Erik Solem, "Programming Computer Vision with Python", 2012  
  - 본 포스팅은 위 도서의 내용을 정리한 것입니다.
  - 다른 곳으로의 무분별한 내용 복사를 자제해 주세요.  

</div>
</details> 

[def]: https://i.imgur.com/xkXuch2.png