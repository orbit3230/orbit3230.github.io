---
layout: post
title: "[컴퓨터네트워크] 13주차 - MPLS, Data Center Network"
excerpt: "Link virtualization - MPLS, Data center networking"

tags:
  - [컴퓨터네트워크]

toc: true

date: 2025-11-20
last_modified_at: 2025-12-01
---
## MPLS, Data Center Network
### 1. Link virtualization - MPLS  
- MultiProtocol Label Switching (MPLS)
  - MPLS-capablee 라우터들의 네트워크에서 작동  
  ![mpls_overview][def]  

  - IP 포워딩 speed up 
    - 고정된 길이의 identifier를 이용한 더 빠른 lookup
    - Virtual Circuit(VC) 접근법에서 영감을 얻음
    - 그러나 IP datagram은 여전히 IP address를 유지중

  - Flexible routing  
    - 트래픽 엔지니어링이 가능
    - Link failure로부터 Fast recovery 가능  

    <br>

- MPLS capable routers  
  - a.k.a. label-switched router  
  - 패킷을 오직 label 값에 기반하여 outgoing 인터페이스로 포워딩
    - IP 주소를 inspect하지 않음
    - MPLS 포워딩 테이블은 IP 포워딩 테이블과 별개

  - MPLS 포워딩 결정은 IP 포워딩 결정과는 다를 수 있다.
    - destination & source address를 사용하여, 같은 destination으로의 flow들을 다른 경로로 보낼 수 있음 (트래픽 엔지니어링)
    - 만약 link failure가 발생하면, flow를 re-route하는데 직접적으로 Pre-computed backup path를 사용할 수 있음  

- MPLS vs. IP paths
  - IP routing  
  ![ip_routing][def2]  
    - destination으로의 path는 오직 destination address에 의해 결정됨
    - 같은 destination -> 같은 path

  - MPLS routing  
  ![mpls_routing][def3]  
    - path는 source & destination address에 의해 결정됨
    - Flavor of generalized forwarding
    - **Fast reroute** : link failure 시 미리 계산된 backup path로 빠르게 전환 가능  

- MPLS signaling  
![mpls_signaling][def4]  
  - MPLS 라우팅에 사용되는 info를 전달하기 위해 OSPF, IS-IS 같은 기존 라우팅 프로토콜을 확장
    - e.g., link bandwidth, amount of "reserved" link bandwidth
  - Entry MPLS 라우터(위 그림의 `R4`)는 Resource Reservation Protocol-Traffic Engineering (RSVP-TE) 시그널링 프로토콜을 사용하여 downstream 라우터들로의 MPLS 포워딩을 셋업  

  <br>

- MPLS 포워딩 테이블  
![mpls_forwarding_table][def5]  

<br>

### 2. Data center networking
- Cloud computing  
![data_center_overview](TODO)  
  - Elastic resources
    - 리소스를 확장하고 축소
    - 사용한 만큼 지불하는 on-demand 인프라

  - Multi-tenancy
    - 여러 independent 사용자 -> 리소스 isolation이 필요
    - 공유 인프라의 비용을 분할

  - Flexible service management
    - Resilience(탄력성) : 서버와 저장공간의 failure를 isolate
    - 워크로드 마이그레이션 : 다른 위치로 task를 move

    <br>

- Large-scale data centers
  - Google data center는 전 세계에 분포  
  ![google_data_centers](TODO)  

  - Google의 lowa data center  
  ![google_iowa_data_center](TODO)  

  - Data center 내부는?  
  ![data_center_interior](TODO)  

  <br>

- Data center networks
  - 데이터 센터 내 서버들은 어떻게 연결이 되어있을까?
  - 모든 서버를 연결하는 하나의 거대한 스위치가 있을까?
  - 만약 그런 디자인(아래 그림)이라면, 어떤 문제가 있을까?  
  ![data_center_single_switch](TODO)  
    - 확장성 이슈 (제한된 포트 density)
    - 브로드캐스트 폭풍(broadcast storm) 이슈
    - isolation 이슈

  - Connectivity와 Complexity의 Trade-off 하에 다양한 토폴로지 디자인이 존재  
  ![data_center_topologies](TODO)  

- Tree-based DCN  
![tree_based_dcn](TODO)  

- Example DCN topology (META F16 data center)  
![meta_f16_dcn](TODO)  

<br>

- Application-layer routing  
![application_layer_routing](TODO)  
  - 로드 밸런서(load balancer)
    - 애플리케이션 계층 라우팅
    - 외부 클라이언트 요청을 수신
    - 데이터 센터 내 워크로드로 direct
    - 외부 클라이언트에게 결과를 리턴 (클라이언트로부터 데이터 센터 내부는 숨김)  

- Multipath  
  - 스위치, 랙 간의 풍부한 interconnection
    - 랙 간의 throughput 증가
    - Redundancy를 통해 Reliability 향상
    - e.g., Rack 1과 Rack 11 간의 두 개의 disjoint 경로 (아래 그림의 파란색, 빨간색 경로)  
    ![multipath_in_dcn](TODO)  

<br>

- Network performance metric  
![network_performance_metrics](TODO)  
  - Bisection width
    - 네트워크를 두 개의 절반으로 나누는 데 드는 최소 링크 수  
  - Bisection bandwidth
    - 네트워크를 두 개의 절반으로 나누는 데 드는 최소 Bandwidth
    - Full bisection bandwidth : 노드의 한 절반이 다른 절반과 동시에 커뮤니케이션 가능

- Oversubscription  
![oversubscription_in_dcn](TODO)  
  - 정의 : end-host 간 필요로하는 worst-case bandwidth 대비 네트워크 토폴로지의 total bisection bandwidth의 비율  
  - Example
    - `1`:`1` -> 모든 호스트가 full uplink capacity 사용 가능
    - `5`:`1` -> 오직 `20`%의 호스트 bandwidth만 사용 가능할 것
  - 일반적으로 data center subscription ratio은 `2.5`:`1` ~ `8`:`1` 사이  

- Oversubscription Example  
![oversubscription_example](TODO)  
  - `192` (`16`x`12`) 노드의 fat-tree 토폴로지
    - 2개의 `96`포트 스위치
    - 12개의 `24`포트 스위치

  - 각 `24`포트 스위치는
    - `8`개의 root로의 uplink 연결
    - `16`개의 호스트로의 downlink 연결

  - oversubscription ratio
    - Total bisection bandwidth : `1` x `48` = `48` Gbps
    - Worst-case bandwidth demand : `16` x `12` = `192` Gbps
    - Oversubscription ratio : `192` : `48` = `4` : `1`

<br>

- Factors behind DCN designs
  - Commoditization in the data center
    - 저렴한 서버&스토리지 디바이스 상품
    - 그러나 네트워크는 여전히 매우 specialized

  - 데이터 센터는 "smaller internet"이 아님
    - 하나의 admin domain, not adversarial, limited policy routing, etc.

  - Bandwidth는 종종 bottleneck
    - Data-intensive 워크로드 (big data, graph processing, machine learning, etc.)  

  <br>

- Protocol innovation in DCN
  - Link layer
    - RoCE : RDMA(Remote Direct Memory Access) over Converged Ethernet
      - DMA란, CPU 개입 없이 메모리와 디바이스 간 데이터 전송

  - Transport layer
    - Transport-layer congestion control에서 사용되는 ECN(Explicit Congestion Notification)  
      - DCTCP, DCQCN
    - Hop-by-hop congestion control과 함께 사용

  - Routing, management
    - SDN이 기업의 데이터 센터 간/센터 내에서 널리 사용됨
    - 관련성 있는 서비스와 데이터를 가능한 가깝게 위치 (tier-2, tier-1 커뮤니케이션 최소화)

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">

이 포스팅은 강원대학교 김도형 교수님의 컴퓨터네트워크 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details>

[def]: https://i.imgur.com/RJrWcsL.png
[def2]: https://i.imgur.com/TukaPW4.png
[def3]: https://i.imgur.com/qiaWN1X.png
[def4]: https://i.imgur.com/NPvOxBu.png
[def5]: https://i.imgur.com/m00kvic.png