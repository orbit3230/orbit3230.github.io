---
layout: post
title: "[데이터 분석 프로그래밍] 13주차 - Classification (2)"
excerpt: "Decision Tree, Ensemble Model"

tags:
  - [데이터 분석 프로그래밍, Python]

toc: true

date: 2024-11-26
last_modified_at: 2024-11-26
---
## Classification
### 1. Decision Tree
- Decision Tree는 결정을 도와주는 예측 분석 기법이다.  

- Tree graph의 노드들은 event나 choice를 나타내고, edge들은 decision rules나 conditions을 나타낸다.  

![decision_tree](TODO)  

<br>

- 지난번 dataset을 이용하여 Decision Tree를 만들어보자.  
![tennis_dataset](TODO)  

<br>

- Internal nodes : 특정 feature `x`<sub>`i`</sub>의 값을 test 했을 때, test의 결과에 따라 branch 된다.  

- Leaf nodes : class `h(x)`를 나타낸다.  

![decision_tree_example](TODO)  
  - feature들이 `Outlook(x`<sub>`1`</sub>`)`, `Temperature(x`<sub>`2`</sub>`)`, `Humidity(x`<sub>`3`</sub>`)`, `Wind(x`<sub>`4`</sub>`)`라고 하자.  
  - 그러면 feature vector `x` = `{Sunny, Hot, High, Strong}`은 `No`로 분류된다.  
  - `Temperature` feature는 관계가 없다.  

<br>

- Decision Algorithm의 핵심은 데이터에 기반한 decision tree를 만드는 것이다.  
  - 가장 중요한 정보는 어떻게 decision tree의 노드를 구조화 할 것인가이다.  

- Internal node는 `if`-`else`문 내 조건에 대응되고, 이 조건을 "splitting attribute" 라고 부른다.  
  - 바로 이 splitting attribute를 선택하는 것이 중요하다.  
![splitting_attribute](TODO)  

<br>

#### Selecting the Best Splitting Attribute
- 어느 attribute가 더 훌륭한 classifier인가?  

- 전체 데이터를 특정한 attribute를 기반으로 나눈다.  
![splitting_attribute_example](TODO) 
  - 만약 왼쪽처럼 각 class가 서로 다른 노드들로 나뉘어졌다면, 단 하나의 condition judgement로 class를 구분할 수 있다.  
  - 반면 오른쪽처럼 서로 다른 노드들에 섞여있다면, 재분류가 필요해질 것이다.  
 
<br>

#### Entropy
- Entropy는 불확실성을 나타내는 척도이다.  
  - Entropy는 아래와 같이 계산된다.  
  ![entropy](TODO)  
  - Examples  
  ![entropy_example](TODO)  

<br>

#### Information Gain
- Information gain은 데이터가 특정 attribute로 나뉘어 졌을 때, 얻는 이익의 양을 측정하는 수단이다.  
  - 분할 시 dataset의 purity가 얼마나 증가하는 지를 보여주고, 어느 attribute가 가장 유용한 지를 결정하는 데 사용된다.  

- Information gain은 아래와 같이 계산된다.  
![information_gain](TODO)  

<br>

#### Determine the Root Attribute
- Root attribute는 가장 큰 information gain을 가진 attribute로 선택하는 것이 좋다.    

- 각 attribute `humidity`, `outlook`, `wind`, `temperature`의 information gain을 계산해보자.  
![root_attribute_1](TODO)  
![root_attribute_2](TODO)  

- `outlook`이 가장 큰 information gain을 가지므로, Root attribute로 채택되었다.  

<br>

#### Gini Index
- CART는 decision tress에 기반한 machine learning 알고리즘이다.  
   - Gini index는 경제학에서 수입의 불평등을 측정하는데 쓰이는 지수이다.  
   - CART 알고리즘은 각 attribute의 불순도를 측정하는 데에 Gini index를 사용한다.  

- Gini index는 아래와 같이 계산된다.  
![gini_index](TODO)  
- Examples  
![gini_index_example](TODO)  

<br>

#### Decision Tree in Python
- 아래와 같은 Heart Disease dataset을 이용하여 Decision Tree를 만들어보자.  
![heart_disease_dataset](TODO)  

<br>

- Data preparation and exploration

```py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score
from sklearn import tree
import matplotlib.pyplot as plt

df.head()
df.info()
```

![heart_disease_dataset](TODO)  
![heart_disease_info](TODO)  

```py
# Categorical variables
categorical_features = ['sex', 'cp', 'fbs', 'restecg']
X = df[categorical_features]
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Create Decision tree model
clf = DecisionTreeClassifier(random, state=42)
# Model training
clf.fit(X_train, y_train)
```

```py
# Prediction
y_pred = clf.predict(X_test)
y_pred
```

![heart_disease_prediction](TODO)  

```py
# Evaluation
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print(f"\nAccuracy: {accuracy_score(y_test, y_pred):.3f}")
print(f"F1 Score: {f1_score(y_test, y_pred):.3f}")
```

![heart_disease_evaluation](TODO)  

```py
# Visualization
plt.figure(figsize=(40, 20))
tree.plot_tree(clf, feature_names=X.columns, class_names=['No Disease', 'Disease'], filled=True)
plt.show()
```

![heart_disease_tree](TODO)  

<br>

### 2. Ensemble Model
- Ensemble Learning은, machine learning에서 여러개의 learning algorithms 들을 조합하여 더 정확한 예측을 하는 방법이다.  

- 이 방식은 single model의 한계를 극복하고, 여러 모델로부터 예측을 결합하여 성능을 향상하는 데 초점을 둔다.  

![ensemble_model](TODO)  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">

이 포스팅은 강원대학교 장홍준 교수님의 데이터분석프로그래밍 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 