---
layout: post
title: "[데이터 분석 프로그래밍] 9주차 - Data Preprocessing"
excerpt: ""

tags:
  - [데이터 분석 프로그래밍, Python]

toc: true

date: 2024-10-29
last_modified_at: 2024-10-29
---
## Data Preprocessing
- 데이터 분석 수행 이전에 데이터를 정제하고 준비하는 과정  
  - 실제 세계 데이터는 일반적으로 "dirty data"이며, data 퀄리티 문제가 존재한다.  
  - 실제 세계 데이터는 종종 불완전하고, noise가 섞여 있으며, 모순이 있을 수 있다.  

- Data preprocessing은 이러한 문제를 해결하고 데이터를 분석에 적합한 형태로 바꾸는 데에 초점을 둔다.  

- 실제 세계 데이터의 특징
  - (1) Incomplete
    - Missing Values
    - Gaps in Time Series Data
    - Inconsistencies in Merged Datasets

  - (2) Noisy
    - Sensor Errors
    - Typos and Input Errors
    - Background Noise

  - (3) Inconsistent
    - 더로 다른 소스 간 측정 단위의 Inconsistencies
    - 데이터의 형식 간 Inconsistencies

### 1. Data Cleaning
- Main task
  - missing values(`NaN`) 처리
  - 중복 데이터 제거
  - 데이터 형식 일관성 유지
  - 이상치 파악 및 처리
  - 오타 수정 및 부적절한 값 정상화  
  
  <br>

- `df.info()` : DataFrame의 정보를 출력  
![df_info](TODO)  
  - `Dtype`은 각 열에 저장된 데이터의 타입을 나타낸다.  
    - `object` : 문자열
    - `int64`, `int32`, `int16` : 정수형
    - `float64`, `float32` : 실수형
    - `bool` : Boolean
    - `datetime64` : 날짜 및 시간  

<br>

- `df.describe()` : DataFrame의 numeric columns 에 대한 통계 정보를 출력  
![df_describe](TODO)  
  - `df.describe(include='object')` : 문자열 데이터에 대한 통계 정보 출력  
  ![df_describe_object](TODO)  

  <br>

#### [1] Missing Value  
- 데이터 분석에서, Missing Value는 하나 이상의 필드가 비어있는 instance를 의미한다.  

- Missing value는 데이터 분석, 통계적 모델링, 머신 러닝 알고리즘의 성능에 부정적인 영향을 미칠 수 있다.  

<br>

- **Drop Missing Values**
  - `df.dropna()` : NaN이 포함된 행을 삭제
  - `df.dropna(axis=1)` : NaN이 포함된 열을 삭제 (caution)  
  ![dropna](TODO)  

<br>

- **Handling Missing Values with Imputation** - missing values를 채우는 것
  - 가장 간단한 방법은 non-missing values 들의 mean/median/mode 값으로 채우는 것이다.  
    - `df.fillna(df.mean())` : `NaN`을 해당 열의 평균값으로 채움  
    - `SimpleInputer()` : scikit-learn에서 제공하는 missing value filling methods  
    `SimpleImputer(strategy='mean')` : `NaN`을 해당 열의 평균값으로 채움  

  - k-NN Imputation
    - k-NN 알고리즘을 사용하여 missing value를 채우는 방법  
    - `KNNImputer()` : scikit-learn에서 제공하는 k-NN Imputation method  
    `KNNImputer(n, neighbors=k)` : `NaN`을 해당 열의 k개의 가장 가까운 이웃의 평균값으로 채움

<br>

#### [2] Data Filtering
- 데이터 필터링은 데이터셋에서 매우 관련성 있거나 특정 criteria를 만족하는 데이터만 selecting하는 절차이다.  

- 불필요하거나 noisy한 정보를 제거함으로서,  
데이터의 퀄리티와 분석의 정확도를 향샹시킨다.  

<br>

- **Column Filtering**
  - `df.filter(['column_name1', 'column_name2'])` : 특정 열들만 선택  

  - 만약 하나의 column이 specify 되면, table 보다는 list로서 column을 specify 하는 편이 낫다.  
    - `df[['column_name']]` : `column_name`열만 가지는 **DataFrame**
    - `df['column_name']` : `column_name`열만 가지는 **Series** <- better  

    <br>

- **Row Filtering**
  - `df.filter([0, 1, 2], axis=0)` : 특정 행들만 선택

  - `df[2:5]` : slicing으로 행 section 선택  

  - `df[df.Team=='Liverpool']` : 특정 조건을 만족하는 행만 선택  

    - `df[df.Team.isin(['Liverpool', 'Arsenal'])]` : 특정 조건들 중 하나 이상을 만족하는 행만 선택(`or` 조건)  

    - `df[(df.Team=='Liverpool') & (df.Position=='DF')]` : 특정 조건들을 모두 만족하는 행만 선택(`and` 조건)  

<br>

#### [3] Outliers
- Outlier는 비슷한 points들의 majority와 크게 떨어진 data point를 의미한다.  
![outlier](TODO)  

- Interquartile Range (IQR)
  - IQR은 데이터의 중간 50%를 나타내는 값이다. (Q3 - Q1)  
    - Q1 : 1사분위수, 25% 지점
    - Q3 : 3사분위수, 75% 지점  

- Outlier Detection
  - `Q1 - 1.5 * IQR` 보다 작거나,  
  `Q3 + 1.5 * IQR` 보다 큰 값은 outlier로 간주한다.  

```py
attribute = 'Salary'
Q1 = df[attribute].quantile(0.25)
Q3 = df[attribute].quantile(0.75)
IQR = Q3 - Q1
outlier_step = 1.5 * IQR
df_outliers = df[(df[attribute] < Q1 - outlier_step) | (df[attribute] > Q3 + outlier_step)]
```

<br>

#### [4] Imbalanced Data
- class 간의 examples 수가 불균형한 경우.  

<br>

- **Random Undersampling**
  - majority class의 examples를 임의로 제거하여 ratio를 맞추는 방법

- **Oversampling**
  - minority class의 examples를 임의로 복제하여 ratio를 맞추는 방법  

  - **SMOTE (Synthetic Minority Oversampling Technique)**
    - 단순히 복제하는 oversampling 대신,  
  synthetic samples를 생성하는 oversampling 방법  

<br>

- `make_classification()` : artificial classification dataset을 생성하는 함수 

```py
# Creating an imbalanced dataset
X, y = make_classification(n_classes=2, class_sep=2, flip_y = 0, weights=[0.1, 0.9], n_features=20, n_clusters_per_class=1, n_samples=1000)

print("Before SMOTE: {Counter(y)}")
# Before SMOTE: Counter({1: 900, 0: 100})

sm = SMOTE(random_state=42)
X_res, y_res = sm.fit_resample(X, y)
print("After SMOTE: {Counter(y_res)}")
# After SMOTE: Counter({0: 900, 1: 900})
```

<br>

### 2. Data Transformation
#### [1] Scaling
- data의 범위를 임의적으로 조정하는 것이다.  
  - 데이터 분포의 모양은 변하지 않고,
  - 범위는 조정되되 기존 데이터의 상대적인 비율은 유지되어야 한다.  

- **Maximum Absolute Scaling**
  - 각 feature의 최댓값으로 나누어 scaling  
  `x_maxabs = x / max(abs(x))`
  - `MaxAbsScaler()` : scikit-learn에서 제공하는 Maximum Absolute Scaling method  

  ```py
  scaler = MaxAbsScaler()
  X_maxabs = scaler.fit_transform(X)
  ```

<br>

- **Min-Max Scaling**
  - 각 feature의 최솟값과의 차이를 feature의 범위로 나누어 scaling  
  `x_minmax = (x - min(x)) / (max(x) - min(x))`  
  - `MinMaxScaler()` : scikit-learn에서 제공하는 Min-Max Scaling method  

  ```py
  scaler = MinMaxScaler()
  X_minmax = scaler.fit_transform(X)
  ```

<br>

- **Standard Scaling**
  - 각 feature의 평균을 빼고, 표준편차로 나누어 scaling  
  `x_std = (x - mean(x)) / std(x)`
  - `StandardScaler()` : scikit-learn에서 제공하는 Standard Scaling method  

  ```py
  scaler = StandardScaler()
  X_std = scaler.fit_transform(X)
  ```

  <br>

- **Robust Scaling**
  - 각 feature의 median(Q2)을 빼고, IQR(Q3 - Q1)로 나누어 scaling  
  `x_robust = (x - Q2(x)) / Q3(x) - Q1(x)`  
  - `RobustScaler()` : scikit-learn에서 제공하는 Robust Scaling method  

  ```py
  scaler = RobustScaler()
  X_robust = scaler.fit_transform(X)
  ```

  <br>

#### [2] Categorical Variable Encoding
- Categorial data를 머신러닝이 가능한 데이터 형태로 변환하는 것이다.

<br>

- **One-Hot Encoding**
  - Categorical data를 binary vector로 변환하는 방법
  - 하나의 category를 column으로 만들어 해당 category에 해당하는 지의 여부를 `0`, `1`의 binary로 표기한다.  
  <br>
  - `pd.get_dummies()` : pandas에서 제공하는 One-Hot Encoding method  

  ```py
  df_encoded = pd.get_dummies(df, columns=['Color', 'Size'])
  df_encoded
  ```

  ![one_hot_encoding](TODO)

  - `0`, `1` binary result로 표기  
  
  ```py
  df_encoded = pd.get_dummies(df, columns=['Color', 'Size'], dtype=int)
  df_encoded
  ```

  ![one_hot_encoding_int](TODO)

  - Scikit-learn에서도 One-Hot Encoder를 제공한다.  
  `OneHotEncoder()` : scikit-learn에서 제공하는 One-Hot Encoding method  

  ```py
  encoder = OneHotEncoder(sparse_output=False)
  encoded_data = encoder.fit_transform(['Color', 'Size'])
  encoded_data
  ```

  ![one_hot_encoding_sklearn](TODO)  

  <br>

- **Label Encoding**
  - Categorical data를 숫자로 변환하는 방법
  - Category에 등장한 값들에 대하여 unique한 숫자 값을 부여한다.  
  <br>
  - `factorize()` : pandas에서 제공하는 Label Encoding method  

  ```py
  df['Color_encoded'] = pd.factorize(df['Color'])[0]
  df['Size_encoded'] = pd.factorize(df['Size'])[0]
  df
  ```

  ![label_encoding](TODO)

  - Scikit-learn에서도 Label Encoder를 제공한다.  
  `LabelEncoder()` : scikit-learn에서 제공하는 Label Encoding method  

  ```py
  le_color = LabelEncoder()
  le_size = LabelEncoder()
  df['Color_encoded'] = le_color.fit_transform(df['Color'])
  df['Size_encoded'] = le_size.fit_transform(df['Size'])
  df
  ```

  ![label_encoding_sklearn](TODO)  

<br>

#### [3] Ordinal Encoding
- Categorial data를 순서를 나타내는 숫자로 변환하는 방법  
  - 순서가 있는 category에 대하여 순서를 나타내는 숫자 값을 부여한다.  
  <br>
  - 우선 각 category에 대응되는 숫자 값을 dictionary로 specify 한다.
  - `map()` : dictionary를 이용하여 category를 숫자로 변환한다.  

  ```py
  education_order = {
    'High School': 1,
    'Associates': 2,
    'Bachelors': 3,
    'Masters': 4,
    'PhD': 5
  }
  income_order = {
    'Low': 1,
    'Medium': 2,
    'High': 3
  }

  df['Education_encoded'] = df['Education'].map(education_order)
  df['Income_encoded'] = df['Income'].map(income_order)
  df
  ```

  ![ordinal_encoding](TODO)

  - Scikit-learn에서도 Ordinal Encoder를 제공한다.  
  `OrdinalEncoder()` : scikit-learn에서 제공하는 Ordinal Encoding method  

  ```py
  education_categories = ['High School', 'Associates', 'Bachelors', 'Masters', 'PhD']
  income_categories = ['Low', 'Medium', 'High']
  encoder = OrdinalEncoder(categories=[education_categories, income_categories])
  df_encoded = encoder.fit_transform(df[['Education', 'Income']])

  df['Education_encoded'] = df_encoded[:, 0]
  df['Income_encoded'] = df_encoded[:, 1]
  df
  ```

  ![ordinal_encoding_sklearn](TODO)  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">

이 포스팅은 강원대학교 장홍준 교수님의 데이터분석프로그래밍 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 