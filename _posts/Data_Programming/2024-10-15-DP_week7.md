---
layout: post
title: "[데이터 분석 프로그래밍] 7주차 - Pandas"
excerpt: "Instruction to Pandas, Pandas Data Structures, Data Exploration, Data Extraction, Data Manipulation"

tags:
  - [데이터 분석 프로그래밍, Python]

toc: true

date: 2024-10-15
last_modified_at: 2024-10-15
---
## Introduction to Pandas
- ***Pandas***
  - **데이터 조작과 분석**을 위한 파이썬 오픈소스 라이브러리
  - 데이터 조작과 분석이 **쉽고 직관적**이게 디자인 되었다.  
  - 빠르고 간편한 **Data cleaning**, **exploration**, 그리고 **analysis 편의성** 제공  
  - **다양한 데이터 처리 함수**를 제공함으로써 데이터 분석을 보다 쉽게 만들어준다.  
    - Data cleaning / Missing value processing / Data transformation  
  - **NumPy를 기반**으로 만들어졌다. 가장 큰 차이는, Pandas는 table 형태의 heterogeneous data를 다루는데 특화되어 있다.  
  - **Pan**el **Da**ta 의 줄임말이다.  

<br>

- **Easy Data Import and Export**
  - 다양한 파일 포맷으로부터 손쉽게 데이터 load. (CSV, Excel, SQL, etc.)  
  - 처리한 데이터를 매끄럽게 export.

- **Data Exploration**
  - 빠른 data 요약과 통계 분석
  - 트렌드, 패턴, 이상치 파악

- **Data Cleaning** and **Preprocessing**
  - 효율적인 Missing value 처리
  - Rename, filter, or drop columns
  - 데이터를 변환하는 데에 유용한 함수 제공

- **Data Manipulation**
  - 데이터 aggregation에 `groupby` 함수 수행
  - dataset을 merge & concatenate

- **Time Series Analysis**
  - 시계열 데이터를 다루는데 훌륭한 지원  
  - 간편한 날짜/시간 데이터 처리

- **Integration with other libraries**
  - 다른 파이썬라이브러리와 매끄러운 호환성
  - NumPy, Matplotlib, Scikit-learn, etc.

  <br>

- Version check  
`!pip show pandas`

```py
import pandas as pd
print(pd.__version__)
```

- Installation  
`!pip install pandas`  

<br> 

## Pandas
### 1. Pandas Data Structures
- **DataFrame**
  - Pandas에서 **table 형태의 데이터를 저장하는 object**이다.
  - 행/열 구조의 **2차원 데이터 구조**. Excel sheet와 유사하다.
  - **여러 개의 Series**로 이루어져있다.  

- **Series**
    - Pandas에서 **1차원 데이터를 저장하는 object**이다.  
    **DataFrame의 각 열**이 Series이다.  
    - 각 데이터 조각을 **고유한 index로 관리**한다.  

    <br>

- 즉, 요약하자면 **DataFrame**은 **같은 Index를 고유하는 Series의 집합**이다.  
![dataframe_is_collection_of_series][def]  

<br>

- (1) **직접 Series를 부여**하여 DataFrame 생성  
`pd.Series()`

```py
import pandas as pd
s = pd.Series(["apple", "banana", "melon"])
print(s)
# 0     apple
# 1    banana
# 2     melon
# dtype: object
```

- `index` : labels의 집합, 각 값들을 식별하는 key
- `values` : values의 집합, 주로 같은 데이터 타입.  

```py
print("Index: ", s.index)
# Index:  RangeIndex(start=0, stop=3, step=1)
print("Values: ", s.values)
# Values:  ['apple' 'banana' 'melon']
```

- Series에 **고유한 index를 부여**할 수 있다.  
  - Pandas series를 만들 때, **직접 index를 specify** 할 수 있다.
  - index는 데이터의 각 element에 접근하도록 해주는 label이다.  

```py
s = pd.Series(["apple", "banana", "melon"], index=["A", "B", "C"])
print(s)
# A     apple
# B    banana
# C     melon
# dtype: object
```

```py
s.index = ["first", "second", "third"]
print(s)
# first     apple
# second    banana
# third      melon
# dtype: object
```

<br>

- (2) **Dataset을 Import** 하여 DataFrame 생성  
`pd.read_csv()`
  - `titanic.csv` 파일을 불러와 DataFrame을 생성해보자.

```py
from google.colab import drive
drive.mount('/content/gdrive')
titanic_df = pd.read_csv('/content/gdrive/My Drive/titanic.csv')
```

- 생성된 DataFrame은 일반적으로 매우 크기 때문에, **일부만 읽어볼 수 있는 함수**가 존재한다.  
  - `head(n = 5)` : **처음 n개**의 데이터를 읽어온다.
  - `tail(n = 5)` : **마지막 n개**의 데이터를 읽어온다.  

  ```py
  titanic_df.head(5)
  titanic_df.tail(5)
  ```  

<br>

- (3) `ndarray`로 DataFrame 생성  
`pd.DataFrame()`

```py
import numpy as np
data = np.array([
    (1, "Alice", 25),
    (2, "Bob", 30),
    (3, "Charlie", 22)
], dtype=[('ID', 'int'), ('Name', 'object'), ('Age', 'int')])
df = pd.DataFrame(data)
df
```

![ndarray_to_dataframe][def2]  

<br>

-  (4) list와 dictionary로 DataFrame 생성  
`pd.DataFrame()`

```py
data = [[1, 'Alice', 25], [2, 'Bob', 30], [3, 'Charlie', 22]]
columns = ['ID', 'Name', 'Age']
df = pd.DataFrame(data, columns=columns)
df
```

![list_to_dataframe][def2]  

```py
data = {
    'ID': [1, 2, 3],
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 22]
}
df = pd.DataFrame(data)
df
```

![dict_to_dataframe][def2]  

<br>

### 2. Data Exploration
- 데이터가 주어지면, 우리는 그 데이터에 친숙해져야 한다.  
- 데이터를 알아가는 것은 중요한 단계이다.  
- `shape`
  - DataFrame의 **dimension을 나타내는 tuple**을 반환한다. `(rows, columns)`  
  - 내 dataset의 크기를 빠르게 파악할 수 있다.  
- `info()`
  - 데이터 타입이나 non-null 데이터 개수를 포함한 **DataFrame에 대한 간결한 요약**을 제공한다.  
  - 내 dataset의 구조를 빠르게 파악할 수 있다.  

```py
titanic_df.shape
# (891, 12)
```

```py
titanic_df.info()
# <class 'pandas.core.frame.DataFrame'>
# RangeIndex: 891 entries, 0 to 890
# Data columns (total 12 columns):
#  #   Column       Non-Null Count  Dtype
# ---  ------       --------------  -----
#  0   PassengerId  891 non-null    int64
#  1   Survived     891 non-null    int64
#  2   Pclass       891 non-null    int64
#  3   Name         891 non-null
#  4   Sex          891 non-null    object
#  5   Age          714 non-null    float64
#  6   SibSp        891 non-null    int64
#  7   Parch        891 non-null    int64
#  8   Ticket       891 non-null    object
#  9   Fare         891 non-null    float64
#  10  Cabin        204 non-null    object
#  11  Embarked     889 non-null    object
# dtypes: float64(2), int64(5), object(5)
# memory usage: 83.7+ KB
```

<br>

- `describe()`
  - **수치형 데이터**에 대한 **기술 통계량**을 제공한다.
    - object types는 표시되지 않는다.
  - **count**, **mean**, **std**, **min**, **25%**, **50%**, **75%**, **max**를 제공한다.  

```py
titanic_df.describe()
```

![describe][def3]  

<br>

- `value_counts()`
  - 각 열(Series)의 **unique value의 각 빈도수**를 반환한다.  
    - 빈도수를 담은 새로운 Series로 반환된다.
  - categorical data의 **분포**를 파악할 수 있다.  

```py
titanic_df['Age'].value_counts()
```

![value_counts][def4]  

<br>

- `sample()`  
  - DataFrame에서 **임의의 데이터**를 추출한다.  
  - 주로 데이터셋의 일부를 빠르게 확인하거나 model을 train시킬 때 사용된다.  

```py
titanic_df.sample(n=5)
```

![sample](https://i.imgur.com/4CN5kdO.png)  

<br>

- `unique()`  
  - DataFrame의 특정 열(Series)에 **unique한 값들을 반환**한다.  
  - 중복 값을 제거하고 unique 값들만 확인하는데 사용된다.  

```py
titanic_df['Embarked'].unique()
# array(['S', 'C', 'Q', nan], dtype=object)
```
  
<br>

- `sort_values()`
  - DataFrame을 **특정 열을 기준으로 정렬**한다.
  - `ascending` parameter를 통해 오름차순/내림차순을 설정할 수 있다.
    - descending order : `titanic_df.sort_values(by='Fare', ascending=False)`

```py
titanic_df.sort_values(by='Fare')  # default : ascending order
```

![sort_values][def5]  

<br>

#### Exploring Data with Series
- DataFrame의 각 열들은 Series로 취급될 수 있다.  
- Series는 DataFrame 내에서 **index**와 **데이터**를 가지고 있는 1차원 데이터 column 이다.  

```py
type(titanic_df['Survived'])
# pandas.core.series.Series
type(titanic_df['Age'])
# pandas.core.series.Series

t_survived = titanic_df['Survived']
t_survived.head()
# 0    0
# 1    1
# 2    1
# 3    1
# 4    0

t_age = titanic_df['Age']
t_age.head()
# 0    22.0
# 1    38.0
# 2    26.0
# 3    35.0
# 4    35.0
# Name: Age, dtype: float64
```

<br>

#### Exploring Data with Indices
- Pandas에서 Indices는 non-numerical 할 수 있고, labels나 다른 데이터 타입으로 구성될 수 있다.  
- 이러한 flexibility는 좀 더 의미있고 contextual하게 관련성 있는 indexing을 가능하게 해준다.  

![labeled_and_non_numerical_indices](https://i.imgur.com/lONIXzc.png)  

<br>

- 특정한 column을 index로 설정할 수 있다.  
`set_index()`

```py
titanic_df.set_index('PassengerId', inplace=True)
titanic_df.head()
```

![set_index][def7]  

- Index reset  
`reset_index()`

```py
titanic_df.reset_index(inplace=True)
titanic_df.head(3)
```

![reset_index][def8]  

<br>

#### Creating and Modifying Columns
- Creating new columns  
  - assignment operator `=`를 사용하여 새로운 column과 값들을 추가할 수 있다.  
  - 기존 column을 활용하거나, 함수를 적용하거나, 아니면 list/ndarray를 활용할 수도 있다.  

```py
data = {
    'ID': [1, 2, 3],
    'Name': ['Alice', 'Bob', 'Charlie'],
    'Age': [25, 30, 22]
}
df = pd.DataFrame(data)

df['City'] = ['Seoul', 'Busan', 'Chuncheon']  # add new column (by list)
```  

<br>

- Modifying columns
  - assignment operator `=`를 사용하여 기존 column의 값들을 수정할 수 있다.  
  - Element-wise  

```py
df['Age'] = df['Age'] + 1
# 25 -> 26
# 30 -> 31
# 22 -> 23
```

<br>

- `apply()` : Pandas DataFrame의 각 행/열에 함수를 적용할 수 있게 해주는 매우 강력한 함수이다.  
  - `df.apply(func, axis=0)` : 각 열에 함수를 적용한다. (axis=0 -> default)
  - `df.apply(func, axis=1)` : 각 행에 함수를 적용한다.  
  - 특히 Lambda function과 함께 주로 사용된다.  
  `lambda arguments : expression`  

```py
df['Age Plus 1'] = df['Age'].apply(lambda x: x + 1)
df
```  

![apply_lambda_age_plus_1][def9]

```py
df['Is Adult'] = df['Age'].apply(lambda row: row['Age'] >= 25, axis=1)
```

![apply_lambda_is_adult][def10]  

<br>

### 3. Data Extraction
- `[]` (square brackets)
  - DataFrame에서 **특정 열**을 **선택**, **슬라이싱**, **Boolean Indexing**, 그리고 **추가** 하는데 사용된다.  

  <br>

- Select single column

```py
df['Name']  # Select single column
# 0      Alice
# 1        Bob
# 2    Charlie
# Name: Name, dtype: object
```

- Select multiple columns

```py
df[['ID', 'City']]  # Select multiple columns
#      ID       City
# 0   1      Seoul
# 1   2      Busan
# 2   3  Chuncheon
```

<br>

- Slicing rows based on index

```py
df[1:3]
#     ID     Name    Age     City
# 1   2       Bob       31    Busan
# 2   3    Charlie    23    Chuncheon
```

- Filter rows using Boolean Indexing

```py
df[df['Age'] > 26]
#      ID     Name   Age     City
# 1   2       Bob       31    Busan
```

- Combine multiple conditions using logical operators

```py
df[(df['Age'] > 20) & (df['City'] == 'Seoul')]
#     ID     Name   Age     City
# 0  1       Alice     26     Seoul
```

<br>

- `isin()`  
  - 주어진 DataFrame의 특정 column에 **특정 값**이 들어있는 rows를 필터링한다.  

```py
names_to_filter = ['Alice', 'Bob']
df[df['Name'].isin(names_to_filter)]
# 0      True
# 1      True
# 2     False
# Name: Name, dtype: bool
filtered_df = df[df['Name'].isin(names_to_filter)]
filtered_df
#     ID     Name   Age     City
# 0  1       Alice     26     Seoul
# 1  2       Bob       31     Busan
```

- `str.contains()`  
  - 주어진 DataFrame의 특정 column **특정 문자열**이 포함된 rows를 필터링한다.

```py
df[df['City'].str.contains('an')]
# 0      False
# 1       True
# 2       False
# Name: City, dtype: bool
filtered_df = df[df['City'].str.contains('an')]
filtered_df
#     ID     Name   Age     City
# 1  2       Bob       31     Busan
```

<br>

- `loc[]`
  - **label에 기반**하여 **rows와 columns을 선택**한다.  
  - `df.loc[row_labels, column_labels]`  
  <br>
  - Extraction with lists

  ```py
  df.loc[[0, 2], ['Name', 'Age']]
  #     Name   Age
  # 0   Alice     26
  # 2  Charlie  23
  ```

  - Extraction with slicing

  ```py
  df.loc[1:2, 'ID' : 'Age']
  #     ID     Name   Age
  # 1   2       Bob       31
  # 2   3    Charlie    23
  ```

  - Extraction using a single value

  ```py
  df.loc[0, 'Name']
  # 'Alice'
  ```

  - Select all rows and specific columns

  ```py
  df.loc[:, 'Name', 'Age']
  #     Name   Age
  # 0   Alice     26
  # 1    Bob      31
  # 2  Charlie  23
  ```

  - Select specific rows and all columns

  ```py
  df.loc[1:2, :]
  #     ID     Name   Age     City
  # 1   2       Bob       31     Busan
  # 2   3    Charlie    23     Chuncheon
  ```

  - Data extraction using Boolean conditions

  ```py
  age_condition = df['Age'] > 25
  age_condition
  # 0     True
  # 1     True
  # 2    False
  # Name: Age, dtype: bool
  filtered_df = df.loc[age_condition]
  filtered_df
  #     ID     Name   Age     City
  # 0  1       Alice     26     Seoul
  # 1  2       Bob       31     Busan

  name_condition = df['Name'] == 'Alice'
  name_condition
  # 0     True
  # 1    False
  # 2    False
  filtered_Df = df.loc[name_condition, ['Name', 'Age']]
  filtered_df
  #     Name   Age
  # 0   Alice     26
  ```

  <br>

- `iloc[]`
  - **integer-based index**를 사용하여 **rows와 columns을 선택**한다.  
  - `df.iloc[row_indices, column_indices]`  
  <br>
  
  - Extraction with lists

  ```py
  df.iloc[[0, 2], [0, 1]]
  #     ID     Name
  # 0   1      Alice
  # 2   3   Charlie
  ```

  - Extraction with slicing

  ```py
  df.iloc[0:2, 0:2]
  #     ID     Name
  # 0   1      Alice
  # 1   2       Bob
  ```

  - Extraction using a single value

  ```py
  df.iloc[0, 1]
  # 'Alice'
  ```

  - Select all rows and specific columns

  ```py
  df.iloc[:, [0, 1]]
  #    ID     Name
  # 0  1      Alice
  # 1  2       Bob
  # 2  3   Charlie
  ```

  - Select specific rows and all columns

  ```py
  df.iloc[0:2, :]
  #    ID     Name   Age     City
  # 0  1      Alice     26     Seoul
  # 1  2       Bob       31     Busan
  ```

  - Data extraction using Boolean conditions

  ```py
  age_condition = df['Age'] > 25
  age_condition
  # 0     True
  # 1     True
  # 2    False
  # Name: Age, dtype: bool
  filtered_df = df.iloc[age_condition.values, [0, 1]]
  filtered_df
  #     ID     Name
  # 0  1       Alice
  # 1  2       Bob
  ```

  - `age_condition.values`인 점에 유의하자.  
  integer-based index를 부여해야 하기 때문이다.  

  <br>

- Dropping data
  - `drop()` : DataFrame에서 **특정 행**이나 **열**을 **제거**한다.  
  - `df.drop(labels=None, axis=0, index=None, columns=None, inplace=False)`  
    - `labels` : 제거할 행/열의 label
    - `axis` : 0 (row), 1 (column)
    - `index` : 특정한 행을 지정해주는 대체 옵션
    - `columns` : 특정한 열을 지정해주는 대체 옵션
    - `inplace` : True일 경우, 원본 DataFrame을 수정한다.(위험)  

  ```py
  df_dropped = df.drop(index=1)
  df_dropped
  #     ID     Name   Age     City
  # 0  1      Alice     26     Seoul
  # 2  3   Charlie    23     Chuncheon
  ```

<br>

### 4. Data Manipulation
- Groupby and Aggregation Functions
  - `groupby()` : DataFrame을 **특정 column을 기준**으로 **group화**한다.
  - `agg()` : 여러 개의 values를 **기준을 잡아** 하나의 summary value로 **aggregation**한다.  
    - e.g., `agg("sum")`, `agg("mean")`, `agg("max")`, `agg("min")`, ...

  <br>

  ```py
  import pandas as pd
  data = {
    'Category': ['A', 'B', 'A', 'B', 'A', 'B'],
    'Value': [10, 15, 20, 25, 30, 35]
    'Name' : ['Purse', 'Shirt', 'Jacket', 'Jeans', 'Trousers', 'Backpack']
  }
  df = pd.DataFrame(data)
  df
  #   Category  Value    Name
  # 0           A        10        Purse
  # 1           B        15       Shirt
  # 2           A        20       Jacket
  # 3           B        25       Jeans
  # 4           A        30       Trousers
  # 5           B        35       Backpack
  ```

  ```py
  grouped = df.groupby('Category')
  grouped.agg('sum')
  #                  Value   Name
  # Category
  # A                 60       PurseJacketTrousers
  # B                 75       ShirtJeansBackpack
  grouped.sum()
  #                  Value   Name
  # Category
  # A                 60       PurseJacketTrousers
  # B                 75       ShirtJeansBackpack
  grouped['Value'].sum()
  # Category
  # A                 60
  # B                 75
  grouped['Value'].agg(['sum', 'mean', 'max', 'min'])
  #               sum   mean   max   min
  # Category
  # A             60     20.0       30       10
  # B             75     25.0       35       15
  ```

  <br>

- Merging
  - 두 개 이상의 datasets를 합쳐서 **하나의 dataset**로 만드는 것이다.  
  - Merge types
    - **Inner join**
      - 두 datasets에 존재하는 **공통된 key**를 기반으로 합친다.  
      - 공통된 key가 없는 Data는 제외된다.
    - **Full outer join**
      - 두 datasets에 존재하는 **모든 key**를 기반으로 합친다.
      - 공통된 key가 없는 Data는 `NaN`으로 채워진다.
    - **Left join**
      - **왼쪽** dataset의 **모든 key**를 기반으로 합친다.
      - 오른쪽 dataset에만 존재하지 않는 key는 `NaN`으로 채워진다.
    - **Right join**
      - **오른쪽** dataset의 **모든 key**를 기반으로 합친다.
      - 왼쪽 dataset에만 존재하지 않는 key는 `NaN`으로 채워진다.  
      <br>

  - `pd.merge(df1, df2, on='key', how='inner')`  
    - `df1`, `df2` : 합칠 두 개의 DataFrame
    - `on` : 합칠 기준이 되는 key
    - `how` : 합치는 방식 (inner, outer, left, right) - default : inner  

  ```py
  df1 = pd.DataFrame([
    'ID' : [1, 2, 3, 4],
    'Name' : ['Alice', 'Bob', 'Charlie', 'David'],
    'Age' : [20, 21, 22, 23]
  ])
  df2 = pd.DataFrame([
    'ID' : [1, 2, 3, 5],
    'Score' : [85, 90, 95, 80],
    'Subject' : ['Math', 'Science', 'English', 'History']
  ])
  df1
  #    ID    Name    Age
  # 0  1     Alice       20
  # 1  2     Bob         21
  # 2  3     Charlie   22
  # 3  4     David      23
  df2
  #    ID    Score    Subject
  # 0  1     85         Math
  # 1  2     90         Science
  # 2  3     95         English
  # 3  5     80         History
  ```

  - `merge()` - Inner join

  ```py
  inner_merged = pd.merge(df1, df2, on='ID', how='inner')
  inner_merged
  #    ID    Name    Age    Score    Subject
  # 0  1     Alice       20       85         Math
  # 1  2     Bob         21       90         Science
  # 2  3     Charlie   22       95         English
  ```

  - `merge()` - Full outer join

  ```py
  outer_merged = pd.merge(df1, df2, on='ID', how='outer')
  outer_merged
  #    ID    Name       Age   Score    Subject
  # 0  1     Alice        20.0   85.0       Math
  # 1  2     Bob          21.0   90.0       Science
  # 2  3     Charlie    22.0   95.0       English
  # 3  4     David       23.0   NaN        NaN
  # 4  5     NaN         NaN    80.0       History
  ```

  - `merge()` - Left join

  ```py
  left_merged = pd.merge(df1, df2, on='ID', how='left')
  left_merged
  #    ID    Name      Age   Score    Subject
  # 0  1     Alice        20    85.0       Math
  # 1  2     Bob          21    90.0       Science
  # 2  3     Charlie    22    95.0       English
  # 3  4     David       23    NaN        NaN
  ```

  - `merge()` - Right join

  ```py
  right_merged = pd.merge(df1, df2, on='ID', how='right')
  right_merged
  #    ID    Name      Age   Score    Subject
  # 0  1     Alice        20     85.0       Math
  # 1  2     Bob          21     90.0       Science
  # 2  3     Charlie    22     95.0       English
  # 3  5     NaN         NaN     80.0       History
  ```

  <br>

- **Concatenation**
  - `concat([df1, df2], axis=0)` : 두 개 이상의 DataFrame을 axis를 따라 단순**연결**한다.  

```py
df1 = pd.DataFrame({'ID' : [1, 2], 'Name' : ['John', 'Alice']})
df2 = pd.DataFrame({'ID' : [3, 4], 'Name' : ['Bob', 'Charlie']})
pd.concat([df1, df2], axis=0)
#    ID    Name
# 0  1     John
# 1  2     Alice
# 0  3     Bob
# 1  4     Charlie
pd.concat([df1, df2], axis=1)
#    ID    Name    ID    Name
# 0  1     John     3     Bob
# 1  2     Alice     4     Charlie
```

<br>

- **Missing Values**
  - `isna()` : DataFrame에서 유실값이나 N/A 값을 찾는다.  
    - 입력으로 주어진 것과 같은 shape의 boolean DataFrame을 반환한다.  
    - 반환된 DataFrame에서 `True`는 유실값을 나타낸다.  

  ```py
  data = {'A' : [1, 2, None, 4], 'B' : [5, None, 7, 8]}
  df = pd.DataFrame(data)
  df.isna()
  #         A          B
  # 0  False  False
  # 1  False   True
  # 2   True  False
  # 3  False  False
  ```

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">

이 포스팅은 강원대학교 장홍준 교수님의 데이터분석프로그래밍 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 

[def]: https://i.imgur.com/wpZ7a87.png
[def2]: https://i.imgur.com/SOCPgdp.png
[def3]: https://i.imgur.com/asBVAAs.png
[def4]: https://i.imgur.com/tEi1qT1.png
[def5]: https://i.imgur.com/xiXA26Q.png
[def6]: https://i.imgur.com/1Z2Z2Zv.png
[def7]: https://i.imgur.com/5Qw4Ikr.png
[def8]: https://i.imgur.com/UCOH5Z3.png
[def9]: https://i.imgur.com/NCDjJ4w.png
[def10]: https://i.imgur.com/xgLgxDY.png