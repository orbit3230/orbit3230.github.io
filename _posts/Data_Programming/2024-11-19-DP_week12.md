---
layout: post
title: "[데이터 분석 프로그래밍] 12주차 - Classification"
excerpt: ""

tags:
  - [데이터 분석 프로그래밍, Python]

toc: true

date: 2024-11-19
last_modified_at: 2024-11-20
---
## Classification
### 1. Evaluation Metrics for Classification Models  
- Regression : input features를 이용하여 숫자 output values의 무한한 범위를 예측하는 수단  
![regression](TODO)  

- Classification : input features를 이용하여 categorical classes를 예측하는 수단  
![classification](TODO)  

<br>

- Binary Classification : categorical labels이 두 개.
  - Example
    - 이메일이 'spam'인 지 'normal'인 지 예측
    - 환자가 'diseased'인 지 'not sick'인 지 진단
    - 스포츠 겨익에서 'win'인 지 'lose'인 지 예측  
  ![binary_classification](TODO)  

- Multiclass Classification : categorical labels이 두 개 이상.
  - Example
    - dogs, cats, birds를 각각 `0`, `1`, `2`로 표현하여 분류  
  ![multiclass_classification](TODO)  

<br>

#### Confusion Matrix  
- Confusion Matrix : 모델에 의해 예측된 label value와 실제 label value를 비교하는 표.
  - 주로 classification model의 성능을 측정하는 데 사용된다.  
  <br>
    
![confusion_matrix](TODO)  
- True Positive(TP) : 실제 값이 `1`이고 예측 값도 `1`인 경우 (`y = 1`, `ŷ = 1`)
- True Negative(TN) : 실제 값이 `0`이고 예측 값도 `0`인 경우 (`y = 0`, `ŷ = 0`)
- False Positive(FP) : 실제 값이 `0`이고 예측 값이 `1`인 경우 (`y = 0`, `ŷ = 1`)
- False Negative(FN) : 실제 값이 `1`이고 예측 값이 `0`인 경우 (`y = 1`, `ŷ = 0`)  

<br>

- **Accuracy** : 전체 데이터 중에서 정확하게 예측한 데이터의 비율  
![accuracy](TODO)  
  - `Accuracy` = `(TP + TN)` / `(TP + TN + FP + FN)`  

  - 데이터가 불균형한 imbalanced datase에서는 한계가 있다.  

- **Precision** : 모델이 `1`로 예측한 데이터 중에서 실제로 `1`인 데이터의 비율  
(positive prediction의 정확도)  
![precision](TODO)  
  - `Precision` = `TP` / `(TP + FP)`

- **Recall** : 실제 `1`인 데이터 중에서 모델이 `1`로 예측한 데이터의 비율  
![recall](TODO)  
  - `Recall` = `TP` / `(TP + FN)`  

- **F1 Score** : `Precision`과 `Recall`의 조화평균(harmonic mean)  
![f1_score](TODO)  
  - `F1 Score` = `2 * Precision * Recall` / `(Precision + Recall)`

  - imbalance datasets에서, F1 score는 작은 클래스에 대한 예측 성능을 강조한다.  

<br>

- Model Evaluation using Scikit-learn  

```py
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
```

```py
y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]
y_pred = [1, 0, 0, 1, 1, 1, 0, 1, 1, 0]
```

```py
# Create confusion matrix
cm = confusion_matrix(y_true, y_pred)
print(cm)
# [[3 2]
#  [2 3]]
```

```py
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)

print("Accuracy: ", accuracy)
print("Precision: ", precision)
print("Recall: ", recall)
print("F1 Score: ", f1)
# Accuracy:  0.7
# Precision:  0.6666666666666666
# Recall:  0.8
# F1 Score:  0.7272727272727272
```

```py
# classification_report
from sklearn.metrics import classification_report

y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]
y_pred = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]

# Print classification report
report = classification_report(y_true, y_pred)
print(report)
```

![classification_report](TODO)  

<br>

### 2. Logistic Regression  
- classification은 categorical classes를 예측하는 수단인 반면,  
**Regression**은 숫자 input data를 이용하여 real numbers를 예측하는 수단이다.  

- Linear Regression vs. Logistic Regression  
![linear_vs_logistic_regression](TODO)  
  - Linear Regression을 사용하여 표현하면, 아래와 같은 형태로 나타난다.  
  - linear regression의 결과가 sigmoid function(logistic function)의 input으로 들어가고,  
  최종 값은 `0`과 `1` 사이의 값으로 나타난다.  
  ![make_logistic_regression](TODO)  

  <br>

- Logistic regression은 sigmond function의 결과를 `0.5`를 기준으로 `0`과 `1`로  분류하여,  
예측된 class를 결정한다.  
![logistic_regression](TODO)  

<br>

- 아래와 같은 Heart Disease Dataset이 있다고 하자.  
![heart_disease_dataset](TODO)  

```py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score
import matplotlib.pyplot as plt
```

```py
df.head(3)
```

![heart_disease_dataset_head](TODO)  

```py
df.info()
```

![heart_disease_dataset_info](TODO)  

```py
print("Missing values in each column:")
print(df.isnull().sum())
```

```py
# Check the distribution of the target variable
print("Distribution of target variable:")
print(df['target'].value_counts())
```

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">

이 포스팅은 강원대학교 장홍준 교수님의 데이터분석프로그래밍 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 