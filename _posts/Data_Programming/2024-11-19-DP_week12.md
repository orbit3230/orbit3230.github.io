---
layout: post
title: "[데이터 분석 프로그래밍] 12주차 - Classification"
excerpt: "Evaluation Metrics for Classification Models, Logistic Regression"

tags:
  - [데이터 분석 프로그래밍, Python]

toc: true

date: 2024-11-19
last_modified_at: 2024-11-20
---
## Classification
### 1. Evaluation Metrics for Classification Models  
- **Regression** : input features를 이용하여 숫자 output values의 무한한 범위를 예측하는 수단  
![regression][def]  

- **Classification** : input features를 이용하여 categorical classes를 예측하는 수단  
![classification][def2]  

<br>

- Binary Classification : categorical labels이 두 개.
  - Example
    - 이메일이 'spam'인 지 'normal'인 지 예측
    - 환자가 'diseased'인 지 'not sick'인 지 진단
    - 스포츠 겨익에서 'win'인 지 'lose'인 지 예측  
  ![binary_classification][def3]  

- Multiclass Classification : categorical labels이 두 개 이상.
  - Example
    - dogs, cats, birds를 각각 `0`, `1`, `2`로 표현하여 분류  
  ![multiclass_classification][def4]  

<br>

#### Confusion Matrix  
- Confusion Matrix : 모델에 의해 예측된 label value와 실제 label value를 비교하는 표.
  - 주로 classification model의 성능을 측정하는 데 사용된다.  
  <br>
    
![confusion_matrix][def5]  
- True Positive(TP) : 실제 값이 `1`이고 예측 값도 `1`인 경우 (`y = 1`, `ŷ = 1`)
- True Negative(TN) : 실제 값이 `0`이고 예측 값도 `0`인 경우 (`y = 0`, `ŷ = 0`)
- False Positive(FP) : 실제 값이 `0`이고 예측 값이 `1`인 경우 (`y = 0`, `ŷ = 1`)
- False Negative(FN) : 실제 값이 `1`이고 예측 값이 `0`인 경우 (`y = 1`, `ŷ = 0`)  

<br>

- **Accuracy** : 전체 데이터 중에서 정확하게 예측한 데이터의 비율  
![accuracy][def6]  
  - `Accuracy` = `(TP + TN)` / `(TP + TN + FP + FN)`  

  - 데이터가 불균형한 imbalanced datase에서는 한계가 있다.  

- **Precision** : 모델이 `1`로 예측한 데이터 중에서 실제로 `1`인 데이터의 비율  
(positive prediction의 정확도)  
![precision][def7]  
  - `Precision` = `TP` / `(TP + FP)`

- **Recall** : 실제 `1`인 데이터 중에서 모델이 `1`로 예측한 데이터의 비율  
![recall][def8]  
  - `Recall` = `TP` / `(TP + FN)`  

- **F1 Score** : `Precision`과 `Recall`의 조화평균(harmonic mean)  
![f1_score][def9]  
  - `F1 Score` = `2 * Precision * Recall` / `(Precision + Recall)`

  - imbalance datasets에서, F1 score는 작은 클래스에 대한 예측 성능을 강조한다.  

<br>

- Model Evaluation using Scikit-learn  

```py
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
```

```py
y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]
y_pred = [1, 0, 0, 1, 1, 1, 0, 1, 1, 0]
```

```py
# Create confusion matrix
cm = confusion_matrix(y_true, y_pred)
print(cm)
# [[3 2]
#  [2 3]]
```

```py
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)

print("Accuracy: ", accuracy)
print("Precision: ", precision)
print("Recall: ", recall)
print("F1 Score: ", f1)
# Accuracy:  0.7
# Precision:  0.6666666666666666
# Recall:  0.8
# F1 Score:  0.7272727272727272
```

```py
# classification_report
from sklearn.metrics import classification_report

y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]
y_pred = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]

# Print classification report
report = classification_report(y_true, y_pred)
print(report)
```

![classification_report][def10]  

<br>

### 2. Logistic Regression  
- classification은 categorical classes를 예측하는 수단인 반면,  
**Regression**은 숫자 input data를 이용하여 real numbers를 예측하는 수단이다.  

- Linear Regression vs. Logistic Regression  
![linear_vs_logistic_regression][def11]  
  - Linear Regression을 사용하여 표현하면, 아래와 같은 형태로 나타난다.  
  - linear regression의 결과가 sigmoid function(logistic function)의 input으로 들어가고,  
  최종 값은 `0`과 `1` 사이의 값으로 나타난다.  
  ![make_logistic_regression][def12]  

  <br>

- Logistic regression은 sigmond function의 결과를 `0.5`를 기준으로 `0`과 `1`로  분류하여,  
예측된 class를 결정한다.  
![logistic_regression][def13]  

<br>

- 아래와 같은 Heart Disease Dataset이 있다고 하자.  
![heart_disease_dataset][def14]  

```py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score
import matplotlib.pyplot as plt
```

```py
df.head(3)
```

![heart_disease_dataset_head][def15]  

```py
df.info()
```

![heart_disease_dataset_info][def16]  

```py
print("Missing values in each column:")
print(df.isnull().sum())
```

![heart_disease_dataset_missing][def17]

```py
# Check the distribution of the target variable
print("Distribution of target variable:")
print(df['target'].value_counts())
```

![heart_disease_dataset_target][def18]

```py
# Divide the entire data into training data and test data
X = df[['thalach']]
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling (Standardization)
scalar = StandardScaler()
X_train_scaled = scalar.fit_transform(X_train)
X_test_scaled = scalar.transform(X_test)
```

- StandardScaler는 데이터를 평균이 0, 표준편차가 1인 표준 정규분포를 따르도록 변환한다.  
  - `fit_transform(X_train)` : training data를 scaling하고 변환
  - `transform(X_test)` : test data를 scaling하고 변환

```py
# initialized the Logistic Regression model
model = LogisticRegression(max_iter=1000)
# Train the model
model.fit(X_train_scaled, y_train)
```

```py
# Predict using the test set
y_pred = model.predict(X_test_scaled)
y_pred
```

![heart_disease_dataset_predict][def19]  

<br>

- Evaluate the model 

```py
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print(f"\nAccuracy: {accuracy_score(y_test, y_pred):.3f}")
print(f"F1 Score: {f1_score(y_test, y_pred):.3f}")
```

![heart_disease_dataset_evaluation][def20]  

- Understanding the model

```py
print(model.predict(X_test_scaled[:5]))
# [1 0 0 1 1]

print(model.predict_proba(X_test_scaled[:5]))
#  [[0.33684463, 0.66315537]
#   [0.82431009, 0.17568991]
#   [0.53900003, 0.46099997]
#   [0.34726783, 0.65273217]
#   [0.48119213, 0.51880787]]

print(model.coef_, model.intercept_)
# [[1.06129273]] [0.04521758]
```



<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">

이 포스팅은 강원대학교 장홍준 교수님의 데이터분석프로그래밍 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 

[def]: https://i.imgur.com/0ve69nM.png
[def2]: https://i.imgur.com/O6F3T3T.png
[def3]: https://i.imgur.com/iH2onU7.png
[def4]: https://i.imgur.com/mNTuKNf.png
[def5]: https://i.imgur.com/fZtamfF.png
[def6]: https://i.imgur.com/GTmeBxz.png
[def7]: https://i.imgur.com/wm0twFZ.png
[def8]: https://i.imgur.com/RsQbnpO.png
[def9]: https://i.imgur.com/Rn6nyrr.png
[def10]: https://i.imgur.com/3mSwAzg.png
[def11]: https://i.imgur.com/iwq5BJ6.png
[def12]: https://i.imgur.com/fQJGNQV.png
[def13]: https://i.imgur.com/Q87MhrH.png
[def14]: https://i.imgur.com/lyNcdT0.png
[def15]: https://i.imgur.com/GfpuNJQ.png
[def16]: https://i.imgur.com/NOoaGs1.png
[def17]: https://i.imgur.com/7B6Bkwh.png
[def18]: https://i.imgur.com/uwcbvdi.png
[def19]: https://i.imgur.com/hTnAMtZ.png
[def20]: https://i.imgur.com/HfxX9wh.png