---
layout: post
title: "[데이터 분석 프로그래밍] 12주차 - Classification"
excerpt: "Evaluation Metrics for Classification Models, Logistic Regression"

tags:
  - [데이터 분석 프로그래밍, Python]

toc: true

date: 2024-11-19
last_modified_at: 2024-11-20
---
## Classification
### 1. Evaluation Metrics for Classification Models  
- **Regression** : input features를 이용하여 숫자 output values의 무한한 범위를 예측하는 수단  
![regression][def]  

- **Classification** : input features를 이용하여 categorical classes를 예측하는 수단  
![classification][def2]  

<br>

- Binary Classification : categorical labels이 두 개.
  - Example
    - 이메일이 'spam'인 지 'normal'인 지 예측
    - 환자가 'diseased'인 지 'not sick'인 지 진단
    - 스포츠 겨익에서 'win'인 지 'lose'인 지 예측  
  ![binary_classification][def3]  

- Multiclass Classification : categorical labels이 두 개 이상.
  - Example
    - dogs, cats, birds를 각각 `0`, `1`, `2`로 표현하여 분류  
  ![multiclass_classification][def4]  

<br>

#### Confusion Matrix  
- Confusion Matrix : 모델에 의해 예측된 label value와 실제 label value를 비교하는 표.
  - 주로 classification model의 성능을 측정하는 데 사용된다.  
  <br>
    
![confusion_matrix][def5]  
- True Positive(TP) : 실제 값이 `1`이고 예측 값도 `1`인 경우 (`y = 1`, `ŷ = 1`)
- True Negative(TN) : 실제 값이 `0`이고 예측 값도 `0`인 경우 (`y = 0`, `ŷ = 0`)
- False Positive(FP) : 실제 값이 `0`이고 예측 값이 `1`인 경우 (`y = 0`, `ŷ = 1`)
- False Negative(FN) : 실제 값이 `1`이고 예측 값이 `0`인 경우 (`y = 1`, `ŷ = 0`)  

<br>

- **Accuracy** : 전체 데이터 중에서 정확하게 예측한 데이터의 비율  
![accuracy][def6]  
  - `Accuracy` = `(TP + TN)` / `(TP + TN + FP + FN)`  

  - 데이터가 불균형한 imbalanced datase에서는 한계가 있다.  

- **Precision** : 모델이 `1`로 예측한 데이터 중에서 실제로 `1`인 데이터의 비율  
(positive prediction의 정확도)  
![precision][def7]  
  - `Precision` = `TP` / `(TP + FP)`

- **Recall** : 실제 `1`인 데이터 중에서 모델이 `1`로 예측한 데이터의 비율  
![recall][def8]  
  - `Recall` = `TP` / `(TP + FN)`  

- **F1 Score** : `Precision`과 `Recall`의 조화평균(harmonic mean)  
![f1_score][def9]  
  - `F1 Score` = `2 * Precision * Recall` / `(Precision + Recall)`

  - imbalance datasets에서, F1 score는 작은 클래스에 대한 예측 성능을 강조한다.  

<br>

- Model Evaluation using Scikit-learn  

```py
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
```

```py
y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0]
y_pred = [1, 0, 0, 1, 1, 1, 0, 1, 1, 0]
```

```py
# Create confusion matrix
cm = confusion_matrix(y_true, y_pred)
print(cm)
# [[3 2]
#  [2 3]]
```

```py
accuracy = accuracy_score(y_true, y_pred)
precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)

print("Accuracy: ", accuracy)
print("Precision: ", precision)
print("Recall: ", recall)
print("F1 Score: ", f1)
# Accuracy:  0.7
# Precision:  0.6666666666666666
# Recall:  0.8
# F1 Score:  0.7272727272727272
```

```py
# classification_report
from sklearn.metrics import classification_report

y_true = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]
y_pred = [1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1]

# Print classification report
report = classification_report(y_true, y_pred)
print(report)
```

![classification_report][def10]  

<br>

### 2. Logistic Regression  
#### [1] Binary Classification
- classification은 categorical classes를 예측하는 수단인 반면,  
**Regression**은 숫자 input data를 이용하여 real numbers를 예측하는 수단이다.  

- Linear Regression vs. Logistic Regression  
![linear_vs_logistic_regression][def11]  
  - Linear Regression을 사용하여 표현하면, 아래와 같은 형태로 나타난다.  
  - linear regression의 결과가 sigmoid function(logistic function)의 input으로 들어가고,  
  최종 값은 `0`과 `1` 사이의 값으로 나타난다.  
  ![make_logistic_regression][def12]  

  <br>

- Logistic regression은 sigmond function의 결과를 `0.5`를 기준으로 `0`과 `1`로  분류하여,  
예측된 class를 결정한다.  
![logistic_regression][def13]  

<br>

- 아래와 같은 Heart Disease Dataset이 있다고 하자.  
![heart_disease_dataset][def14]  

```py
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, f1_score
import matplotlib.pyplot as plt
```

```py
df.head(3)
```

![heart_disease_dataset_head][def15]  

```py
df.info()
```

![heart_disease_dataset_info][def16]  

```py
print("Missing values in each column:")
print(df.isnull().sum())
```

![heart_disease_dataset_missing][def17]

```py
# Check the distribution of the target variable
print("Distribution of target variable:")
print(df['target'].value_counts())
```

![heart_disease_dataset_target][def18]

```py
# Divide the entire data into training data and test data
X = df[['thalach']]
y = df['target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling (Standardization)
scalar = StandardScaler()
X_train_scaled = scalar.fit_transform(X_train)
X_test_scaled = scalar.transform(X_test)
```

- StandardScaler는 데이터를 평균이 0, 표준편차가 1인 표준 정규분포를 따르도록 변환한다.  
  - `fit_transform(X_train)` : training data를 scaling하고 변환
  - `transform(X_test)` : test data를 scaling하고 변환

```py
# initialized the Logistic Regression model
model = LogisticRegression(max_iter=1000)
# Train the model
model.fit(X_train_scaled, y_train)
```

```py
# Predict using the test set
y_pred = model.predict(X_test_scaled)
y_pred
```

![heart_disease_dataset_predict][def19]  

<br>

- Evaluate the model 

```py
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print(f"\nAccuracy: {accuracy_score(y_test, y_pred):.3f}")
print(f"F1 Score: {f1_score(y_test, y_pred):.3f}")
```

![heart_disease_dataset_evaluation][def20]  

- Understanding the model

```py
print(model.predict(X_test_scaled[:5]))
# [1 0 0 1 1]

print(model.predict_proba(X_test_scaled[:5]))
#  [[0.33684463, 0.66315537]
#   [0.82431009, 0.17568991]
#   [0.53900003, 0.46099997]
#   [0.34726783, 0.65273217]
#   [0.48119213, 0.51880787]]

print(model.coef_, model.intercept_)
# [[1.06129273]] [0.04521758]
```

#### [2] Multiclass Classification
- Multiclass Classification은 데이터를 여러 classes(or categories) 중 하나로 분류하는 것이다.  
  - binary classification과 달리, 2개 이상의 classes 중에서 어느 class에 속할 지 예측한다.  

- Multiclass Classification은 여러 번의 binary classification을 하는 것과 같다.  
![multiclass_classification][def21]  

<br>

- 각 모델의 값들만 가지고 어떤 한 linear model이 다른 linear model보다 더 나은지를 비교하는 것은 어렵다.  
  - 왜냐하면 각 linear model의 값들을 1로 정규화하는 것이 필요하기 때문이다.  
  - 그렇기에 softmax function을 사용하여 각 class에 대한 확률을 계산한다.  
  ![softmax_function][def22]  
    - `K` : class의 개수
    - `z`<sub>`i`</sub> : i번째 class에 대한 linear model의 output 값  

  - 조금 전의 Multiplication Classification의 `Z` = `[3.2, -0.4, 1.2]` 였다고 하면,  
  ![softmax_function_example][def23]  

  <br>

```py
# Divide the entire data into training data and test data
X = df.drop('thal', axis=1)
y = df['thal']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Data Standardization
scalar = StandardScaler()
X_train = scalar.fit_transform(X_train)
X_test = scalar.transform(X_test)
```

```py
thal_counts = df['thal'].value_counts()
print("Counts of unique values in 'thal' column:\n", thal_counts)
```

![multiclass_classification_counts][def24]  

```py
# Initialize the Logistic Regression model
model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=500)

# Train the model
model.fit(X_train_scaled, y_train)
```

```py
# Predict using the test set
y_pred = model.predict(X_test)
y_pred
```

![multiclass_classification_predict][def25]  

```py
# Understanding the model
print(model.predict(X_test[:5]))
# [2 3 3 3 2]

proba = model.predict_proba(X_test[:5])
print(np.round(proba, decimals=3))
```

![multiclass_classification_predict_proba][def26]  

```py
print(model.coef_, model.intercept_)
```

![multiclass_classification_coef_intercept][def27]  

<br>

### 3. K-Nearest Neighbor Classification
- KNN은 classification과 regression에 뛰어난 알고리즘을 제공한다.  
- KNN은 비슷한 것들이 서로 가까이에 있다는 생각을 기반으로 작동한다.  
- KNN은 `k`개의 인접 data points를 찾아서 가장 높은 빈도로 나타내는 category로 분류한다.  
- 거리를 측정하는 데에는 주로 Euclidean distance를 사용한다.  
![knn][def28]  

<br>

- KNN Example
  - 새로운 데이터가 들어왔을 때, 기존 데이터와의 거리를 계산하여 예측을 진행한다.  
  ![knn_example][def29]  

  <br>

- KNN Classification in Python

```py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score

df.head(5)
```

![knn_classification_head][def30]  

```py
numerical_features = ['age', 'cp', 'trestbps', 'chol', 'thalach', 'oldpeak']
X = df[numerical_features]
y = df['target']
# Split into training and test data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Feature Scaling (Standardization)
scalar = StandardScaler()
X_train_scaled = scalar.fit_transform(X_train)
X_test_scaled = scalar.transform(X_test)
```

```py
# Initialize K-NN model (set K=5)
knn = KNeighborsClassifier(n_neighbors=5)
# Train the model
knn.fit(X_train_scaled, y_train)
```

```py
# Predict
y_pred = knn.predict(X_test_scaled)
y_pred
```

![knn_classification_predict][def31]  

```py
# Print confusion matrix
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Performance evaluation indicator output
print(f"\nAccuracy: {accuracy_score(y_test, y_pred):.3f}")
print(f"F1 Score: {f1_score(y_test, y_pred):.3f}")
```

![knn_classification_evaluation][def32]  

```py
# Setting the optimal k value
k_range = range(1, 21)
accuracies = []
f1_scores = []
# Calculate the accuracy of the k-NN model for each K value
for k in k_range :
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train_scaled, y_train)
    y_pred = knn.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    accuracies.append(accuracy)
    f1_scores.append(f1)
    print(f"K={k}, Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}")
```

![knn_classification_k_value][def33]  

```py
import matplotlib.pyplot as plt
# Visualization of accuracy according to K value
plt.figure(figsize=(12, 6))
plt.plot(k_range, accuracies, marker='o', linestyle='-', color='b', label='Accuracy')
plt.plot(k_range, f1_scores, marker='x', linestyle='-', color='r', label='F1 Score')
plt.xlabel('Number of Neighbors (K)')
plt.ylabel('Performance Metric')
plt.legend()
plt.grid()
plt.show()
```

![knn_classification_k_value_plot][def34]  

<br>

### 4. Naive Bayes Classification
- Naive Bayes Classification은 베이즈 정리를 기반으로 한 통계적 분류 테크닉이다.  
  - 'naive' 하다는 것은 각 feature가 독립적이라고 가정한다는 것이다.  
  (서로 영향을 X)  

- 베이즈 정리에 기반
  - 각 class의 조건부 확률을 계산하기 위하여 베이즈 정리를 사용한다.  

- 조건부 확률
  - 다른 한 event가 일어났다는 조건 하에 특정 event가 일어날 확률  
  - `P(A|B)` : B가 주어졌을 때 A의 확률
  - `P(B|A)` : A가 주어졌을 때 B의 확률  
  ![conditional_probability][def35]  

- 베이즈 정리
  - 베이즈 정리는 조건부 확률을 계산하는 방법이다.  
  - 새로운 데이터가 주어지는 경우, 이전에 알려진 정보들 중 관련된 것들에 기반하여 확률을 계산한다.  
  ![bayes_theorem][def36]  

<br>

- 아래와 같은 data set이 주어졌다.  
![naive_bayes_dataset][def37]  

  - 우리가 예측하고자 하는 것이 `Sunny ∩ High` 일 때 `Tennis`의 값이라면,  
  
    - (1) evidence `P(X)`  
    ![naive_bayes_evidence][def38]  

    - (2) likelihood `P(X|Y)`  
    ![naive_bayes_likelihood][def39]  

    - (3) prior probability `P(Y)`  
    ![naive_bayes_prior][def40]  

    - (4) posterior probability `P(Y|X)`  
    ![naive_bayes_posterior][def41]  

<br>

- Naive Bayes Classification in Python

```py
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import CategoricalNB
from sklearn.metrics import confusion_matrix, accuracy_score, f1_score

df.head(5)
```

![naive_bayes_classification_head][def30]  

```py
categorial_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']
X = df[categorial_features]
y = df['target']
# Split into training and test data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
```

```py
# Training Naive Bayes classification model
model = CategoricalNB()
model.fit(X_train, y_train)
```

```py
# Model prediction
y_pred = model.predict(X_test)
y_pred
```

![naive_bayes_classification_predict][def42]  

```py
# Evaluation of the model
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

# Performance evaluation indicator output
print(f"\nAccuracy: {accuracy_score(y_test, y_pred):.3f}")
print(f"F1 Score: {f1_score(y_test, y_pred):.3f}")
```

![naive_bayes_classification_evaluation][def43]  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">

이 포스팅은 강원대학교 장홍준 교수님의 데이터분석프로그래밍 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details> 

[def]: https://i.imgur.com/0ve69nM.png
[def2]: https://i.imgur.com/O6F3T3T.png
[def3]: https://i.imgur.com/iH2onU7.png
[def4]: https://i.imgur.com/mNTuKNf.png
[def5]: https://i.imgur.com/fZtamfF.png
[def6]: https://i.imgur.com/GTmeBxz.png
[def7]: https://i.imgur.com/wm0twFZ.png
[def8]: https://i.imgur.com/RsQbnpO.png
[def9]: https://i.imgur.com/Rn6nyrr.png
[def10]: https://i.imgur.com/3mSwAzg.png
[def11]: https://i.imgur.com/iwq5BJ6.png
[def12]: https://i.imgur.com/fQJGNQV.png
[def13]: https://i.imgur.com/Q87MhrH.png
[def14]: https://i.imgur.com/lyNcdT0.png
[def15]: https://i.imgur.com/GfpuNJQ.png
[def16]: https://i.imgur.com/NOoaGs1.png
[def17]: https://i.imgur.com/7B6Bkwh.png
[def18]: https://i.imgur.com/uwcbvdi.png
[def19]: https://i.imgur.com/hTnAMtZ.png
[def20]: https://i.imgur.com/HfxX9wh.png
[def21]: https://i.imgur.com/GkdX4cO.png
[def22]: https://i.imgur.com/Y92AepP.png
[def23]: https://i.imgur.com/g1u2ehs.png
[def24]: https://i.imgur.com/KfM3uKY.png
[def25]: https://i.imgur.com/aNQCJaG.png
[def26]: https://i.imgur.com/aNQCJaG.png
[def27]: https://i.imgur.com/JG91ghh.png
[def28]: https://i.imgur.com/W2FrzUR.png
[def29]: https://i.imgur.com/eVTUzmY.png
[def30]: https://i.imgur.com/NnRZQpJ.png
[def31]: https://i.imgur.com/6SIGLuW.png
[def32]: https://i.imgur.com/6LSZb7w.png
[def33]: https://i.imgur.com/jsfQs9e.png
[def34]: https://i.imgur.com/03AUf8H.png
[def35]: https://i.imgur.com/7vA3w5V.png
[def36]: https://i.imgur.com/xltX4Va.png
[def37]: https://i.imgur.com/0meMWi5.png
[def38]: https://i.imgur.com/4tp0pjM.png
[def39]: https://i.imgur.com/vHJScbM.png
[def40]: https://i.imgur.com/GqAmbm0.png
[def41]: https://i.imgur.com/XbKLr87.png
[def42]: https://i.imgur.com/6pZAYZT.png
[def43]: https://i.imgur.com/Ogbpfv0.png