---
layout: post
title: "[선형대수학] 12주차 (3) - Pseudo-Inverse"
excerpt: "Invertibility of Gram matrix, Pseudo-Inverse, Pseudo inverse of square or tall matrix, Pseudo inverse of square or wide matrix, Pseudo-inverse via QR factorization, Solving linear equations using pseudo-inverse"

tags:
  - [선형대수학, Math]

toc: true

date: 2024-05-23
last_modified_at: 2024-05-23
---
## Matrix Inverses
### 1. Invertibility of Gram matrix
- **Gram matrix** `A`<sup>`T`</sup>`A`는 ***invertible*** 할까?

  - `m x n` matrix `A`의 **columns 들이 linearly independent** 하다면,  
  이것의 `n x n` **Gram matrix** `A`<sup>`T`</sup>`A` 는 ***invertible*** 하다.  

  - proof ) `(A`<sup>`T`</sup>`A)x = 0` 의 solution `x`를 찾아보자.  
  `0 = x`<sup>`T`</sup>`(A`<sup>`T`</sup>`A)x = (Ax)`<sup>`T`</sup>`(Ax)`<sup>`T`</sup>`(Ax) = ∥Ax∥`<sup>`2`</sup>  
  -> `Ax = 0`
    - 앞서서 이미 `A`의 columns 들이 linearly independent 하다고 했으므로,  
    `x = 0` is the **only one solution** of `Ax = 0`  
    - 따라서 또한 `(A`<sup>`T`</sup>`A)x = 0` 에서도 `x = 0` is the **only one solution** 이다.  
    즉, `A`<sup>`T`</sup>`A` 는 ***invertible*** 하다.  

  - **역으로**, `A`<sup>`T`</sup>`A`가 ***invertible*** 하다면,  
  `(A`<sup>`T`</sup>`A)x = 0` 에서 `x = 0` is the **only one solution**.  
    - `A`의 **columns 들이 linearly dependent** 하다고 ***가정***해보면,  
    `Ax = 0`의 **non-zero `x` solution이 존재해야 한다**.  
    이는 곧 `(A`<sup>`T`</sup>`A)x = 0`에서도 **non-zero `x` solution이 존재**해야 한다는 말인데,  
    이는 **모순적**이다.  
    - 즉, `A`의 **columns 또한 linearly independent 함을 역으로도 도출**할 수 있다.  

    <br>
  
### 2. Pseudo-Inverse
#### [1] Pseudo inverse of sqaure or tall matrix
- `A`의 **columns들이 linearly independent** -> `A` is ***left-invertible***  

- proof ) `A`의 **columns들이 linearly independent 하다고 가정**해보면,  
`A`<sup>`T`</sup>`A` : ***invertible*** 하므로  
`((A`<sup>`T`</sup>`A)`<sup>`-1`</sup>`A`<sup>`T`</sup>`)A = (A`<sup>`T`</sup>`A)`<sup>`-1`</sup>`(A`<sup>`T`</sup>`A) = I` 이므로,  
사실상 `A`의 ***left-inverse***는 `((A`<sup>`T`</sup>`A)`<sup>`-1`</sup>`A`<sup>`T`</sup>`)`가 되는 신기한 현상이 발견된다.  

![left_pseudo][def]

- 따라서 우리는 이 `(A`<sup>`T`</sup>`A)`<sup>`-1`</sup>`A`<sup>`T`</sup>를 `A`의 ***pseudo-inverse*** 라고 이름 붙였으며,  
때로는 *Moore-Penrose inverse* 라고도 부른다.  
우리는 이것을 **`A`<sup>`+`</sup> 라고 표기**할 것이다.  

- 만약 `A`가 **square** 라면, 다음과 같은 **등식이 추가로 성립**할 것이다.  
`A`<sup>`+`</sup>`= (A`<sup>`T`</sup>`A)`<sup>`-1`</sup>`A`<sup>`T`</sup>`= A`<sup>`-1`</sup>`A`<sup>`-T`</sup>`A`<sup>`T`</sup>`= A`<sup>`-1`</sup>`I = A`<sup>`-1`</sup>  
  - 즉, `A`<sup>`+`</sup>`= A`<sup>`-1`</sup>  

  <br>

#### [2] Pseudo inverse of square of wide matrix
- `B`의 **rows들이 linearly independent** -> `B` is ***right-invertible***  

- proof ) `B`의 **rows 들이 linearly independent 하다고 가정**해보면,  
`BB`<sup>`T`</sup> : ***invertible*** 하므로  
`BB`<sup>`T`</sup>`(BB`<sup>`T`</sup>`)`<sup>`-1`</sup>`= I` 이므로,  
사실상 `B`의 ***right-inverse***는 `B`<sup>`T`</sup>`(BB`<sup>`T`</sup>`)`<sup>`-1`</sup>가 되는 신기한 현상이 또 발견된다.  

![right_pseudo][def2]

- 따라서 우리는 이 `A`<sup>`T`</sup>`(AA`<sup>`T`</sup>`)`<sup>`-1`</sup>또한 `A`의 ***pseudo-inverse*** 라고 이름 붙였으며,  
또한 이것도 *Moore-Penrose inverse* 라고 부른다.  
마찬가지로 **`A`<sup>`+`</sup> 로 표기**할 수 있다.  

- 만약 `A`가 **square** 라면, 다음과 같은 **등식이 추가로 성립**할 것이다.  
`A`<sup>`+`</sup>`= A`<sup>`T`</sup>`(AA`<sup>`T`</sup>`)`<sup>`-1`</sup>`= A`<sup>`T`</sup>`A`<sup>`-T`</sup>`A`<sup>`-1`</sup>`= IA`<sup>`-1`</sup>`= A`<sup>`-1`</sup>
  - 즉, `A`<sup>`+`</sup>`= A`<sup>`-1`</sup>  

  <br>

#### [3] Pseudo-inverse via QR factorization  
- **사전 지식**
  - `Q`는 **orthonormal** 하므로 `Q`<sup>`T`</sup>`Q = I`.
  - `R`은 **upper triangular** 이므로 ***invertible***. 

- `A`가 ***left-invertible matrix*** 라면,  
`A`의 **columns 들은 linearly independent** 하며 `A = QR`  
(즉, **QR factorization 가능**하다.)  

  - 즉, **`Q`와 `R`을 이용**하여 `A`의 **pseudo-inverse**를 구할 수 있다.  
  ![left_QR_pseudo_inverse][def3]  

    - 더 나아가 `Q`<sup>`T`</sup>의 columns 들에 대하여 back substitution으로 `A`<sup>`+`</sup>가 계산될 수도 있겠다.  

- `A`가 ***right-invertible matrix*** 라면,  
`A`의 **rows 들은 linearly independent** 하며 `A`<sup>`T`</sup>`= QR`  
(즉, **QR factorization 가능**하다.)  

  - 즉, **`Q`와 `R`을 이용**하여 `A`의 ***pseudo-inverse***를 구할 수 있다.  
  ![right_QR_pseudo_inverse][def4]  

  <br>

#### [4] Solving linear equations using Pseudo-inverse
- matrix `A` is . . .
  - `A`의 **columns : linearly independent**
  - **Over-determined equation** `Ax = b` **has a solution**  
  - `Ax = b`  
  `AA`<sup>`+`</sup>`x = A`<sup>`+`</sup>`b`  
  `x = A`<sup>`+`</sup>`b`  
  (`A`<sup>`+`</sup>`= R`<sup>`-1`</sup>`Q`<sup>`T`</sup> 이므로)  
  `x = R`<sup>`-1`</sup>`Q`<sup>`T`</sup>`b`  
  `Rx = Q`<sup>`T`</sup>`b`
  - 최종적으로 **위 equation을 해결**하면 되겠다.  

- or, matrix `A` is . . .
  - `A`의 **rows : linearly independent**
  - **Under-determined equation** `Ax = b` **has a solution**  
  - `Ax = b`  
  `AA`<sup>`+`</sup>`x = A`<sup>`+`</sup>`b`  
  `x = A`<sup>`+`</sup>`b`  
  (`A`<sup>`+`</sup>`= QR`<sup>`-T`</sup> 이므로)  
  `x = QR`<sup>`-T`</sup>`b`  
  `R`<sup>`T`</sup>`x = Qb`
  - 최종적으로 **위 equation을 해결**하면 되겠다.  

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">

이 포스팅은 강원대학교 김도형 교수님의 선형대수학 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details>

[def]: https://i.imgur.com/VcSyEgB.png
[def2]: https://i.imgur.com/RZBxYzX.png
[def3]: https://i.imgur.com/2Lo6eKT.png
[def4]: https://i.imgur.com/ltGNAIX.png