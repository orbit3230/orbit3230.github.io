---
layout: post
title: "[선형대수학] 13주차 (3) - Least Sqaures"
excerpt: "Least Squares Problem, Column Interpretation,Row Interpretation, Example, Solution of least squares problem, Derivation via calculus, Verification of least squares solution"

tags:
  - [선형대수학, Math]

toc: true

date: 2024-05-30
last_modified_at: 2024-05-30
---
## Least Squares
### 1. Least squares problem
- `m x n` matrix `A`가 tall 하다면,  
  -> `Ax = b` equation은 over-determined.  

  - 만약 solution `x`가 존재한다면, `b`는 `A`의 columns 들에 대한 linear combination set 임이 자명하다.  

- 하지만 슬프게도, 대부분의 `b`에 대하여 `Ax = b`를 만족하는 `x`는 존재하지 않는다.  

- 따라서 우리는 타협점으로, `Ax`가 `b`와 가장 가까운 값을 가지게 하는 `x`를 찾을 것이다.  
`r`(residual)`= Ax - b`  

  - 가장 가깝다는 것은, `Ax`와 `b` 사이의 Euclidean Distance를 최소화 하겠다는 의미이다.  

  ![minimum_euclidean_distance][def]
  - 따라서, 우리는 `∥Ax - b∥`<sup>`2`</sup> 를 최소화하는 `x`를 선택할 것이다.  

  - 제곱의 최소값을 찾는 해결방법이라서, 최소 제곱법(Least Square) 이라고 부른다.  

  <br>

- 그렇게하여 선택된 `Ax = b`에 대한 least squares approximate solution을 `x̂`(x-hat) 으로 표기하자.  
또한 `x̂`에 대하여 다음과 같은 inequality가 성립한다.  
![least_sqaures_approximate_solution_inequality][def12]

<br>

### 2. Column Interpretation
- Least squares problem `∥Ax - b∥`<sup>`2`</sup>을 Column의 관점에서 해석해보자.  
`a`<sub>`1`</sub>`, a`<sub>`2`</sub>`, ..., a`<sub>`n`</sub>을 `A`의 column들이라고 하면,  

![column_interpretation][def3]  

- 즉, Least sqaures problem은 이렇게도 해석될 수 있다.  

  -> `b`에 가장 가까운 `A`의 Columns 들의 linear combination을 찾는 것

- 그러므로 `x̂`을 이용하여 다르게 표현하자면,  
`Ax̂`는 `A`의 columns 들에 대한 모든 linear combination들 중에서 `b`에 가장 가까운 `m`-vector이다.  
![linear_combination_of_x_hat][def4]  

<br>

### 3. Row Interpretation
- Least squares problem `∥Ax - b∥`<sup>`2`</sup>을 Row의 관점에서 해석해보자.  
`â`<sub>`1`</sub><sup>`T`</sup>`, â`<sub>`2`</sub><sup>`T`</sup>`, ..., â`<sub>`n`</sub><sup>`T`</sup>를 `A`의 Row들이라고 하면,  

![row_interpretation][def5]  

- 즉, Least sqaures problem은 이렇게도 해석될 수 있다.  
  ![residual_components][def6]  
  -> residual들의 제곱의 합을 최소화하는 것.  

  - 간단하게 말해 만약 `Ax = b`가 Solving 가능하다면, 모든 residuals 들을 `zero`로 만드는 것이다.  

  - 그렇지 못하는 지금같은 경우, Least Squares는 모든 residuals 들을 가능한 작게 만드려는 시도가 되겠다.  

  <br>

### 4. Example
- Least Squares Problem 으로 approximate solution을 찾는 예제를 하나 보자!  
다음과 같은 tall matrix `A`와 vector `b`가 있다.  

![least_squares_example][def7]  

- `Ax = b`는 solution이 존재하지 않는다.  
그러므로 Least Sqaures Problem 을 적용해보자.  

![example_least_squares_applying][def8]  

- 계산해보면, 최소값으로 만드는 `x̂ = (1/3, -1/3)` 이다.  

  - `∥Ax̂ - b∥`은 `∥Ax - b∥`<sup>`2`</sup>의 가능한 최소값이 된다.  
  - `Ax̂ = (2/3, -2/3, -2/3)`은 `b`와 가장 가까운 `A`의 Columns에 대한 linear combination이 된다.  

  <br>

### 5. Solution of least squares problem
- 우선 전제조건으로 반드시 가정하고 가야하는 것이 있다.  
`A`의 Columns 들은 linearly independent 하다. 이를 기억하자.  

- 따라서 Gram matrix `A`<sup>`T`</sup>`A`는 invertible 하다.  

- 이를 통하여, Least Sqaures problem의 Unique solution은,  
![least_square_problem_unique_solution][def9]  

  - WHY ??!!  우리 한번 차근차근 살펴보자.  

  <br>

#### Derivation via calculus
- 우선 Least Sqaures의 목표인 `∥Ax - b∥`<sup>`2`</sup>를 Element 단위로 풀어서 summation으로 표현해보자면 이렇다.  
![least_squares_summation][def10]  
  - 잘 이해가 안 간다면, row interpretation을 다시 보고 오는 것도 도움이 될 것이다.  

- 이제 여기에 `x`에 대하여 Partial Derivative(편미분)을 취해줄 것이다.  
![partial_derivative][def11]  

- 우리가 찾고자하는건, `∥Ax - b∥`<sup>`2`</sup>의 최소값이다.  
이차 함수의 그래프를 생각해보자. 이차 함수에서 최소값은 기울기가 정확히 `0`이 되는, 그래프의 바닥 부분이다.  
따라서 편미분한 결과를 `= 0`으로 설정하면, 해당 지점이 함수의 최소값이 된다.  
![partial_derivative_equals_zero][def2]  

- 추가적으로 pseudo-inverse를 적용하면,  
`x̂ = A`<sup>`+`</sup>`b`  

<br>

#### Verification of least squares solution
- 따라서 `x̂ = (A`<sup>`T`</sup>`A)`<sup>`-1`</sup>`A`<sup>`T`</sup>`b` 이 least squares problem의 solution임이 밝혀졌으므로,  
우리는 아래 부등식이 성립함을 보일 수 있게되었다.  
![least_sqaures_approximate_solution_inequality][def13]  

- proof )
![inequality_proof][def14]

<br>
<br>
<br>
<br>
<details>
<summary>주의사항</summary>
<div markdown="1">

이 포스팅은 강원대학교 김도형 교수님의 선형대수학 수업을 들으며 내용을 정리 한 것입니다.  
수업 내용에 대한 저작권은 교수님께 있으니,  
다른 곳으로의 무분별한 내용 복사를 자제해 주세요.

</div>
</details>

[def]: https://i.imgur.com/v46aBpo.png
[def3]: https://i.imgur.com/ictNhEj.png
[def4]: https://i.imgur.com/Apbpnyz.png
[def5]: https://i.imgur.com/f0ue4Hh.png
[def6]: https://i.imgur.com/rAc8VVZ.png
[def7]: https://i.imgur.com/rIWGWY8.png
[def8]: https://i.imgur.com/ICqcenY.png
[def9]: https://i.imgur.com/9UcSVU6.png
[def10]: https://i.imgur.com/1eSrMcW.png
[def11]: https://i.imgur.com/6FVOvMZ.png
[def2]: https://i.imgur.com/1FhGiey.png
[def12]: https://i.imgur.com/JOxU7Fv.png
[def13]: https://i.imgur.com/dwEeVo2.png
[def14]: https://i.imgur.com/L4RbgyH.png